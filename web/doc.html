<head>
   <title>Backendjs Documentation</title>
   <link rel="shortcut icon" href="img/logo.png" type="image/png" />
   <link rel="icon" href="img/logo.png" type="image/png" />
   <link href="css/bootstrap5.css" rel="stylesheet">
   <link href="css/doc.css" rel="stylesheet" >
</head>
<body>
    <div class="d-flex justify-content-between align-items-center w-100 pb-4">
      <div><img class="logo" height=22 src="img/logo.png"><span class="px-2">Backend library for Node.js</span></div>
      <a href="https://github.com/vseryakov/backendjs">[Repository]</a>
    </div>

<h1 id="backendjs-documentation">Backendjs Documentation</h1>
<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#backend-library-for-node-js"> Backend library for Node.js</a></li>
<li><a href="#installation"> Installation</a></li>
<li><a href="#dependencies"> Dependencies</a></li>
<li><a href="#quick-start-and-introduction"> Quick start and introduction</a></li>
<li><a href="#to-run-an-example"> To run an example</a></li>
<li><a href="#configuration"> Configuration</a></li>
<li><a href="#backend-runtime"> Backend runtime</a></li>
<li><a href="#application-structure"> Application structure</a></li>
<li><a href="#modules"> Modules</a></li>
<li><a href="#npm-packages-as-modules"> NPM packages as modules</a></li>
<li><a href="#database-schema-definition"> Database schema definition</a></li>
<li><a href="#tables-can-have-aliases"> Tables can have aliases</a></li>
<li><a href="#api-requests-handling"> API requests handling</a></li>
<li><a href="#example-of-todo-application"> Example of TODO application</a></li>
<li><a href="#backend-directory-structure"> Backend directory structure</a></li>
<li><a href="#environment-variables"> Environment variables</a></li>
<li><a href="#cache-configurations"> Cache configurations</a></li>
<li><a href="#local"> Local</a></li>
<li><a href="#redis"> Redis</a></li>
<li><a href="#pub-sub-or-queue-configurations"> PUB/SUB or Queue configurations</a></li>
<li><a href="#redis-system-bus"> Redis system bus</a></li>
<li><a href="#redis-queue"> Redis Queue</a></li>
<li><a href="#sqs"> SQS</a></li>
<li><a href="#local"> Local</a></li>
<li><a href="#nats"> NATS</a></li>
<li><a href="#rabbitmq"> RabbitMQ</a></li>
<li><a href="#security-configurations"> Security configurations</a></li>
<li><a href="#api-only"> API only</a></li>
<li><a href="#secure-web-site-client-verification"> Secure Web site, client verification</a></li>
<li><a href="#secure-web-site-backend-verification"> Secure Web site, backend verification</a></li>
<li><a href="#websockets-connections"> WebSockets connections</a></li>
<li><a href="#versioning"> Versioning</a></li>
<li><a href="#the-backend-tool-bkjs"> The backend tool: bkjs</a></li>
<li><a href="#extending-bkjs"> Extending bkjs</a></li>
<li><a href="#web-development-notes"> Web development notes</a></li>
<li><a href="#deployment-use-cases"> Deployment use cases</a></li>
<li><a href="#aws-instance-setup-with-node-and-backendjs"> AWS instance setup with node and backendjs</a></li>
<li><a href="#aws-provisioning-examples"> AWS Provisioning examples</a></li>
<li><a href="#make-an-ami"> Make an AMI</a></li>
<li><a href="#update-route53-with-all-ips-from-running-instances"> Update Route53 with all IPs from running instances</a></li>
<li><a href="#configure-http-port"> Configure HTTP port</a></li>
<li><a href="#backend-library-development-mac-os-x-developers-"> Backend library development (Mac OS X, developers)</a></li>
<li><a href="#simple-testing-facility"> Simple testing facility</a></li>
<li><a href="#design-considerations"> Design considerations</a></li>
<li><a href="#api-endpoints-provided-by-the-backend"> API endpoints provided by the backend</a></li>
<li><a href="#authentication-and-sessions"> Authentication and sessions</a></li>
<li><a href="#signature"> Signature</a></li>
<li><a href="#authentication-api"> Authentication API</a></li>
<li><a href="#accounts"> Accounts</a></li>
<li><a href="#health-enquiry"> Health enquiry</a></li>
<li><a href="#data"> Data</a></li>
<li><a href="#system-api"> System API</a></li>
<li><a href="#author"> Author</a></li>
<li>Javascript Modules<ul>
<li><a href="#module-api">api</a></li>
<li><a href="#module-app">app</a></li>
<li><a href="#module-auth">auth</a></li>
<li><a href="#module-aws">aws</a></li>
<li><a href="#module-core">core</a></li>
<li><a href="#module-db">db</a></li>
<li><a href="#module-events">events</a></li>
<li><a href="#module-httpget">httpget</a></li>
<li><a href="#module-ipc">ipc</a></li>
<li><a href="#module-nats">nats</a></li>
<li><a href="#module-jobs">jobs</a></li>
<li><a href="#module-lib">lib</a></li>
<li><a href="#module-logger">logger</a></li>
<li><a href="#module-syslog">syslog</a></li>
<li><a href="#module-metrics">metrics</a></li>
<li><a href="#module-msg">msg</a></li>
<li><a href="#module-pool">pool</a></li>
<li><a href="#module-run">run</a></li>
<li><a href="#module-server">server</a></li>
<li><a href="#module-shell">shell</a></li>
<li><a href="#module-watch">watch</a></li>
<li><a href="#module-bk_data">bk_data</a></li>
<li><a href="#module-bk_system">bk_system</a></li>
<li><a href="#module-bk_user">bk_user</a></li>
</ul>
</li>
</ul>
<h1 id="backend-library-for-node-js">Backend library for Node.js</h1>
<p>General purpose backend library. The primary goal is to have a scalable platform for running and managing Node.js
servers for Web services implementation.</p>
<p>This project only covers the lower portion of the Web services ecosystem:
Node.js processes, HTTP servers, basic API functionality, database access, caching, messaging between processes,
metrics and monitoring, a library of tools for developing Node.js servers.</p>
<p>For the UI and presentation layer there are no restrictions what to use as long as it can run on top of the Express server.</p>
<p>Features:</p>
<ul>
<li>Exposes a set of Web service APIs over HTTP(S) using Express framework.</li>
<li>Database API supports SQLite, PostreSQL, DynamoDB, ElasticSearch with all basic operations behaving the
same way allowing you to switch databases without changing the code.</li>
<li>Database operations (Get, Put, Del, Update, Select) for all supported databases using the same DB API.</li>
<li>Experimental database drivers for MySQL, Cassandra, Riak, CouchDB</li>
<li>Experimental DynamoDB Streams processing in background worker processes</li>
<li>Easily extensible to support any kind of database, provides an experimental database driver on top of Redis with all supported methods as an example.</li>
<li>Supports crontab and queue job processing by separate worker processes.</li>
<li>Authentication is based on signed requests using API key and secret, similar to Amazon AWS signing requests.</li>
<li>Runs web server as separate processes to utilize multiple CPU cores.</li>
<li>Supports WebSockets connections and process them with the same Express routes as HTTP requests</li>
<li>Supports several cache modes(Redis, Memcache, Hazelcast, LRU) for the database operations, multiple hosts support
in the clients for failover.</li>
<li>Supports several PUB/SUB modes of operations using Redis, NATS, RabbitMQ, Hazelcast.</li>
<li>Supports async jobs processing using several work queue implementations on top of SQS, Redis, NATS, DB, RabbitMQ, Hazelcast.</li>
<li>REPL (command line) interface for debugging and looking into server internals.</li>
<li>Supports push notifications via Webpush, APN and FCM.
server running in the master process instead of relying on the OS scheduling between processes listening on the same port.</li>
<li>Can be used with any MVC, MVVC or other types of frameworks that work on top of, or with, the Express server.</li>
<li>AWS support is very well integrated including EC2, S3, DynamoDB, SQS and more.</li>
<li>Includes simple log watcher to monitor the log files including system errors.</li>
<li>Supports i18n hooks for request/response objects, easily overriden with any real i18n implementation.</li>
<li>Integrated very light unit testing facility which can be used to test modules and API requests</li>
<li>Support runtime metrics about the timing on database, requests, cache, memory and request rate limit control</li>
<li>Full implementation of SRP6a protocol in the server and client</li>
<li>Hosted on <a href="https://github.com/vseryakov/backendjs">github</a>, BSD licensed.</li>
</ul>
<p>Check out the <a href="http://bkjs.io">Documentation</a> for more details.</p>
<h1 id="installation">Installation</h1>
<p>To install the module with all optional dependencies if they are available in the system</p>
<pre><code>npm install backendjs
</code></pre>
<p>To install from the git</p>
<pre><code> npm install git+https://github.com/vseryakov/backendjs.git
</code></pre>
<p>or simply</p>
<pre><code> npm install vseryakov/backendjs
</code></pre>
<h1 id="dependencies">Dependencies</h1>
<p>Only core required dependencies are installed but there are many modules which require a module to work correctly.</p>
<p>All optional dependencies are listed in the package.json under &quot;modDependencies&quot; so npm cannot use it, only manual install of required modules is supported or
it is possible to install all optional dependencies for development purposes.</p>
<p>Here is the list of modules required for each internal feature:</p>
<ul>
<li><code>pg</code> - PostgreSQL database access</li>
<li><code>argon2</code> or <code>bcrypt</code> - for user password hashing</li>
<li><code>mmmagic</code> - file detection in uploads, only used when <code>allow</code> is passed to the <code>api.putFile</code></li>
<li><code>redis</code> - for Redis queue and cache driver</li>
<li><code>unix-dgram</code> - for syslog on Linux to use local syslog</li>
<li><code>bkjs-sqlite</code> - to use SQLite database driver</li>
<li><code>web-push</code> - for Web push notifications</li>
<li><code>@parse/node-apn</code> - for Apple push notifications</li>
<li><code>sharp</code> - scaling images in uploads using VPS imaging</li>
<li><code>nats</code> - NATS driver for queue and events</li>
<li><code>amqplib</code> - RabbitMQ driver for queue and events (alpha)</li>
</ul>
<p>The command below will show all core and optional dependencies, <code>npm install</code> will install only the core dependencies</p>
<pre><code> bkjs deps -dry-run -mods
</code></pre>
<h1 id="quick-start-and-introduction">Quick start and introduction</h1>
<ul>
<li><p>Simplest way of using the backendjs, it will start the server listening on port 8000</p>
<pre><code>  $ node
  &gt; const bkjs = require(&#39;backendjs&#39;)
  &gt; bkjs.server.start()
</code></pre>
</li>
<li><p>Access is allowed only with valid signature except urls that are explicitly allowed without it (see <code>api-allow</code> config parameter below)</p>
</li>
<li><p>Same but using the helper tool, by default no database driver are enablked so here we use embedded SQLite database and listen on port 8000.</p>
<pre><code>  bkjs web -db-pool sqlite -db-sqlite-pool default
</code></pre>
</li>
<li><p>or to the PostgreSQL server, database backend</p>
<pre><code>  bkjs web -db-pool pg -db-pg-pool postgresql://postgres@localhost/backend
</code></pre>
</li>
<li><p>If running on EC2 instance with IAM profile no need to specify AWS credentials:</p>
<pre><code>  bkjs web -db-pool dynamodb -db-dynamodb-pool default
</code></pre>
</li>
<li><p>To start the server and connect to the DynamoDB (command line parameters can be saved in the <code>etc/config file</code>, see below about config files)</p>
<pre><code>  bkjs web -db-pool dynamodb -db-dynamodb-pool default -aws-key XXXX -aws-secret XXXX
</code></pre>
</li>
<li><p>or to the ElasticSearch server, database backend</p>
<pre><code>  bkjs web -db-pool elasticsearch -db-elasticsearch-pool http://127.0.0.1:9200
</code></pre>
</li>
<li><p>All commands above will behave exactly the same</p>
</li>
<li><p><strong>Tables are not created by default</strong>, in order to initialize the database, run the server or the shell with <code>-db-create-tables</code> flag,
it is called only inside a master process, a worker never creates tables on start</p>
<ul>
<li><p>prepare the tables in the shell</p>
<pre><code>bksh -db-pool dynamodb -db-dynamodb-pool default -db-create-tables
</code></pre>
</li>
<li><p>run the server and create tables on start, run Elasticsearch locally first on the local machine</p>
<pre><code>bkjs get-elasticsearch
bkjs run-elasticsearch

bkjs web -db-pool elasticsearch -db-elasticsearch-pool http://127.0.0.1:9200 -db-create-tables
</code></pre>
</li>
</ul>
</li>
<li><p>While the local backendjs is runnning, the documentation is always available at <a href="http://localhost:8000/doc.html">http://localhost:8000/doc.html</a> (or whatever port is the server using)</p>
</li>
<li><p>To add users from the command line</p>
<pre><code>  bksh -user-add login test secret test name TestUser email test@test.com
</code></pre>
</li>
<li><p>To start Node.js shell with backendjs loaded and initialized, all command line parameters apply to the shell as well</p>
<pre><code>  bkjs shell
</code></pre>
</li>
<li><p>To access the database while in the shell using callbacks</p>
<pre><code>  &gt; db.select(&quot;bk_user&quot;, {}, lib.log);
  &gt; db.add(&quot;bk_user&quot;, { id: &#39;test2&#39;, login: &#39;test2&#39;, secret: &#39;test2&#39;, name&#39; Test 2 name&#39; }, lib.log);
  &gt; db.select(&quot;bk_user&quot;, { id: &#39;test2&#39; }, lib.log);
  &gt; db.select(&quot;bk_user&quot;, { id: [&#39;test1&#39;,&#39;test2&#39;] }, { ops: { id: &quot;in&quot; } }, lib.log);
</code></pre>
</li>
</ul>
<p>or the same using async/await, same methods with <code>a</code> prepended to the name</p>
<pre><code>    &gt; await db.aselect(&quot;bk_user&quot;, {});
    &gt; await db.aadd(&quot;bk_user&quot;, { id: &#39;test2&#39;, login: &#39;test2&#39;, secret: &#39;test2&#39;, name&#39; Test 2 name&#39; });
    &gt; await db.aselect(&quot;bk_user&quot;, { id: &#39;test2&#39; });
</code></pre>
<ul>
<li><p>To search using Elasticsearch (assuming it runs on EC2 and it is synced with DynamoDB using streams)</p>
<pre><code>  &gt; await db.select(&quot;bk_user&quot;, { q: &#39;test&#39; }, { pool: &quot;elasticsearch&quot; });
</code></pre>
</li>
</ul>
<h2 id="to-run-an-example">To run an example</h2>
<ul>
<li><p>The library is packaged with copies of Bootstrap, jQuery, Knockout.js for quick Web development
in web/js and web/css directories, all scripts are available from the browser with /js or /css paths. To use all at once as a bundle
run the following command:</p>
<pre><code>  cd node_modules/backendjs &amp;&amp; npm run devbuild
</code></pre>
</li>
<li><p>Go to <code>examples/api</code> directory:</p>
</li>
<li><p>Run the application, it will start the Web server on port 8000:</p>
<pre><code>  ./app.sh
</code></pre>
</li>
<li><p>Now log in with the new account,</p>
</li>
<li><p>Go to <a href="http://localhost:8000/api.html">http://localhost:8000/api.html</a> and click on <em>Login</em> at the top-right corner, then enter &#39;test&#39; as login and &#39;test&#39; as secret in the login popup dialog.</p>
</li>
<li><p>To see your account details run the command in the console <code>/account/get</code></p>
</li>
<li><p>To see current metrics run the command in the console <code>/system/stats/get</code></p>
</li>
<li><p>When the web server is started with <code>-watch</code> parameter or as <code>bkjs watch</code> then any change in the source files will make the server restart automatically
letting you focus on the source code and not server management, this mode is only enabled by default in development mode,
check <code>app.sh</code> for parameters before running it in production.</p>
</li>
</ul>
<h1 id="configuration">Configuration</h1>
<p>Almost everything in the backend is configurable using config files, a config database or DNS.
The whole principle behind it is that once deployed in production, even quick restarts are impossible to do so
there should be a way to push config changes to the processes without restarting.</p>
<p>Every module defines a set of config parameters that defines the behavior of the code, due to the single threaded
nature of the Node.js. It is simple to update any config parameter to a new value so the code can operate differently.
To achieve this the code must be written in a special way, like driven by configuration which can be changed at
any time.</p>
<p>All configuration goes through the configuration process that checks all inputs and produces valid output which
is applied to the module variables. Config file or database table with configuration can be loaded on demand or
periodically, for example all local config files are watched for modification and reloaded automatically, the
config database is loaded periodically which is defined by another config parameter.</p>
<h1 id="backend-runtime">Backend runtime</h1>
<p>When the backendjs server starts it spawns several processes that perform different tasks.</p>
<p>There are 2 major tasks of the backend that can be run at the same time or in any combination:</p>
<ul>
<li>a Web server (server) with Web workers (web)</li>
<li>a job scheduler (master)</li>
</ul>
<p>These features can be run standalone or under the guard of the monitor which tracks all running processes and restarted any failed ones.</p>
<p>This is the typical output from the ps command on Linux server:</p>
<pre><code>ec2-user    891  0.0  0.6 1071632 49504 ?  Ssl  14:33   0:01 bkjs: monitor
ec2-user    899  0.0  0.6 1073844 52892 ?  Sl   14:33   0:01 bkjs: master
ec2-user    908  0.0  0.8 1081020 68780 ?  Sl   14:33   0:02 bkjs: server
ec2-user    917  0.0  0.7 1072820 59008 ?  Sl   14:33   0:01 bkjs: web
ec2-user    919  0.0  0.7 1072820 60792 ?  Sl   14:33   0:02 bkjs: web
ec2-user    921  0.0  0.7 1072120 40721 ?  Sl   14:33   0:02 bkjs: worker
</code></pre>
<p>To enable any task a command line parameter must be provided, it cannot be specified in the config file. The <code>bkjs</code> utility supports several
commands that simplify running the backend in different modes.</p>
<ul>
<li><code>bkjs start</code> - this command is supposed to be run at the server startup as a service, it runs in the background and the monitors all tasks,
 the env variable <code>BKJS_SERVER</code> must be set in the profile to one of the <code>master or monitor</code> to define which run mode to use</li>
<li><code>bkjs start-instance</code> - this command is supposed to be run at the server startup to perform system adjustments, it is run in <code>bkjs start</code></li>
<li><code>bkjs watch</code> - runs the master and Web server in wather mode checking all source files for changes, this is the common command to be used
 in development, it passes the command line switches: <code>-watch -master</code></li>
<li><code>bkjs monitor</code> - this command is supposed to be run at the server startup, it runs in the background and the monitors all processes,
 the command line parameters are: <code>-daemon -monitor -master -syslog</code></li>
<li><code>bkjs master</code> - this command is supposed to be run at the server startup, it runs in the background and the monitors all processes,
 the command line parameters are: <code>-daemon -monitor -master -syslog</code>, web server and workers are started by default</li>
<li><code>bkjs web</code> - this command runs just web server process with child processes as web workers</li>
<li><code>bkjs run</code> - this command runs without other parameters, all additional parameters can be added in the command line, this command
 is a barebone helper to be used with any other custom settings.</li>
<li><code>bkjs run -api</code> - this command runs a single process as web server, sutable for Docker</li>
<li><code>bkjs run -worker</code> - this command runs a single process worker, suatable for Docker</li>
<li><code>bkjs shell</code> or <code>bksh</code> - start backendjs shell, no API or Web server is initialized, only the database pools</li>
</ul>
<h1 id="application-structure">Application structure</h1>
<p>The main purpose of the backendjs is to provide API to access the data, the data can be stored in the database or some other way
but the access to that data will be over HTTP and returned back as JSON. This is default functionality but any custom application
may return data in whatever format is required.</p>
<p>Basically the backendjs is a Web server with ability to perform data processing using local or remote jobs which can be scheduled similar to Unix cron.</p>
<p>The principle behind the system is that nowadays the API services just return data which Web apps or mobiles apps can render to
the user without the backend involved. It does not mean this is simple gateway between the database, in many cases it is but if special
processing of the data is needed before sending it to the user, it is possible to do and backendjs provides many convenient helpers and tools for it.</p>
<p>When the API layer is initialized, the api module contains <code>app</code> object which is an Express server.</p>
<p>Special module/namespace <code>app</code> is designated to be used for application development/extension. This module is available in the same way as <code>api</code> and <code>core</code>
which makes it easy to refer and extend with additional methods and structures.</p>
<p>The typical structure of a single file backendjs application is the following:</p>
<pre><code class="language-javascript">    const bkjs = require(&#39;backendjs&#39;);
    const api = bkjs.api;
    const app = bkjs.app;
    const db = bkjs.db;

    app.listArg = [];

    // Define the module config parameters
    core.describeArgs(&#39;app&#39;, [
        { name: &quot;list-arg&quot;, array: 1, type: &quot;list&quot;, descr: &quot;List of words&quot; },
        { name: &quot;int-arg&quot;, type: &quot;int&quot;, descr: &quot;An integer parameter&quot; },
     ]);

    // Describe the tables or data models, all DB pools will use it, the master or shell
    // process only creates new tables, workers just use the existing tables
    db.describeTables({
         ...
    });

     // Optionally customize the Express environment, setup MVC routes or else, `api.app` is the Express server
    app.configureMiddleware = function(options, callback)
    {
       ...
       callback()
    }

    // Register API endpoints, i.e. url callbacks
    app.configureWeb = function(options, callback)
    {
        api.app.get(&#39;/some/api/endpoint&#39;, (req, res) =&gt; {
          // to return an error, the message will be translated with internal i18n module if locales
          // are loaded and the request requires it
          api.sendReply(res, err);

          // or with custom status and message, explicitely translated
          api.sendReply(res, 404, res.__({ phrase: &quot;not found&quot;, locale: &quot;fr&quot; }));

          // with config check
          if (app.intArg &gt; 5) ...
          if (app.listArg.indexOf(req.query.name) &gt; -1) ...

          // to send data back with optional postprocessing hooks
          api.sendJSON(req, err, data);
          // or simply
          res.json(data);
        });
        ...
        callback();
    }

    // Optionally register post processing of the returned data from the default calls
    api.registerPostProcess(&#39;&#39;, /^\/account\/([a-z\/]+)$/, (req, res, rows) =&gt; { ... });
     ...

    // Optionally register access permissions callbacks
    api.registerAccessCheck(&#39;&#39;, /^\/test\/list$/, (req, status, callback) =&gt; { ...  });
    api.registerPreProcess(&#39;&#39;, /^\/test\/list$/, (req, status, callback) =&gt; { ...  });
     ...
    bkjs.server.start();
</code></pre>
<p>Another probably easier way to create single file apps is to use your namespace instead of <code>app</code>:</p>
<pre><code class="language-javascript">    const bkjs = require(&quot;backendjs&quot;);
    const api = bkjs.api;
    const db = bkjs.db;

    const mymod = {
        name: &quot;mymod&quot;,
        args: [
            { name: &quot;types&quot;, type: &quot;list&quot;, descr: &quot;Types allowed&quot; },
            { name: &quot;size&quot;, type: &quot;int&quot;, descr: &quot;Records in one page&quot; },
        ],
        tables: {
            mytable: {
                id: { type: &quot;int&quot;, primary: 1 },
                name: { primary: 2 },
                type: { type: &quot;list&quot; },
                descr: {}
            }
        }
    };
    exports.module = mymod;
    bkjs.core.addModule(mymod);

    mymod.configureWeb = function(options, callback)
    {
        api.app.all(&quot;/mymod&quot;, async function(req, res) {
            if (!req.query.id) return api.sendReply(res, 400, &quot;id is required&quot;);
            req.query.type = mod.types;

            const rows = await db.aselect(&quot;mymod&quot;, req.query, { ops: { type: &quot;in&quot; }, count: mod.size });
            api.sendJSON(req, null, rows);
        });
    }

    bkjs.server.start();
</code></pre>
<p>Except the <code>app.configureWeb</code> and <code>server.start()</code> all other functions are optional, they are here for the sake of completeness of the example. Also
because running the backend involves more than just running web server many things can be setup using the configuration options like common access permissions,
configuration of the cron jobs so the amount of code to be written to have fully functioning production API server is not that much, basically only
request endpoint callbacks must be provided in the application.</p>
<p>As with any Node.js application, node modules are the way to build and extend the functionality, backendjs does not restrict how
the application is structured.</p>
<h2 id="modules">Modules</h2>
<p><em>By default no system modules are loaded except <code>bk_user</code>, it must be configured by the <code>-preload-modules</code> config parameter to
preload modules from the backendjs/modules/.</em></p>
<p>Another way to add functionality to the backend is via external modules specific to the backend, these modules are loaded on startup from the backend
home subdirectory <code>modules/</code>. The format is the same as for regular Node.js modules and only top level .js files are loaded on the backend startup.</p>
<p>Once loaded they have the same access to the backend as the rest of the code, the only difference is that they reside in the backend home and
can be shipped regardless of the npm, node modules and other env setup. These modules are exposed in the <code>core.modules</code> the same way as all other core submodules
methods.</p>
<p>Let&#39;s assume the <code>modules/</code> contains file facebook.js which implements custom FB logic:</p>
<pre><code class="language-javascript">    const bkjs = require(&quot;backendjs&quot;);
    const core = bkjs.core;
    const mod = {
        name: &quot;facebook&quot;,
        args: [
            { name: &quot;token&quot;, descr: &quot;API token&quot; },
        ]
    }
    module.exports = mod;

    mod.configureWeb = function(options, callback) {
       ...
    }

    mod.makeRequest = function(options, callback) {
         core.sendRequest({ url: options.path, query: { access_token: fb.token } }, callback);
    }
</code></pre>
<p>This is the main app code:</p>
<pre><code class="language-javascript">    const bkjs = require(&quot;backendjs&quot;);
    const core = bkjs.core;

    // Using facebook module in the main app
    api.app.get(&quot;/me&quot;, (req, res) =&gt; {

       core.modules.facebook.makeRequest({ path: &quot;/me&quot; }, (err, data) =&gt; {
          bkjs.api.sendJSON(req, err, data);
       });
    });

    bkj.server.start();
</code></pre>
<h2 id="npm-packages-as-modules">NPM packages as modules</h2>
<p>In case different modules is better keep separately for maintenance or development purposes they can be split into
separate NPM packages, the structure is the same, modules must be in the modules/ folder and the package must be loadable
via require as usual. In most cases just empty index.js is enough. Such modules will not be loaded via require though but
by the backendjs <code>core.loadModule</code> machinery, the NPM packages are just keep different module directories separate from each other.</p>
<p>The config parameter <code>preload-packages</code> can be used to specify NPM package names to be loaded separated by comma, as with the default
application structure all subfolders inside each NPM package will be added to the core:</p>
<ul>
<li>modules will be loaded from the modules/ folder</li>
<li>locales from the locales/ folder</li>
<li>files in the web/ folder will be added to the static search path</li>
<li>all templates from views/ folder will be used for rendering</li>
</ul>
<p>If there is a config file present as <code>etc/config</code> it will be loaded as well, this way each package can maintain its default config parameters if necessary
without touching other or global configuration. Although such config files will not be reloaded on changes, when NPM installs or updates packages it
moves files around so watching the old config is no point because the updated config file will be different.</p>
<h1 id="database-schema-definition">Database schema definition</h1>
<p>The backend support multiple databases and provides the same db layer for access. Common operations are supported and all other specific usage can be achieved by
using SQL directly or other query language supported by any particular database.
The database operations supported in the unified way provide simple actions like <code>db.get, db.put, db.update, db.del, db.select</code>. The <code>db.query</code> method provides generic
access to the database driver and executes given query directly by the db driver, it can be SQL or other driver specific query request.</p>
<p>Before the tables can be queried the schema must be defined and created, the backend db layer provides simple functions to do it:</p>
<ul>
<li>first the table needs to be described, this is achieved by creating a JavaScript object with properties describing each column, multiple tables can be described
at the same time, for example lets define album table and make sure it exists when we run our application:</li>
</ul>
<pre><code class="language-javascript">        db.describeTables({
           album: {
               id: { primary: 1 },                         // Primary key for an album
               name: { pub: 1 },                           // Album name, public column
               mtime: { type: &quot;now&quot; },                     // Modification timestamp
           },
           photo: {
               album_id: { primary: 1 },                   // Combined primary key
               id: { primary: 1 },                         // consisting of album and photo id
               name: { pub: 1, index: 1 },                 // Photo name or description, public column with the index for faster search
               mtime: { type: &quot;now&quot; }
           }
        });
</code></pre>
<ul>
<li>the system will automatically create the album and photos tables, this definition must remain in the app source code
and be called on every app startup. This allows 1) to see the db schema while working with the app and 2) easily maintain it by adding new columns if
necessary, all new columns will be detected and the database tables updated accordingly. And it is all JavaScript, no need to learn one more language or syntax
to maintain database tables.</li>
</ul>
<p>Each database may restrict how the schema is defined and used, the db layer does not provide an artificial layer hiding all specifics, it just provides the same
API and syntax, for example, DynamoDB tables must have only hash primary key or combined hash and range key, so when creating table to be used with DynamoDB, only
one or two columns can be marked with primary property while for SQL databases the composite primary key can consist of more than 2 columns.</p>
<p>The backendjs always creates several tables in the configured database pools by default, these tables are required to support default API functionality and some
are required for backend operations. Refer below for the JavaScript modules documentation that described which tables are created by default. In the custom applications
the <code>db.describeTables</code> method can modify columns in the default table and add more columns if needed.</p>
<p>For example, to make age and some other columns in the accounts table public and visible by other users with additional columns the following can be
done in the <code>api.initApplication</code> method. It will extend the bk_user table and the application can use new columns the same way as the already existing columns.
Using the birthday column we make &#39;age&#39; property automatically calculated and visible in the result, this is done by the internal method <code>api.processAccountRow</code> which
is registered as post process callback for the bk_user table. The computed property <code>age</code> will be returned because it is not present in the table definition
and all properties not defined and configured are passed as is.</p>
<p>The cleanup of the public columns is done by the <code>api.sendJSON</code> which is used by all API routes when ready to send data back to the client. If any post-process
hooks are registered and return data itself then it is the hook responsibility to cleanup non-public columns.</p>
<pre><code class="language-javascript">    db.describeTables({
        bk_user: {
            birthday: {},
            ssn: {},
            salary: { type: &quot;int&quot; },
            occupation: {},
            home_phone: {},
            work_phone: {},
        });

    app.configureWeb = function(options, callback)
    {
       db.setProcessRow(&quot;post&quot;, &quot;bk_user&quot;, this.processAccountRow);
       ...
       callback();
    }
    app.processAccountRow = function(req, row, options)
    {
       if (row.birthday) row.age = Math.floor((Date.now() - core.toDate(row.birthday))/(86400000*365));
    }
</code></pre>
<p>To define tables inside a module just provide a <code>tables</code> property in the module object, it will be picked up by database initialization automatically.</p>
<pre><code class="language-javascript">    const mod = {
        name: &quot;billing&quot;,
        tables: {
            invoices: {
                id: { type: &quot;int&quot;, primary: 1 },
                name: {},
                price: { type: &quot;real&quot; },
                mtime: { type: &quot;now&quot; }
            }
        }
    }
    module.exports = mod;

    // Run db setup once all the DB pools are configured, for example produce dynamic icon property
    // for each record retrieved
    mod.configureModule = function(options, callback)
    {
        db.setProcessRows(&quot;post&quot;, &quot;invoices&quot;, function(req, row, opts) {
         if (row.id) row.icon = &quot;/images/&quot; + row.id + &quot;.png&quot;;
     });
        callback();
    }
</code></pre>
<h2 id="tables-can-have-aliases">Tables can have aliases</h2>
<p>This is useful for easier naming conventions or switching to a different table name on the fly without changinbf the code,
access to the table by it is real name is always available.</p>
<p>For example:</p>
<pre><code>bksh -db-aliases-bk_user users

&gt; await db.aget(&quot;bk_user&quot;, { login: &quot;u1&quot; })
&gt; { login: &quot;u1&quot;, name: &quot;user&quot;, .... }

&gt; await db.aget(&quot;users&quot;, { login: &quot;u1&quot; })
&gt; { login: &quot;u1&quot;, name: &quot;user&quot;, .... }
</code></pre>
<h1 id="api-requests-handling">API requests handling</h1>
<p>All methods will put input parameters in the <code>req.query</code>, GET or POST.</p>
<p>One way to verify input values is to use <code>lib.toParams</code>, only specified parameters will be returned and converted according to
the type or ignored.</p>
<p>Example:</p>
<pre><code class="language-javascript">   var params = {
      test1: { id: { type: &quot;text&quot; },
               count: { type: &quot;int&quot; },
               email: { regexp: /^[^@]+@[^@]+$/ }
      }
   };

   api.app.all(&quot;/endpoint/test1&quot;, function(req, res) {
      const query = lib.toParams(req.query, params.test1);
      if (typeof query == &quot;string&quot;) return api.sendReply(res, 400, query);
      ...
   });
</code></pre>
<h1 id="example-of-todo-application">Example of TODO application</h1>
<p>Here is an example how to create simple TODO application using any database supported by the backend. It supports basic
operations like add/update/delete a record, show all records.</p>
<p>Create a file named <code>app.js</code> with the code below.</p>
<pre><code class="language-javascript">    const bkjs = require(&#39;backendjs&#39;);
    const api = bkjs.api;
    const lib = bkjs.lib;
    const app = bkjs.app;
    const db = bkjs.db;

    // Describe the table to store todo records
    db.describeTables({
       todo: {
           id: { type: &quot;uuid&quot;, primary: 1 },  // Store unique task id
           due: {},                           // Due date
           name: {},                          // Short task name
           descr: {},                         // Full description
           mtime: { type: &quot;now&quot; }             // Last update time in ms
       }
    });

    // API routes
    app.configureWeb = function(options, callback)
    {
        api.app.get(/^\/todo\/([a-z]+)$/, async function(req, res) {
           var options = api.getOptions(req);
           switch (req.params[0]) {
             case &quot;get&quot;:
                if (!req.query.id) return api.sendReply(res, 400, &quot;id is required&quot;);
                const rows = await db.aget(&quot;todo&quot;, { id: req.query.id }, options);
                api.sendJSON(req, null, rows);
                break;

             case &quot;select&quot;:
                options.noscan = 0; // Allow empty scan of the whole table if no query is given, disabled by default
                const rows = await db.aselect(&quot;todo&quot;, req.query, options);
                api.sendJSON(req, null, rows);
                break;

            case &quot;add&quot;:
                if (!req.query.name) return api.sendReply(res, 400, &quot;name is required&quot;);
                // By default due date is tomorrow
                if (req.query.due) req.query.due = lib.toDate(req.query.due, Date.now() + 86400000).toISOString();
                db.add(&quot;todo&quot;, req.query, options, (err, rows) =&gt; {
                    api.sendJSON(req, err, rows);
                });
                break;

            case &quot;update&quot;:
                if (!req.query.id) return api.sendReply(res, 400, &quot;id is required&quot;);
                const rows = await db.aupdate(&quot;todo&quot;, req.query, options);
                api.sendJSON(req, null, rows);
                break;

            case &quot;del&quot;:
                if (!req.query.id) return api.sendReply(res, 400, &quot;id is required&quot;);
                db.del(&quot;todo&quot;, { id: req.query.id }, options, (err, rows) =&gt; {
                    api.sendJSON(req, err, rows);
                });
                break;
            }
        });
        callback();
     }
     bkjs.server.start();
</code></pre>
<p>Now run it with an option to allow API access without an account:</p>
<pre><code>node app.js -log debug -web -api-allow-path /todo -db-create-tables
</code></pre>
<p>To use a different database, for example PostgresSQL(running localy) or DynamoDB(assuming EC2 instance),
all config parametetrs can be stored in the etc/config as well</p>
<pre><code>node app.js -log debug -web -api-allow-path /todo -db-pool dynamodb -db-dynamodb-pool default -db-create-tables
node app.js -log debug -web -api-allow-path /todo -db-pool pg -db-pg-pool default -db-create-tables
</code></pre>
<p>API commands can be executed in the browser or using <code>curl</code>:</p>
<pre><code>curl &#39;http://localhost:8000/todo?name=TestTask1&amp;descr=Descr1&amp;due=2015-01-01`
curl &#39;http://localhost:8000/todo/select&#39;
</code></pre>
<h1 id="backend-directory-structure">Backend directory structure</h1>
<p>When the backend server starts and no -home argument passed in the command line the backend makes its home environment in the <code>~/.bkjs</code> directory.
It is also possible to set the default home using BKJS_HOME environment variable.</p>
<p>The backend directory structure is the following:</p>
<ul>
<li><p><code>etc</code> - configuration directory, all config files are there</p>
<ul>
<li><p><code>etc/profile</code> - shell script loaded by the bkjs utility to customize env variables</p>
</li>
<li><p><code>etc/config</code> - config parameters, same as specified in the command line but without leading -, each config parameter per line:</p>
<p>  Example:</p>
<pre><code>  debug=1
  db-pool=dynamodb
  db-dynamodb-pool=http://localhost:9000
  db-pg-pool=postgresql://postgres@127.0.0.1/backend

  To specify other config file: bkjs shell -config-file file
</code></pre>
</li>
<li><p><code>etc/config.local</code> - same as the config but for the cases when local environment is different than the production or for dev specific parameters</p>
</li>
<li><p>on startup the following local config files will be loaded if present: <code>etc/config.runMode</code> and <code>etc/config.instance.tag</code>. These will be loaded after the main config but before config.local. The runMode is set to <code>dev</code> by default and can be changed with <code>-run-mode</code> config parameter, the instance tag is set with <code>-instance-tag</code> config parameter.</p>
</li>
<li><p>config files support sections that can be used for conditions, see <code>lib.configParse</code> description for details</p>
</li>
<li><p><code>etc/crontab</code> - jobs to be run with intervals, JSON file with a list of cron jobs objects:</p>
<p>  Example:</p>
<ol>
<li><p>Create file in ~/.backend/etc/crontab with the following contents:</p>
<pre><code> [ { &quot;cron&quot;: &quot;0 1 1 * * 1,3&quot;, &quot;job&quot;: { &quot;app.cleanSessions&quot;: { &quot;interval&quot;: 3600000 } } } ]
</code></pre>
</li>
<li><p>Define the function that the cron will call with the options specified, callback must be called at the end, create this app.js file</p>
<pre><code> var bkjs = require(&quot;backendjs&quot;);
 bkjs.app.cleanSessions = function(options, callback) {
      bkjs.db.delAll(&quot;session&quot;, { mtime: options.interval + Date.now() }, { ops: &quot;le&quot; }, callback);
 }
 bkjs.server.start()
</code></pre>
</li>
<li><p>Start the jobs queue and the web server at once</p>
<pre><code> bkjs master -jobs-workers 1 -jobs-cron
</code></pre>
</li>
</ol>
</li>
<li><p>etc/crontab.local - additional local crontab that is read after the main one, for local or dev environment</p>
</li>
<li><p><code>run-mode</code> and <code>db-pool</code> config parameters can be configured in DNS as TXT records, the backend on startup will try to resolve such records and use the value if not empty.
All params that  marked with DNS TXT can be configured in the DNS server for the domain where the backend is running, the config parameter name is
concatenated with the domain and queried for the TXT record, for example: <code>run-mode</code> parameter will be queried for run-mode.domain.name for TXT record type.</p>
</li>
</ul>
</li>
<li><p><code>modules</code> - loadable modules with specific functionality</p>
</li>
<li><p><code>images</code> - all images to be served by the API server, every subfolder represent naming space with lots of subfolders for images</p>
</li>
<li><p><code>var</code> - database files created by the server</p>
</li>
<li><p><code>tmp</code> - temporary files</p>
</li>
<li><p><code>web</code> - Web pages served by the static Express middleware</p>
</li>
</ul>
<h1 id="environment-variables">Environment variables</h1>
<p>On startup some env variable will be used for initial configuration:</p>
<ul>
<li>BKJS_HOME - home directory where to cd and find files, <code>-home</code> config parameter overrides it</li>
<li>BKJS_RUNMODE - initial run mode, <code>-run-mode</code> overrides it</li>
<li>BKJS_CONFFILE - config file to use instead of &#39;config&#39;, <code>-conf-file</code> overrides it</li>
<li>BKJS_PACKAGES - packags to preload, <code>-preload-packages</code> overrieds it</li>
<li>BKJS_CONFIG_ROLES - config roles to use, <code>-config-roles</code> overrides it</li>
<li>BKJS_DB_POOL - default db pool, <code>-db-pool</code> overrides it</li>
<li>BKJS_DB_CONFIG - config db pool, <code>-db-config</code> overrides it</li>
<li>BKJS_APPNAME - default app name</li>
<li>BKJS_TAG - initial instance tag, <code>-instance-tag</code> overrides it, it may be also overridden by AWS instance tag</li>
<li>BKJS_PORT - port for web server</li>
<li>BKJS_WSPORT - port for web sockets</li>
</ul>
<h1 id="cache-configurations">Cache configurations</h1>
<p>Database layer support caching of the responses using <code>db.getCached</code> call, it retrieves exactly one record from the configured cache, if no record exists it
will pull it from the database and on success will store it in the cache before returning to the client. When dealing with cached records, there is a special option
that must be passed to all put/update/del database methods in order to clear local cache, so next time the record will be retrieved with new changes from the database
and refresh the cache, that is <code>{ cached: true }</code> can be passed in the options parameter for the db methods that may modify records with cached contents. In any case
it is required to clear cache manually there is <code>db.clearCache</code> method for that.</p>
<p>Also there is a configuration option <code>-db-caching</code> to make any table automatically cached for all requests.</p>
<h2 id="local">Local</h2>
<p>If no cache is configured the local driver is used, it keeps the cache on the master process in the LRU pool and any worker or Web process
communicate with it via internal messaging provided by the <code>cluster</code> module. This works only for a single server.</p>
<h2 id="redis">Redis</h2>
<p>Set <code>ipc-client=redis://HOST[:PORT]</code> that points to the server running Redis server.</p>
<p>The config option <code>max_attempts</code> defines maximum number of times to reconnect before giving up. Any other <code>node-redis</code> module parameter can be passed as well in
the options or url, the system supports special parameters that start with <code>bk-</code>, it will extract them into options automatically.</p>
<p>For example:</p>
<pre><code>ipc-client=redis://host1?bk-max_attempts=3
ipc-client-backup=redis://host2
ipc-client-backup-options-max_attempts=3
</code></pre>
<h1 id="pub-sub-or-queue-configurations">PUB/SUB or Queue configurations</h1>
<h2 id="redis-system-bus">Redis system bus</h2>
<p>If configured all processes subscribe to it and listen for system messages, it must support PUB/SUB and does not need to be reliable. Websockets
in the API server also use the system bus to send broadcasts between multiple api instances.</p>
<pre><code>ipc-client-system=redis://
ipc-system-queue=system
</code></pre>
<h2 id="redis-queue">Redis Queue</h2>
<p>To configure the backend to use Redis for job processing set <code>ipc-queue=redis://HOST</code> where HOST is IP address or hostname of the single Redis server.
This driver implements reliable Redis queue, with <code>visibilityTimeout</code> config option works similar to AWS SQS.</p>
<p>Once configured, then all calls to <code>jobs.submitJob</code> will push jobs to be executed to the Redis queue, starting somewhere a backend master
process with <code>-jobs-workers 2</code> will launch 2 worker processes which will start pulling jobs from the queue and execute.</p>
<p>The naming convention is that any function defined as <code>function(options, callback)</code> can be used as a job to be executed in one of the worker processes.</p>
<p>An example of how to perform jobs in the API routes:</p>
<pre><code class="language-javascript">
    core.describeArgs(&#39;app&#39;, [
        { name: &quot;queue&quot;, descr: &quot;Queue for jobs&quot; },
    ]);
    app.queue = &quot;somequeue&quot;;

    app.processAccounts = function(options, callback) {
        db.select(&quot;bk_user&quot;, { type: options.type || &quot;user&quot; }, (err, rows) =&gt; {
          ...
          callback();
        });
    }

    api.all(&quot;/process/accounts&quot;, (req, res) =&gt; {
        jobs.submitJob({ job: { &quot;app.processAccounts&quot;: { type: req.query.type } } }, { queueName: app.queue }, (err) =&gt; {
            api.sendReply(res, err);
        });
    });
</code></pre>
<h2 id="sqs">SQS</h2>
<p>To use AWS SQS for job processing set <code>ipc-queue=https://sqs.amazonaws.com....</code>, this queue system will poll SQS for new messages on a worker
and after successful execution will delete the message. For long running jobs it will automatically extend visibility timeout if it is configured.</p>
<h2 id="local">Local</h2>
<p>The local queue is implemented on the master process as a list, communication is done via local sockets between the master and workers.
This is intended for a single server development purposes only.</p>
<h2 id="nats">NATS</h2>
<p>To use NATS (<a href="https://nats.io">https://nats.io</a>) configure a queue like ipc-queue-nats=nats://HOST:PORT, it supports broadcasts and job queues only, visibility timeout is
supported as well.</p>
<h2 id="rabbitmq">RabbitMQ</h2>
<p>To configure the backend to use RabbitMQ for messaging set <code>ipc-queue=amqp://HOST</code> and optionally <code>amqp-options=JSON</code> with options to the amqp module.
Additional objects from the config JSON are used for specific AMQP functions: { queueParams: {}, subscribeParams: {}, publishParams: {} }. These
will be passed to the corresponding AMQP methods: <code>amqp.queue, amqp.queue.subcribe, amqp.publish</code>. See AMQP Node.js module for more info.</p>
<h1 id="security-configurations">Security configurations</h1>
<h2 id="api-only">API only</h2>
<p>This is default setup of the backend when all API requests except must provide valid signature and all HTML, JavaScript, CSS and image files
are available to everyone. This mode assumes that Web development will be based on &#39;single-page&#39; design when only data is requested from the Web server and all
rendering is done using JavaScript. This is how the <code>examples/api/api.html</code> developers console is implemented, using JQuery-UI and Knockout.js.</p>
<p>To see current default config parameters run any of the following commands:</p>
<pre><code>    bkjs bkhelp | grep api-allow

    node -e &#39;require(&quot;backendjs&quot;).core.showHelp()&#39;
</code></pre>
<h2 id="secure-web-site-client-verification">Secure Web site, client verification</h2>
<p>This is a mode when the whole Web site is secure by default, even access to the HTML files must be authenticated. In this mode the pages must defined &#39;Backend.session = true&#39;
during the initialization on every html page, it will enable Web sessions for the site and then no need to sign every API request.</p>
<p>The typical client JavaScript verification for the html page may look like this, it will redirect to login page if needed,
this assumes the default path &#39;/public&#39; still allowed without the signature:</p>
<pre><code class="language-javascript">   &lt;link href=&quot;/css/bkjs.bundle.css&quot; rel=&quot;stylesheet&quot;&gt;
   &lt;script src=&quot;/js/bkjs.bundle.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
   &lt;script&gt;
    $(function () {
       bkjs.session = true;
       $(bkjs).on(&quot;bkjs.nologin&quot;, function() { window.location=&#39;/public/index.html&#39;; });
       bkjs.koInit();
   });
   &lt;/script&gt;
</code></pre>
<h2 id="secure-web-site-backend-verification">Secure Web site, backend verification</h2>
<p>On the backend side in your application app.js it needs more secure settings defined i.e. no html except /public will be accessible and
in case of error will be redirected to the login page by the server. Note, in the login page <code>bkjs.session</code> must be set to true for all
html pages to work after login without singing every API request.</p>
<ol>
<li>We disable all allowed paths to the html and registration:</li>
</ol>
<pre><code class="language-javascript">   app.configureMiddleware = function(options, callback) {
       this.allow.splice(this.allow.indexOf(&#39;^/$&#39;), 1);
       this.allow.splice(this.allow.indexOf(&#39;\\.html$&#39;), 1);
       callback();
   }
</code></pre>
<ol start="2">
<li>We define an auth callback in the app and redirect to login if the request has no valid signature, we check all html pages, all allowed html pages from the /public
will never end up in this callback because it is called after the signature check but allowed pages are served before that:</li>
</ol>
<pre><code class="language-javascript">   api.registerPreProcess(&#39;&#39;, /^\/$|\.html$/, (req, status, callback) =&gt; {
       if (status.status != 200) {
           status.status = 302;
           status.url = &#39;/public/index.html&#39;;
       }
       callback(status);
   });
</code></pre>
<h1 id="websockets-connections">WebSockets connections</h1>
<p>The simplest way is to configure <code>ws-port</code> to the same value as the HTTP port. This will run WebSockets server along the regular Web server.</p>
<p>In the browser the connection config is stored in the <code>bkjs.wsconf</code> and by default it connects to the local server on port 8000.</p>
<p>There are two ways to send messages via Websockets to the server from a browser:</p>
<ul>
<li><p>as urls, eg. <code>bkjs.wsSend(&#39;/project/update?id=1&amp;name=Test2&#39;)</code></p>
<p>In this case the url will be parsed and checked for access and authorization before letting it pass via Express routes. This method allows to
share the same route handlers between HTTP and Websockets requests, the handlers will use the same code and all responses will be sent back,
only in the Websockets case the response will arrived in the message listener (see an example below)</p>
</li>
</ul>
<pre><code class="language-javascript">    bkjs.wsConnect({ path: &quot;/project/ws?id=1&quot; });

    $(bkjs).on(&quot;bkjs.ws.message&quot;, (msg) =&gt; {
        switch (msg.op) {
        case &quot;/account/update&quot;:
            bkjs.wsSend(&quot;/account/ws/account&quot;);
            break;

        case &quot;/project/update&quot;:
            for (const p in msg.project) app.project[p] = msg.project[p];
            break;

        case &quot;/message/new&quot;:
            bkjs.showAlert(&quot;info&quot;, `New message: ${msg.msg}`);
            break;
        }
    });
</code></pre>
<ul>
<li><p>as JSON objects, eg. <code>bkjs.wsSend({ op: &quot;/project/update&quot;, project: { id: 1, name: &quot;Test2&quot; } })</code></p>
<p>  In this case the server still have to check for access so it treats all JSON messages as coming from the path which was used during the connect,
  i.e. the one stored in the <code>bkjs.wsconf.path</code>. The Express route handler for this path will receive all messages from Websocket clients, the response will be
  received in the event listener the same way as for the first use case.</p>
</li>
</ul>
<pre><code class="language-javascript">    // Notify all clients who is using the project being updated
    api.app.all(&quot;/project/ws&quot;, (req, res) =&gt; {
        switch (req.query.op) {
        case &quot;/project/update&quot;:
           //  some code ....
           api.wsNotify({ query: { id: req.query.project.id } }, { op: &quot;/project/update&quot;, project: req.query.project });
           break;
       }
       res.send(&quot;&quot;);
    });
</code></pre>
<p>In any case all Websocket messages sent from the server will arrive in the event handler and must be formatted properly in order to distinguish what is what, this is
the application logic. If the server needs to send a message to all or some specific clients for example due to some updates in the DB, it must use the
<code>api.wsNotify</code> function.</p>
<pre><code class="language-javascript">    // Received a new message for a user from external API service, notify all websocket clients by account id
    api.app.post(&quot;/api/message&quot;, (req, res) =&gt; {
        ....
        ... processing logic
        ....
        api.wsNotify({ account_id: req.query.uid }, { op: &quot;/message/new&quot;, msg: req.query.msg });
    });
</code></pre>
<h1 id="versioning">Versioning</h1>
<p>There is no ready to use support for different versions of API because there is no just one solution that satisfies all applications. But there are
tools ready to use that will allow to implement such versioning system in the backend. Some examples are provided below:</p>
<ul>
<li><p>Fixed versions
This is similar to AWS version system when versions are fixed and changed not very often. A client can specify the core version
using <code>bk-version</code> header. When a request is parsed and the version is provided it will be set in the request options object as <code>apiVersion</code>.</p>
<p>All API routes are defined using Express middleware and one of the possible ways of dealing with different versions can look like this, by
appending version to the command it is very simple to call only changed API code.</p>
</li>
</ul>
<pre><code class="language-javascript">    api.all(/\/domain\/(get|put|del)/, function(req, res) {
        var options = api.getOptions(req);
        var cmd = req.params[0];
        if (options.apiVersion) cmd += &quot;/&quot; + options.apiVersion;
        switch (cmd) {
        case &quot;get&quot;:
            break;

        case &quot;get/2015-01-01&quot;:
            break;

        case &quot;put&quot;:
            break;

        case &quot;put/2015-02-01&quot;:
            break;

        case &quot;del&quot;
            break;
        }
    });
</code></pre>
<ul>
<li><p>Application semver support
For cases when applications support Semver kind of versioning and it may be too many releases the method above still can be used while the number of versions is
small, once too many different versions with different minor/patch numbers, it is easier to support greater/less comparisons.</p>
<p>The application version <code>bk-app</code> can be supplied in the query or as a header or in the user-agent HTTP header which is the easiest case for mobile apps.
In the middlware, the code can look like this:</p>
</li>
</ul>
<pre><code class="language-javascript">    var options = api.getOptions(req);
    var version = lib.toVersion(options.appVersion);
    switch (req.params[0]) {
    case &quot;get&quot;:
        if (version &lt; lib.toVersion(&quot;1.2.5&quot;)) {
            res.json({ id: 1, name: &quot;name&quot;, description: &quot;descr&quot; });
            break;
        }
        if (version &lt; lib.toVersion(&quot;1.1&quot;)) {
            res.json([id, name]);
            break;
        }
        res.json({ id: 1, name: &quot;name&quot;, descr: &quot;descr&quot; });
        break;
    }
</code></pre>
<p>The actual implementation can be modularized, split into functions, controllers.... there are no restrictions how to build the working backend code,
the backend just provides all necessary information for the middleware modules.</p>
<h1 id="the-backend-tool-bkjs">The backend tool: bkjs</h1>
<p>The purpose of the <code>bkjs</code> shell script is to act as a helper tool in configuring and managing the backend environment
and as well to be used in operations on production systems. It is not required for the backend operations and provided as a convenience tool
which is used in the backend development and can be useful for others running or testing the backend.</p>
<p>Run <code>bkjs help</code> to see description of all available commands.</p>
<p>The tool is multi-command utility where the first argument is the command to be executed with optional additional arguments if needed.</p>
<p>On Linux, when started the bkjs tries to load and source the following global config files:</p>
<pre><code>    /etc/conf.d/bkjs
    /etc/sysconfig/bkjs
</code></pre>
<p>Then it try to source all local config files:</p>
<pre><code>    $HOME/.env
    $BKJS_HOME/etc/profile
    $BKJS_HOME/etc/profile.local
</code></pre>
<p>Any of the following config files can redefine any environment variable thus pointing to the correct backend environment directory or
customize the running environment, these should be regular shell scripts using bash syntax.</p>
<p>To check all env variables inside bkjs just run the command <code>bkjs env</code></p>
<p>The tool provides some simple functions to parse comamndline arguments,
the convention is that argument name must start with a single dash followed by a value.</p>
<ul>
<li><p><code>get_arg(name, dflt)</code> - returns the value for the arg <code>name</code> or default value if specified</p>
</li>
<li><p><code>get_flag(name, dflt)</code> - returns 1 if there is a command lione arg with the <code>name</code> or default value
Example:</p>
<pre><code>bkjs shell -log debug
</code></pre>
</li>
<li><p><code>concat_arg(name, value)</code> - returns concatenated value from the arg and provided value, to combine values from multiple sources
Example:</p>
<pre><code>ssh=$(concat_arg -ssh $BKJS_SSH_ARGS)
</code></pre>
</li>
<li><p><code>get_json(file, name, dflt, realpath)</code> - returns a value from the json file, <code>name</code> can be path deep into object, <code>realpath</code> flag if nonempty will treat all values as paths and convert each into actual real path (this is used by the internal web bundler)</p>
</li>
<li><p><code>get_json_flat</code> - similar to get_json but property names are flattened for deep access
Example:</p>
<pre><code>$(get_json package.json config.sync.path)
$(get_json package.json name)
</code></pre>
</li>
<li><p><code>get_all_args(except)</code> - returns all args not present in the <code>except</code> list, this is to pass all arguments to other script, for command development
 Example:</p>
<pre><code>The script is called: `bkjs cmd1 -skip 1 -filter 2 -log 3`

Your command handler process -skip but must pass all other args to another except -skip

cmd1)
  skip=$(get_arg -skip)
  ...
  other_script $(get_all_args &quot;-skip&quot;)
  ;;
</code></pre>
</li>
</ul>
<h2 id="extending-bkjs">Extending bkjs</h2>
<p>The utility is extended via external scripts that reside in the <code>tools/</code> folders.</p>
<p>When bkjs is running it treats the first arg as a command:</p>
<ul>
<li><code>$BKJS_CMD</code> set to the whole comamnd</li>
<li><code>$BKJS_MODULE</code> set to the first part of the command split by dash, i.e. command module</li>
</ul>
<p>if no internal commands match it starts loading external scripts that start with <code>bkjs-$BKJS_MODULE</code> from the following directories:</p>
<ul>
<li>via <code>-tools</code> command line argument if provided</li>
<li>$(pwd)/tools</li>
<li><code>$BKJS_TOOLS</code>,</li>
<li><code>$BKJS_HOME/tools</code></li>
<li><code>$BKJS_DIR/tools</code></li>
</ul>
<p><code>BKJS_DIR</code> always points to the backendjs installation directory, thus internal backendjs commands will be checked first.</p>
<p><code>BLKJS_TOOLS</code> env variable may contain a list of directories separated by <code>spaces</code>, this variable or command line arg <code>-tools</code> is the way to add
custom commands to bkjs. BKJS_TOOLS var is usually set in one of the profile config files mentioned above.</p>
<p>Example of a typical bkjs command:</p>
<p>We need to set BKJS_TOOLS to point to our package(s), on Darwin add it to ~/.bkjs/etc/profile as</p>
<pre><code>BKJS_TOOLS=&quot;$HOME/src/node-pkg/tools&quot;
</code></pre>
<p>Create a file <code>/Users/user/src/node-pkg/tools/bkjs-cmd</code></p>
<pre><code>#!/bin/sh

case &quot;$BKJS_CMD&quot; in
  cmd)
   arg1=$(get_arg -arg1)
   arg2=$(get_arg -arg1 1)
   [ -z $arg1 ] &amp;&amp; echo &quot;-arg1 is required&quot; &amp;&amp; exit 1
   ...
   exit

  cmd-all)
   ...
   exit
   ;;

  help)
   echo &quot;&quot;
   echo &quot;$0 cmd -arg1 ARG -arg2 ARG ...&quot;
   echo &quot;$0 cmd-all ....&quot;
   ;;
esac
</code></pre>
<p>Now calling <code>bkjs cmd</code> or <code>bkjs cmd-all</code> will use the new bkjs-cmd file</p>
<h1 id="web-development-notes">Web development notes</h1>
<p>Then run the dev build script to produce web/js/bkjs.bundle.js and web/css/bkjs.bundle.css</p>
<pre><code>cd node_modules/backendjs &amp;&amp; npm run devbuild
</code></pre>
<p>Now instead of including a bunch of .js or css files in the html pages it only needs /js/bkjs.bundle.js and /css/bkjs.bundle.css. The configuration is in the
package.json file.</p>
<p>The list of files to be used in bundles is in the package.json under <code>config.bundles</code>.</p>
<p>To enable auto bundler in your project just add to the local config <code>~/.bkjs/etc/config.local</code> a list of directories to be
watched for changes. For example adding these lines to the local config will enable the watcher and bundle support</p>
<pre><code>watch-web=web/js,web/css,$HOME/src/js,$HOME/src/css
watch-ignore=.bundle.(js|css)$
watch-build=bkjs bundle -dev
</code></pre>
<p>The simple script below allows to build the bundle and refresh Chrome tab automatically, saves several clicks:</p>
<pre><code>#!/bin/sh
bkjs bundle -dev -file $2
[ &quot;$?&quot; != &quot;0&quot; ] &amp;&amp; exit
osascript -e &quot;tell application \&quot;Google Chrome\&quot; to reload (tabs of window 1 whose URL contains \&quot;$1\&quot;)&quot;
</code></pre>
<p>To use it call this script instead in the config.local:</p>
<pre><code>watch-build=bundle.sh /website
</code></pre>
<p>NOTE: Because the rebuild happens while the watcher is running there are cases like the server is restarting or pulling a large update from the
repository when the bundle build may not be called or called too early. To force rebuild run the command:</p>
<pre><code>bkjs bundle -dev -all -force
</code></pre>
<h1 id="deployment-use-cases">Deployment use cases</h1>
<h2 id="aws-instance-setup-with-node-and-backendjs">AWS instance setup with node and backendjs</h2>
<ul>
<li><p>start new AWS instance via AWS console, use Alpine 3.19 or later</p>
</li>
<li><p>login as <code>alpine</code></p>
</li>
<li><p>install commands</p>
<pre><code>  doas apk add git
  git clone --depth=1 https://github.com/vseryakov/backendjs.git
  doas backendjs/bkjs setup-ec2
  doas reboot
</code></pre>
</li>
<li><p>now login as <code>ec2-user</code></p>
</li>
</ul>
<p>NOTE: if running behind a Load balancer and actual IP address is needed set Express option in the command line <code>-api-express-options {&quot;trust%20proxy&quot;:1}</code>. In the config file
replacing spaces with %20 is not required.</p>
<h2 id="aws-provisioning-examples">AWS Provisioning examples</h2>
<h3 id="make-an-ami">Make an AMI</h3>
<p>On the running machine which will be used for an image:</p>
<pre><code>bksh -aws-create-image -no-reboot
</code></pre>
<p>Use an instance by tag for an image:</p>
<pre><code>bksh -aws-create-image -no-reboot -instance-id `bkjs ec2-show -tag api -fmt id | head -1`
</code></pre>
<h3 id="update-route53-with-all-ips-from-running-instances">Update Route53 with all IPs from running instances</h3>
<pre><code>bksh -aws-set-route53 -name elasticsearch.ec-internal -filter elasticsearch
</code></pre>
<h2 id="configure-http-port">Configure HTTP port</h2>
<p>The first thing when deploying the backend into production is to change API HTTP port, by default is is 8000, but we would want port 80 so regardless
how the environment is setup it is ultimately 2 ways to specify the port for HTTP server to use:</p>
<ul>
<li><p>config file</p>
<p>The config file is always located in the etc/ folder in the backend home directory, how the home is specified depends on the system but basically it can be
defined via command line arguments as <code>-home</code> or via environment variables when using bkjs. See bkjs documentation but on AWS instances created with bkjs
<code>setup-server</code> command, for non-standard home use <code>/etc/sysconfig/bkjs</code> profile, specify <code>BKJS_HOME=/home/backend</code> there and the rest will be taken care of</p>
</li>
<li><p>command line arguments</p>
<p>When running node scripts which use the backend, just specify <code>-home</code> command line argument with the directory where your backend should be and the backend will use it</p>
<p>Example:</p>
<pre><code>  node app.js -home $HOME -port 80
</code></pre>
</li>
<li><p>config database</p>
<p>If <code>-db-config</code> is specified in the command line or <code>db-config=</code> in the local config file, this will trigger loading additional
config parameters from the specified database pool, it will load all records from the <code>bk_config</code> table on that db pool. Using the database to store
configuration make it easier to maintain dynamic environment for example in case of auto scaling or launching on demand, this way
a new instance will query current config from the database and this eliminates supporting text files and distributing them to all instances.</p>
<p>The config database is refreshed from time to time acording to the <code>db-config-interval</code> parameter, also all records with <code>ttl</code> property in the bk_config
will be pulled every ttl interval and updated in place.</p>
</li>
<li><p>DNS records
Some config options may be kept in the DNS TXT records and every time a instance is started it will query the local DNS for such parameters. Only a small subset of
all config parameters support DNS store. To see which parameters can be stored in the DNS run <code>bkjs show-help</code> and look for &#39;DNS TXT configurable&#39;.</p>
</li>
</ul>
<h1 id="backend-library-development-mac-os-x-developers-">Backend library development (Mac OS X, developers)</h1>
<ul>
<li><p><code>git clone https://github.com/vseryakov/backendjs.git</code> or <code>git clone git@github.com:vseryakov/backendjs.git</code></p>
</li>
<li><p>cd backendjs</p>
</li>
<li><p>if Node.js is already installed skip to the next section</p>
<ul>
<li><p>to install binary release run the command, it will install it into ~/.bkjs on Darwin</p>
<pre><code>bkjs install-node
# To install into different path
bkjs install-node -home ~/.local
</code></pre>
</li>
<li><p><strong>Important</strong>: Add NODE_PATH=$BKJS_HOME/lib/node_modules to your environment in .profile or .bash_profile so
node can find global modules, replace $BKJS_HOME with the actual path unless this variable is also set in the .profile</p>
</li>
</ul>
</li>
<li><p>to install all dependencies and make backendjs module and bkjs globally available:</p>
<p>  <code>npm link backendjs</code></p>
</li>
<li><p>to run local server on port 8000 run command:</p>
<p>  <code>bkjs web</code></p>
</li>
<li><p>to start the backend in command line mode, the backend environment is prepared and initialized including all database pools.
 This command line access allows you to test and run all functions from all modules of the backend without running full server
 similar to Node.js REPL functionality. All modules are accessible from the command line.</p>
<pre><code>$ ./bkjs shell
&gt; core.version
&#39;0.70.0&#39;
&gt; logger.setLevel(&#39;info&#39;)
</code></pre>
</li>
</ul>
<h1 id="simple-testing-facility">Simple testing facility</h1>
<p>Included a simple testing tool, it is used for internal bkjs testing but can be used for other applications as well.</p>
<p>The convention is to create a test file in the tests/ folder, each test file can define one or more test
functions named in the form <code>tests.test_NAME</code> where NAME is any custom name for the test, for example:</p>
<p>File <code>tests/example.js</code>:</p>
<pre><code class="language-javascript">tests.test_example = function(callback)
{
    expect(1 == 2, &quot;expect 1 eq 2&quot;)

    callback();
}
</code></pre>
<p>Then to run all tests</p>
<pre><code>bkjs test-all
</code></pre>
<p>More details are in the documentation or <code>doc.html</code></p>
<h1 id="design-considerations">Design considerations</h1>
<p>While creating Backendjs there were many questions and issues to be considered, some I was able to implement, some still not. Below are the thoughts that
might be useful when designing, developing or choosing the API platform:</p>
<ul>
<li>purpose of the API:<ul>
<li>to expose some parts of the existing system to external apps, users...</li>
<li>to make it the only way to access services</li>
<li>to complement another system</li>
</ul>
</li>
<li>scalability considerations:<ul>
<li>unlimited/uncontrolled access like mobile, web, more users the better</li>
<li>enterprise level, controlled growth</li>
<li>not to be horizontally scalable, just vertically</li>
</ul>
</li>
<li>security:<ul>
<li>support authentication, users, accounts, profiles...</li>
<li>just for robots, limited by api key only</li>
<li>signed requests only</li>
<li>support all access, web, mobile, desktop</li>
<li>user access controls, how to distinguish users, grant access to only parts of the API</li>
<li>ability to run custom/specific filters during processing API requests, independently and ability to extend the app without rewriting/rebuilding the whole system</li>
<li>third party authentication, OAUTH, user mapping</li>
</ul>
</li>
<li>platform/framework:<ul>
<li>one for all, same language/SDK/framework to cover all aspects</li>
<li>multiple languages/frameworks for different tasks, then how to integrate, how to communicate, share code</li>
<li>availability of the third party modules, libraries</li>
<li>support, forums, docs, how easy to learn for new developers</li>
<li>modularity, ability to develop by multiple developers, teams</li>
<li>flexibility in extending, how simple/easy to add custom stuff</li>
<li>maintenance, support,how easy to scale, change, replace parts</li>
</ul>
</li>
<li>database layer:<ul>
<li>one central database for everything</li>
<li>multiple database for different parts of the system according to scalability/other requirements</li>
<li>switch databases behind the scene in order to scale, adding to features, easier to maintain</li>
<li>caching, needs to be independent from other parts and easily enabled/disabled for different components preferably via config</li>
<li>to have or not ORM</li>
</ul>
</li>
<li>process management, easy to deploy, monitor</li>
<li>logging, metrics, profiling</li>
<li>agnostic to the frontends or to be included with some kind of MVC/server based tools</li>
<li>ability to support simple Web development for simple web pages without installing/supporting general purpose tools like Apache/PHP/nginx</li>
</ul>
<h1 id="api-endpoints-provided-by-the-backend">API endpoints provided by the backend</h1>
<p>All API endpoints are optional and can be disabled or replaced easily. By default the naming convention is:</p>
<pre><code> /namespace/command[/subname[/subcommand]]
</code></pre>
<p>Any HTTP methods can be used because its the command in the URL that defines the operation. The payload can be url-encoded query
parameters or JSON or any other format supported by any particular endpoint. This makes the backend universal and usable with any
environment, not just a Web browser. Request signature can be passed in the query so it does not require HTTP headers at all.</p>
<h2 id="authentication-and-sessions">Authentication and sessions</h2>
<h3 id="signature">Signature</h3>
<p>All requests to the API server must be signed with account login/secret pair.</p>
<ul>
<li>The algorithm how to sign HTTP requests (Version 1, 2):<ul>
<li>Split url to path and query parameters with &quot;?&quot;</li>
<li>Split query parameters with &quot;&amp;&quot;</li>
<li>&#39;&#39;&#39;ignore parameters with empty names&#39;&#39;&#39;</li>
<li>&#39;&#39;&#39;Sort&#39;&#39;&#39; list of parameters alphabetically</li>
<li>Join sorted list of parameters with &quot;&amp;&quot;<ul>
<li>Make sure all + are encoded as %2B</li>
</ul>
</li>
<li>Form canonical string to be signed as the following:<ul>
<li>Line1: The signature version</li>
<li>Line2: The application tag or other opaque data</li>
<li>Line3: The login name</li>
<li>Line4: The HTTP method(GET), followed by a newline.</li>
<li>Line5: The host name, lowercase, followed by a newline.</li>
<li>Line6: The request URI (/), followed by a newline.</li>
<li>Line7: The sorted and joined query parameters as one string, followed by a newline.</li>
<li>Line8: The expiration value in milliseconds, required, followed by a newline</li>
<li>Line9: The Content-Type HTTP header, lowercase, optional, followed by a newline</li>
<li>Line10: The SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query parameters</li>
</ul>
</li>
<li>Computed HMAC-SHA1 digest from the canonical string and encode it as BASE64 string, preserve trailing = if any</li>
<li>Form the signature HTTP header as the following:<ul>
<li>The header string consist of multiple fields separated by pipe |<ul>
<li>Field1: Signature version:<ul>
<li>version 1, obsolete, do not use first 3 lines in the canonical string</li>
<li>version 2,3 to be used in session cookies only</li>
<li>version 4</li>
</ul>
</li>
<li>Field2: Application tag or other app specific data</li>
<li>Field3: account login or whatever it might be in the login column</li>
<li>Field4: HMAC-SHA digest from the canonical string, version 1 uses SHA1, other SHA256</li>
<li>Field5: expiration value in milliseconds, same as in the canonical string</li>
<li>Field6: SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query parameters</li>
<li>Field7: empty, reserved for future use</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The resulting signature is sent as HTTP header <code>bk-signature</code> or in the header specified by the <code>api-signature-name</code> config parameter.</p>
<p>For JSON content type, the method must be POST and no query parameters specified, instead everything should be inside the JSON object
which is placed in the body of the request. For additional safety, SHA1 checksum of the JSON payload can be calculated and passed in the signature,
this is the only way to ensure the body is not modified when not using query parameters.</p>
<p>See <a href="https://github.com/vseryakov/backendjs/blob/master/web/js/bkjs.js">web/js/bkjs.js</a> function <code>bkjs.createSignature</code> or
<a href="https://github.com/vseryakov/backendjs/blob/master/api.js">api.js</a> function <code>api.createSignature</code> for the JavaScript implementations.</p>
<p>There is also native iOS implementation <a href="https://raw.githubusercontent.com/vseryakov/backendjs-ios/master/BKjs.m">Bkjs.m</a>.</p>
<h3 id="authentication-api">Authentication API</h3>
<ul>
<li><p><code>/auth</code></p>
<p> This API request returns the current user record from the <code>bk_user</code> table if the request is verified and the signature provided
 is valid. If no signature or it is invalid the result will be an error with the corresponding error code and message.</p>
<p> By default this endpoint is secured, i.e. requires a valid signature.</p>
<p> Parameters:</p>
<ul>
<li><code>_session=1</code> - if the call is authenticated a cookie with the session signature is returned, from now on
 all requests with such cookie will be authenticated, the primary use for this is Web apps</li>
</ul>
</li>
<li><p><code>/login</code></p>
<p> Same as the /auth but it uses secret for user authentication, this request does not need a signature, just simple
 login and secret query parameters to be sent to the backend. This must be sent over SSL.</p>
<p> Parameters:</p>
<ul>
<li><code>login</code> - account login</li>
<li><code>secret</code> - account secret</li>
<li><code>_session=1</code> - same as in /auth request</li>
</ul>
<p> On successful login, the result contains full account record including the secret, this is the only time when the secret is returned back</p>
<p> Example:</p>
</li>
</ul>
<pre><code class="language-javascript">    $.ajax({ url: &quot;/login?login=test123&amp;secret=test123&amp;_session=1&quot;,
        success: function(json, status, xhr) { console.log(json) }
    });

    &gt; { id: &quot;XXXX...&quot;, name: &quot;Test User&quot;, login: &quot;test123&quot;, ...}
</code></pre>
<ul>
<li><p><code>/logout</code></p>
<p> Logout the current user, clear session cookies if exist. For pure API access with the signature this will not do anything on the backend side.</p>
</li>
</ul>
<h2 id="accounts">Accounts</h2>
<p>The accounts API manages accounts and authentication, it provides basic user account features with common fields like email, name, address.</p>
<ul>
<li><p><code>/account/get</code></p>
<p>Returns information about the current account, all account columns are returned except the secret and other table columns with the property <code>priv</code></p>
<p>Response:</p>
<pre><code>      { &quot;id&quot;: &quot;57d07a4e28fc4f33bdca9f6c8e04d6c3&quot;,
      &quot;name&quot;: &quot;Test User&quot;,
      &quot;mtime&quot;: 1391824028,
      &quot;login&quot;: &quot;testuser&quot;,
      &quot;type&quot;: [&quot;user&quot;],
      }
</code></pre>
<p>How to make an account as admin</p>
<pre><code>      # Run backend shell
      bkjs shell

      # Update record by login
      &gt; db.update(&quot;bk_user&quot;, { login: &#39;login@name&#39;, type: &#39;admin&#39; });
</code></pre>
</li>
<li><p><code>/account/update</code></p>
<p>Update current account with new values, the parameters are columns of the table <code>bk_user</code>, only columns with non empty values will be updated.</p>
<p>Example:</p>
<pre><code>      /account/update?name=New%2BName
</code></pre>
</li>
</ul>
<h3 id="health-enquiry">Health enquiry</h3>
<p>When running with AWS load balancer there should be a url that a load balancer polls all the time and this must be very quick and lightweight request. For this
purpose there is an API endpoint <code>/ping</code> that just responds with status 200. It is open by default in the default <code>api-allow-path</code> config parameter.</p>
<h2 id="data">Data</h2>
<p>The data API is a generic way to access any table in the database with common operations, as oppose to the any specific APIs above this API only deals with
one table and one record without maintaining any other features like auto counters, cache...</p>
<p><em>Because it exposes the whole database to anybody who has a login it is a good idea to disable this endpoint in the production or provide access callback that verifies
who can access it.</em></p>
<ul>
<li><p>To disable this endpoint completely in the config: <code>deny-modules=bk_data</code></p>
</li>
<li><p>To allow admins to access it only in the config: <code>api-allow-admin=^/data</code></p>
</li>
<li><p>To allow admins to access it only:</p>
<pre><code>api.registerPreProcess(&#39;GET&#39;, &#39;/data&#39;, function(req, status, cb) { if (req.account.type != &quot;admin&quot;) return cb({ status: 401, message: &#39;access denied&#39; }; cb(status)); });
</code></pre>
</li>
</ul>
<p>This is implemented by the <code>data</code> module from the core.</p>
<ul>
<li><p><code>/data/columns</code></p>
</li>
<li><p><code>/data/columns/TABLE</code>
Return columns for all tables or the specific TABLE</p>
</li>
<li><p><code>/data/keys/TABLE</code>
Return primary keys for the given TABLE</p>
</li>
<li><p><code>/data/(select|search|list|get|add|put|update|del|incr|replace)/TABLE</code>
Perform database operation on the given TABLE, all options for the <code>db</code> functiobns are passed as query parametrrs prepended with underscore,
regular parameters are the table columns.</p>
<p>By default the API does not allow table scans without a condition to avoid expensive and long queries, to enable a scan pass <code>_noscan=0</code>.
For this to work the Data API must be configured as unsecure in the config file using the parameter <code>api-unsecure=data</code>.</p>
<p>Some tables like messages and connections perform data convertion before returning the results, mostly splitting combined columns like type into
separate fields. To return raw data pass the parameter <code>_noprocessrows=1</code>.</p>
<p>Example:</p>
<pre><code>  /data/get/bk_user?login=12345
  /data/update/bk_user?login=12345&amp;name=Admin
  /data/select/bk_user?name=john&amp;_ops=name,gt&amp;_select=name,email
  /data/select/bk_user?_noscan=0&amp;_noprocessrows=1
</code></pre>
</li>
</ul>
<h2 id="system-api">System API</h2>
<p>The system API returns information about the backend statistics, allows provisioning and configuration commands and other internal maintenance functions. By
default is is open for access to all users but same security considerations apply here as for the Data API.</p>
<p>This is implemented by the <code>system</code> module from the core. To enable this functionality specify <code>-preload-modules=bk_system</code>.</p>
<ul>
<li><p><code>/system/restart</code>
  Perform restart of the Web processes, this will be done gracefully, only one Web worker process will be restarting while the other processes will keep
  serving requests. The intention is to allow code updates on live systems without service interruption.</p>
</li>
<li><p><code>/system/cache/(init|stats|keys|get|set|put|incr|del|clear)</code>
  Access to the caching functions</p>
</li>
<li><p><code>/system/config/(init)</code>
  Access to the config functions</p>
</li>
<li><p><code>/system/msg/(init|send)</code>
  Access to the messaging functions</p>
</li>
<li><p><code>/system/jobs/(send)</code>
  Access to the jobs functions</p>
</li>
<li><p><code>/system/queue/(init|publish)</code>
  Access to the queue functions</p>
</li>
<li><p><code>/system/params/get</code>
  Return all config parameters applied from the config file(s) or remote database.</p>
</li>
<li><p><code>/system/stats/get</code>
Database pool statistics and other diagnostics</p>
<ul>
<li>latency - how long a pending request waits in queue at this moment</li>
<li>busy - how many busy error responses have been returned so far</li>
<li>pool - database metrics<ul>
<li>response - stats about how long it takes between issuing the db request and till the final moment all records are ready to be sent to the client</li>
<li>queue - stats about db requests at any given moment queued for the execution</li>
<li>cache - db cache response time and metrics</li>
</ul>
</li>
<li>api - Web requests metrics, same structure as for the db pool metrics</li>
<li>url - metrics per url endpoints</li>
</ul>
<p>Individual sub-objects:</p>
<ul>
<li>meter - Things that are measured as events / interval.<ul>
<li>rmean: The average rate since the meter was started.</li>
<li>rcnt: The total of all values added to the meter.</li>
<li>rate: The rate of the meter since the last toJSON() call.</li>
<li>r1m: The rate of the meter biased towards the last 1 minute.</li>
<li>r5m: The rate of the meter biased towards the last 5 minutes.</li>
<li>r15m: The rate of the meter biased towards the last 15 minutes.</li>
</ul>
</li>
<li>queue or histogram - Keeps a reservoir of statistically relevant values biased towards the last 5 minutes to explore their distribution<ul>
<li>hmin: The lowest observed value.</li>
<li>mmax: The highest observed value.</li>
<li>hsum: The sum of all observed values.</li>
<li>hvar: The variance of all observed values.</li>
<li>hmean: The average of all observed values.</li>
<li>hdev: The standard deviation of all observed values.</li>
<li>hcnt: The number of observed values.</li>
<li>hmed: median, 50% of all values in the reservoir are at or below this value.</li>
<li>hp75: See median, 75% percentile.</li>
<li>hp95: See median, 95% percentile.</li>
<li>hp99: See median, 99% percentile.</li>
<li>hp999: See median, 99.9% percentile.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="author">Author</h1>
<p>  Vlad Seryakov</p>
<p>Check out the <a href="http://bkjs.io">Documentation</a> for more details.</p>

<h2 id="module-api">Module: api</h2>
<p>  HTTP API to the server from the clients, this module implements the basic HTTP(S) API functionality with some common features. The API module
  incorporates the Express server which is exposed as api.app object, the master server spawns Web workers which perform actual operations and monitors
  the worker processes if they die and restart them automatically. How many processes to spawn can be configured via <code>-server-max-workers</code> config parameter.</p>
<p>  When an HTTP request arrives it goes over Express middleware, but before processing any registered routes there are several steps performed:</p>
<ul>
<li>the <code>req</code> object which is by convention is a Request object, assigned with common backend properties to be used later:<ul>
<li>account - an empty object which will be filled after by signature verification method, if successful, properties from the <code>bk_user</code> table will be set</li>
<li>options - an object with internal state and control parameters. Every request always has an options object attached very
early with some properties always present:<ul>
<li>ip - cached IP address</li>
<li>host - cached host header from the request</li>
<li>path - parsed request url path</li>
<li>apath - an array with the path split by /</li>
<li>secure - if the request is encrypted, like https</li>
<li>appName - parsed app version provided in the header or user agent</li>
<li>appVersion - parsed app version from the header or user agent</li>
<li>appTimezone - milliseconds offset from the UTC provided in the header by the app</li>
<li>appLocale - a language provided in the header</li>
<li>apiVersion - app specific version provided in the header</li>
</ul>
</li>
</ul>
</li>
<li>access verification, can the request be satisfied without proper signature, i.e. is this a public request</li>
<li>autherization, check the signature and other global or account specific checks</li>
<li>when a API route found by the request url, it is called as any regular Connect middlware<ul>
<li>if there are registered pre processing callback they will be called during access or autherization phases</li>
<li>if inside the route a response was returned using <code>api.sendJSON</code> method, registered post process callbacks will be called for such response</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>api-images-url</code>, descr: &quot;URL where images are stored, for cases of central image server(s), must be full URL with optional path&quot;</li>
<li><code>api-images-s3</code>, descr: &quot;S3 bucket name where to store and retrieve images&quot;</li>
<li><code>api-images-raw</code>, type: &quot;bool&quot;, descr: &quot;Return raw urls for the images, requires images-url to be configured. The path will reflect the actual 2 level structure and account id in the image name&quot;</li>
<li><code>api-images-s3-options</code>, type: &quot;json&quot;, logger: &quot;warn&quot;, descr: &quot;S3 options to sign images urls, may have expires:, key:, secret: properties&quot;</li>
<li><code>api-images-ext</code>, descr: &quot;Default image extension to use when saving images&quot;</li>
<li><code>api-images-mod</code>, descr: &quot;Images scaling module, sharp&quot;</li>
<li><code>api-files-raw</code>, type: &quot;bool&quot;, descr: &quot;Return raw urls for the files, requires files-url to be configured. The path will reflect the actual 2 level structure and account id in the file name&quot;</li>
<li><code>api-files-url</code>, descr: &quot;URL where files are stored, for cases of central file server(s), must be full URL with optional path&quot;</li>
<li><code>api-files-s3</code>, descr: &quot;S3 bucket name where to store files uploaded with the File API&quot;</li>
<li><code>api-max-request-queue</code>, type: &quot;number&quot;, min: 0, descr: &quot;Max number of requests in the processing queue, if exceeds this value server returns too busy error&quot;</li>
<li><code>api-no-access-log</code>, type: &quot;bool&quot;, descr: &quot;Disable access logging in both file or syslog&quot;</li>
<li><code>api-access-log-file</code>, descr: &quot;File for access logging&quot;</li>
<li><code>api-access-log-level</code>, type: &quot;int&quot;, descr: &quot;Syslog level priority, default is local5.info, 21 * 8 + 6&quot;</li>
<li><code>api-access-log-fields</code>, array: 1, type: &quot;list&quot;, descr: &quot;Additional fields from the request or account to put in the access log, prefix defines where the field is lcoated: q: - query, h: - headers, a: - account otherwise from the request, Example: -api-log-fields h:Referer,a:name,q:action&quot;</li>
<li><code>api-salt</code>, descr: &quot;Salt to be used for scrambling credentials or other hashing activities&quot;</li>
<li><code>api-qs-options-(.+)</code>, autotype: 1, obj: &quot;qsOptions&quot;, strip: &quot;qs-options-&quot;, nocamel: 1, descr: &quot;Options to pass to qs.parse: depth, arrayLimit, allowDots, comma, plainObjects, allowPrototypes, parseArrays&quot;</li>
<li><code>api-no-static</code>, type: &quot;bool&quot;, descr: &quot;Disable static files from /web folder, no .js or .html files will be served by the server&quot;</li>
<li><code>api-static-options-(.+)</code>, autotype: 1, obj: &quot;staticOptions&quot;, strip: &quot;static-options-&quot;, nocamel: 1, descr: &quot;Options to pass to serve-static module: maxAge, dotfiles, etag, redirect, fallthrough, extensions, index, lastModified&quot;</li>
<li><code>api-vhost-path-([^/]+)</code>, type: &quot;regexp&quot;, obj: &quot;vhostPath&quot;, nocamel: 1, strip: &quot;vhost-path-&quot;, regexp: &quot;i&quot;, descr: &quot;Define a virtual host regexp to be matched against the hostname header to serve static content from a different root, a vhost path must be inside the web directory, if the regexp starts with !, that means negative match, example: api-vhost-path-test_dir=test.com$&quot;</li>
<li><code>api-no-vhost-path</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of URL paths that should be served for all virtual hosts&quot;</li>
<li><code>api-templating</code>, descr: &quot;Templating engine package to use, it assumes it supports Expres by exposing __express or renderfile methods&quot;</li>
<li><code>api-no-session</code>, type: &quot;bool&quot;, descr: &quot;Disable cookie session support, all requests must be signed for Web clients&quot;</li>
<li><code>api-session-age</code>, type: &quot;int&quot;, min: 0, descr: &quot;Session age in milliseconds, for cookie based authentication&quot;</li>
<li><code>api-session-domain-(.+)</code>, type: &quot;regexp&quot;, obj: &quot;session-domain&quot;, nocamel: 1, regexp: &quot;i&quot;, descr: &quot;Cookie domain by Host: header, if not matched session is bound to the exact host only, example: -api-session-domain-site.com=site.com$&quot;</li>
<li><code>api-session-same-site</code>, descr: &quot;Session SameSite option, for cookie based authentication&quot;</li>
<li><code>api-session-cache</code>, descr: &quot;Cache name for session control&quot;</li>
<li><code>api-session-secure</code>, type: &quot;bool&quot;, descr: &quot;Set cookie Secure flag&quot;</li>
<li><code>api-query-token-secret</code>, descr: &quot;Name of the property to be used for encrypting tokens for pagination or other sensitive data, any property from bk_user can be used, if empty no secret is used, if not a valid property then it is used as the secret&quot;</li>
<li><code>api-app-header-name</code>, descr: &quot;Name for the app name/version query parameter or header, it is can be used to tell the server about the application version&quot;</li>
<li><code>api-version-header-name</code>, descr: &quot;Name for the access version query parameter or header, this is the core protocol version that can be sent to specify which core functionality a client expects&quot;</li>
<li><code>api-no-cache-files</code>, type: &quot;regexpobj&quot;, descr: &quot;Set cache-control=no-cache header for matching static files&quot;,</li>
<li><code>api-tz-header-name</code>, descr: &quot;Name for the timezone offset header a client can send for time sensitive requests, the backend decides how to treat this offset&quot;</li>
<li><code>api-signature-header-name</code>, descr: &quot;Name for the access signature query parameter, header and session cookie&quot;</li>
<li><code>api-lang-header-name</code>, descr: &quot;Name for the language query parameter, header and session cookie, primary language for a client&quot;</li>
<li><code>api-signature-age</code>, type: &quot;int&quot;, descr: &quot;Max age for request signature in milliseconds, how old the API signature can be to be considered valid, the &#39;expires&#39; field in the signature must be less than current time plus this age, this is to support time drifts&quot;</li>
<li><code>api-access-time-interval</code>, type: &quot;int&quot;, min: 0, descr: &quot;Intervals to refresh last access time for accounts, only updates the cache if <code>bk_user</code> is configured to be cached&quot;</li>
<li><code>api-access-token-secret</code>, descr: &quot;A generic secret to be used for API access or signatures&quot;</li>
<li><code>api-allow-authenticated</code>, type: &quot;regexpobj&quot;, descr: &quot;Add URLs which can be accessed by any authenticated user account, can be partial urls or Regexp, it is checked before any other account types, if matched then no account specific paths will be checked anymore(any of the allow-account-...)&quot;</li>
<li><code>api-allow-acl-authenticated</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-api-allow-authenticated</code> parameter&quot;</li>
<li><code>api-allow-admin</code>, type: &quot;regexpobj&quot;, descr: &quot;Add URLs which can be accessed by admin accounts only, can be partial urls or Regexp&quot;</li>
<li><code>api-allow-acl-admin</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-api-allow-admin</code> parameter&quot;</li>
<li><code>api-allow-account-([a-z0-9_]+)</code>, type: &quot;regexpobj&quot;, obj: &quot;allow-account&quot;, descr: &quot;Add URLs which can be accessed by specific account type, can be partial urls or Regexp&quot;</li>
<li><code>api-allow-acl-([a-z0-9_]+)</code>, type: &quot;rlist&quot;, obj: &quot;allow-acl&quot;, descr: &quot;Combine regexps from the specified acls for allow checks for the specified account type&quot;</li>
<li><code>api-only-account-([a-z0-9_,]+)</code>, type: &quot;regexpobj&quot;, obj: &quot;only-account&quot;, descr: &quot;Add URLs which can be accessed by specific account type only, can be partial urls or Regexp&quot;</li>
<li><code>api-only-acl-([a-z0-9_,]+)</code>, type: &quot;rlist&quot;, obj: &quot;only-acl&quot;, descr: &quot;Combine regexps from the specified acls allowed for the specified account type only&quot;</li>
<li><code>api-deny-authenticated</code>, type: &quot;regexpobj&quot;, descr: &quot;Add URLs which CAN NOT be accessed by any authenticated user account, can be partial urls or Regexp, it is checked before any other account types, if matched then no account specific paths will be checked anymore(any of the deny-account-...)&quot;</li>
<li><code>api-deny-acl-authenticated</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-api-deny-authenticated</code> parameter&quot;</li>
<li><code>api-deny-account-([a-z0-9_]+)</code>, type: &quot;regexpobj&quot;, obj: &quot;deny-account&quot;, descr: &quot;Add URLs which CAN NOT be accessed by specific account type, can be partial urls or Regexp, this is checked before any allow parameters&quot;</li>
<li><code>api-deny-acl-([a-z0-9_]+)</code>, type: &quot;list&quot;, obj: &quot;deny-acl&quot;, descr: &quot;Combine regexps from the specified acls for deny checks for the specified account type&quot;</li>
<li><code>api-acl-([a-z0-9_]+)</code>, type: &quot;regexpobj&quot;, obj: &quot;acl&quot;, descr: &quot;Add URLs to the named ACL which can be used in allow/deny rules per account&quot;</li>
<li><code>api-allow</code>, type: &quot;regexpobj&quot;, set: 1, descr: &quot;Regexp for URLs that dont need credentials, replaces the whole access list&quot;</li>
<li><code>api-allow-path</code>, type: &quot;regexpobj&quot;, key: &quot;allow&quot;, descr: &quot;Add to the list of allowed URL paths without authentication, adds to the <code>-api-allow</code> parameter&quot;</li>
<li><code>api-allow-acl</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-api-allow</code> parameter&quot;</li>
<li><code>api-deny</code>, type: &quot;regexpobj&quot;, set: 1, descr: &quot;Regexp for URLs that will be denied access, replaces the whole access list&quot;</li>
<li><code>api-deny-path</code>, type: &quot;regexpobj&quot;, key: &quot;deny&quot;, descr: &quot;Add to the list of URL paths to be denied without authentication, adds to the <code>-api-deny</code> parameter&quot;</li>
<li><code>api-deny-acl</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-api-deny</code> parameter&quot;</li>
<li><code>api-allow-anonymous</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of allowed URL paths that can be served with or without valid account, the difference with <code>-api-allow-path</code> is that it will check for signature and an account but will continue if no login is provided, return error in case of wrong account or not account found&quot;</li>
<li><code>api-allow-acl-anonymous</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-allow-anonymous</code> parameter&quot;</li>
<li><code>api-allow-empty</code>, type: &quot;regexpobj&quot;, descr: &quot;Regexp for URLs that should return empty responses if not found, for example return nothing for non-existent javascript files or css files&quot;</li>
<li><code>api-ignore-allow</code>, type: &quot;regexpobj&quot;, descr: &quot;Regexp for URLs that should be ignored by the allow rules, the processing will continue&quot;</li>
<li><code>api-ignore-allow-path</code>, type: &quot;regexpobj&quot;, key: &quot;ignore-allow&quot;, descr: &quot;Add to the list of URL paths which should be ignored by the allow rules, in order to keep allow/deny rules simple, for example to keep some js files from open to all: -allow-path \.js -ignore-allow-path /secure/&quot;</li>
<li><code>api-ignore-allow-acl</code>, type: &quot;list&quot;, descr: &quot;Combine regexps from the specified acls for the check explained by <code>-ignore-allow-path</code> parameter&quot;</li>
<li><code>api-allow-ip</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of regexps for IPs that only allowed access from. It is checked before endpoint access list&quot;</li>
<li><code>api-deny-ip</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of regexps for IPs that will be denied access. It is checked before endpoint access list.&quot;</li>
<li><code>api-allow-ssl</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of allowed locations using HTTPs only, plain HTTP requests to these urls will be refused&quot;</li>
<li><code>api-ignore-ssl</code>, type: &quot;regexpobj&quot;, descr: &quot;Allow plain HTTP from matched IP addresss or locations&quot;</li>
<li><code>api-redirect-ssl</code>, type: &quot;regexpobj&quot;, descr: &quot;Add to the list of the locations to be redirected to the same path but using HTTPS protocol&quot;</li>
<li><code>api-express-options</code>, type: &quot;json&quot;, logger: &quot;warn&quot;, descr: &quot;Set Express config options during initialization,example: <code>-api-express-options { \&quot;trust proxy\&quot;: 1, \&quot;strict routing\&quot;: true }</code>&quot;</li>
<li><code>api-mime-body</code>, type: &quot;regexpobj&quot;, descr: &quot;Collect full request body in the req.body property for the given MIME type in addition to json and form posts, this is for custom body processing&quot;</li>
<li><code>api-mime-ignore</code>, type: &quot;regexpobj&quot;, descr: &quot;Ignore the body for the following MIME content types, request body will not be parsed at all&quot;</li>
<li><code>api-mime-map-(.+)</code>, obj: &quot;mime-map&quot;, descr: &quot;File extension to MIME content type mapping, this is used by static-serve, example: -api-mime-map-mobileconfig application/x-apple-aspen-config&quot;</li>
<li><code>api-ignore-content-type</code>, type: &quot;regexpobj&quot;, descr: &quot;Ignore the content type for the following endpoint paths, keep the body unparsed&quot;</li>
<li><code>api-platform-match</code>, type: &quot;regexpmap&quot;, regexp: &quot;i&quot;, descr: &quot;An JSON object with list of regexps to match user-agent header for platform detection, example: { &#39;ios|iphone|ipad&#39;: &#39;ios&#39;, &#39;android&#39;: &#39;android&#39; }&quot;</li>
<li><code>api-cors-origin</code>, descr: &quot;Origin header for CORS requests&quot;</li>
<li><code>api-cors-allow</code>, type: &quot;regexpobj&quot;, descr: &quot;Enable CORS requests if a request host/path matches the given regexp&quot;</li>
<li><code>api-server-header</code>, descr: &quot;Custom Server: header to return for all requests&quot;</li>
<li><code>api-error-message</code>, descr: &quot;Default error message to return in case of exceptions&quot;</li>
<li><code>api-restart</code>, descr: &quot;On address in use error condition restart the specified servers, this assumes an external monitor like monit to handle restarts&quot;</li>
<li><code>api-allow-error-code</code>, type: &quot;regexpobj&quot;, descr: &quot;Error codes in exceptions to return in the response to the user, if not matched the error-message will be returned&quot;</li>
<li><code>api-rlimits-([a-z]+)$</code>, obj: &quot;rlimits&quot;, make: &quot;$1&quot;, autotype: 1, descr: &quot;Default rate limiter parameters, default interval is 1s, <code>ttl</code> is to expire old cache entries, message for error&quot;</li>
<li><code>api-rlimits-(rate|max|interval|ttl|ip|delay|multiplier|queue)-(.+)</code>, autotype: 1, obj: &quot;rlimitsMap.$2&quot;, make: &quot;$1&quot;, descr: &quot;Rate limiter parameters for Token Bucket algorithm. <code>queue</code> to use specific queue, ttl<code>is to expire cache entries,</code>ip` is to limit by IP address as well, ex. -api-rlimits-ip-ip=10, -api-rlimits-rate-/path=1&quot;</li>
<li><code>api-rlimits-map-(.+)</code>, type: &quot;map&quot;, obj: &quot;rlimitsMap.$1&quot;, make: &quot;$1&quot;, maptype: &quot;auto&quot;, merge: 1, descr: &quot;Rate limiter parameters for Token Bucket algorithm. set all at once, ex. -api-rlimits-map-/url=rate:1,interval:2000&quot;</li>
<li><code>api-exit-on-error</code>, type: &quot;bool&quot;, descr: &quot;Exit on uncaught exception in the route handler&quot;</li>
<li><code>api-timeout</code>, type: &quot;number&quot;, min: 0, max: 3600000, descr: &quot;HTTP request idle timeout for servers in ms, how long to keep the connection socket open, this does not affect Long Poll requests&quot;</li>
<li><code>api-keep-alive-timeout</code>, type: &quot;int&quot;, descr: &quot;Number of milliseconds to keep the HTTP conection alive&quot;</li>
<li><code>api-request-timeout</code>, type: &quot;int&quot;, min: 0, descr: &quot;Number of milliseconds to receive the entire request from the client&quot;</li>
<li><code>api-max-requests-per-socket</code>, type: &quot;int&quot;, min: 0, descr: &quot;The maximum number of requests a socket can handle before closing keep alive connection&quot;</li>
<li><code>api-(query|header|upload)-limit</code>, type: &quot;number&quot;, descr: &quot;Max size for query/headers/uploads, bytes&quot;</li>
<li><code>api-limiter-queue</code>, descr: &quot;Name of an ipc queue for API rate limiting&quot;</li>
<li><code>api-errlog-limiter-max</code>, type: &quot;int&quot;, descr: &quot;How many error messages to put in the log before throttling kicks in&quot;</li>
<li><code>api-errlog-limiter-interval</code>, type: &quot;int&quot;, descr: &quot;Interval for error log limiter, max errors per this interval&quot;</li>
<li><code>api-errlog-limiter-ignore</code>, type: &quot;regexpobj&quot;, descr: &quot;Do not show errors that match the regexp&quot;</li>
<li><code>api-routing-(.+)</code>, type: &quot;regexpobj&quot;, reverse: 1, nocamel: 1, obj: &#39;routing&#39;, descr: &quot;Locations to be re-routed to other path, this is done inside the server at the beginning, only the path is replaced, same format and placeholders as in redirect-url, use ! in front of regexp to remove particular redirect from the list, example: -api-routing-^/account/get /acount/read&quot;</li>
<li><code>api-ignore-routing</code>, type: &quot;regexpobj&quot;, descr: &quot;Ignore locations from the routing&quot;</li>
<li><code>api-auth-routing-(.+)</code>, type: &quot;regexpobj&quot;, reverse: 1, nocamel: 1, obj: &#39;auth-routing&#39;, descr: &quot;URL path to be re-routed to other path after the authentication is successful, this is done inside the server, only the path is replaced, same format and placeholders as in redirect-url, example: -api-routing-auth-^/account/get /acount/read&quot;</li>
<li><code>api-redirect-url</code>, type: &quot;regexpmap&quot;, descr: &quot;Add to the list a JSON object with property name defining a location regexp to be matched early against in order to redirect using the value of the property, if the regexp starts with !, that means it must be removed from the list, variables can be used for substitution: @HOST@, @PATH@, @URL@, @BASE@, @DIR@, @QUERY@, status code can be prepended to the location, example: { &#39;^[^/]+/path/$&#39;: &#39;/path2/index.html&#39;, &#39;.+/$&#39;: &#39;301:@PATH@/index.html&#39; } &quot;</li>
<li><code>api-login-redirect-(.+)</code>, type: &quot;regexpobj&quot;, reverse: 1, nocamel: 1, obj: &quot;login-redirect&quot;, descr: &quot;Define a location where to redirect if no login is provided, same format and placeholders as in redirect-url, example: api-login-redirect-^/admin/=/login.html&quot;</li>
<li><code>api-default-auth-status</code>, type: &quot;int&quot;, descr: &quot;Default authenticated status, if no auth rules matched but valid signature this is the status returned&quot;</li>
<li><code>api-default-auth-message</code>, descr: &quot;Default authenticated message to be returned with default auth status&quot;</li>
<li><code>api-reset-acl</code>, type: &quot;callback&quot;, callback: function(v) { if (v) this.resetAcl()  descr: &quot;Reset all ACL, auth, routing and login properties in the api module&quot;</li>
<li><code>api-response-headers</code>, type: &quot;regexpmap&quot;, json: 1, descr: &quot;An JSON object with list of regexps to match against the location and set response headers defined as a ist of pairs name, value..., -api-response-headers={ &quot;^/&quot;: [&quot;x-frame-options&quot;,&quot;sameorigin&quot;,&quot;x-xss-protection&quot;,&quot;1; mode=block&quot;] }&quot;</li>
<li><code>api-cleanup-rules-(.+)</code>, obj: &quot;cleanupRules.$1&quot;, type: &quot;map&quot;, maptype: &quot;auto&quot;, merge: 1, nocamel: 1, descr: &quot;Rules for the cleanupResult per table, ex. api-cleanup-rules-bk_user=email:0,phone:1&quot;</li>
<li><code>api-cleanup-strict</code>, type: &quot;bool&quot;, descr: &quot;Default mode for cleanup results&quot;</li>
<li><code>api-request-cleanup</code>, type: &quot;list&quot;, array: 1, descr: &quot;List of fields to explicitely cleanup on request end&quot;</li>
<li><code>api-query-defaults-([a-z0-9_]+)-(.+)</code>, obj: &quot;queryDefaults.$2&quot;, make: &quot;$1&quot;, autotype: 1, descr: &quot;Global query defaults for getQuery, can be path specific, ex. -api-query-defaults-max-name 128 -api-query-defaults-max-/endpoint-name 255&quot;</li>
<li><code>api-csrf-set-path</code>, type: &quot;regexpobj&quot;, descr: &quot;Regexp for URLs to set CSRF token for all methods, token type(account|pub) is based on the current session&quot;</li>
<li><code>api-csrf-pub-path</code>, type: &quot;regexpobj&quot;, descr: &quot;Regexp for URLs to set public CSRF token only if no valid CSRF token detected&quot;</li>
<li><code>api-csrf-check-path</code>, type: &quot;regexpobj&quot;, descr: &quot;Regexp for URLs to set CSRF token for skip methods and verify for others&quot;</li>
<li><code>api-csrf-skip-method</code>, type: &quot;regexp&quot;, descr: &quot;Do not check for CSRF token for specified methods&quot;</li>
<li><code>api-csrf-skip-status</code>, type: &quot;regexp&quot;, descr: &quot;Do not return CSRF token for specified status codes&quot;</li>
<li><code>api-csrf-header-name</code>, descr: &quot;Name for the CSRF header&quot;</li>
<li><code>api-csrf-age</code>, type: &quot;int&quot;, min: 0, descr: &quot;CSRF token age in milliseconds&quot;</li>
<li><code>api-delays-([0-9]+)</code>, type: &quot;int&quot;, obj: &quot;delays&quot;, nocamel: 1, descr: &quot;Delays in ms by status code, useful for delaying error responses to slow down brute force attacks, ex. -api-delays-401 1000&quot;</li>
<li><code>api-err-(.+)</code>, descr: &quot;Error messages for various cases&quot;</li>
<li><code>api-compressed-([^/]+)</code>, type: &quot;regexp&quot;, obj: &quot;compressed&quot;, nocamel: 1, strip: &quot;compressed-&quot;, reverse: 1, regexp: &quot;i&quot;, descr: &quot;Match static paths to be returned compressed, files must exist and be pre-compressed with the given extention , example: -api-compress-bundle.js gz&quot;</li>
<li><code>api-allow-configure-(web|middleware)</code>, type: &quot;regexp&quot;, descr: &quot;Modules allowed to call configureWeb or Middleware, i.e. only allowed endpoints&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.init(options, callback)</code></p>
<p>  Initialize API layer, this must be called before the <code>api</code> module can be used but it is called by the server module automatically so <code>api.init</code> is
rearely need to called directly, only for new server implementation or if using in the shell for testing.</p>
<p>During the init sequence, this function calls <code>api.initMiddleware</code> and <code>api.initApplication</code> methods which by default are empty but can be redefined in the user aplications.</p>
<p>The bkjs.js uses its own request parser that places query parameters into <code>req.query</code> or <code>req.body</code> depending on the method.</p>
<p>For GET method, <code>req.query</code> contains all url-encoded parameters, for POST method <code>req.body</code> contains url-encoded parameters or parsed JSON payload or multipart payload.</p>
<p>The reason not to do this by default is that this may not be the alwayse wanted case and distinguishing data coming in the request or in the body may be desirable,
also, this will needed only for Express handlers <code>.all</code>, when registering handler by method like <code>.get</code> or <code>.post</code> then the handler needs to deal with only either source of the request data.</p>
</li>
</ul>

<ul>
<li><p><code>api.shutdown(callback)</code></p>
<p>  Gracefully close all connections, call the callback after that</p>
</li>
</ul>

<ul>
<li><p><code>api.shutdownWeb(options, callback)</code></p>
<p>  Gracefully close all database pools when the shutdown is initiated by a Web process</p>
</li>
</ul>

<ul>
<li><p><code>api.configureStatic()</code></p>
<p>  Templating and static paths</p>
</li>
</ul>

<ul>
<li><p><code>api.configureAccessLog()</code></p>
<p>  Setup access log stream</p>
</li>
</ul>

<ul>
<li><p><code>api.handleServerRequest(req, res)</code></p>
<p>  Start Express middleware processing wrapped in the node domain</p>
</li>
</ul>

<ul>
<li><p><code>api.prepareRequest(req)</code></p>
<p>  Prepare request options that the API routes will merge with, can be used by pre process hooks, initialize
required properties for subsequent use</p>
</li>
</ul>

<ul>
<li><p><code>api.prepareOptions(req)</code></p>
<p>  Parse or re-parse special headers about app version, language and timezone, it is called early to parse headers first and then
right after the query parameters are available, query values have higher priority than headers.</p>
</li>
</ul>

<ul>
<li><p><code>api.startMetrics(req, res, next)</code></p>
<p>  This is supposed to be called at the beginning of request processing to start metrics and install the handler which
will be called at the end to finalize the metrics and call the cleanup handlers</p>
</li>
</ul>

<ul>
<li><p><code>api.handleMetrics(req, elapsed)</code></p>
<p>  Finish metrics collection about the current rquest</p>
</li>
</ul>

<ul>
<li><p><code>api.handleCleanup(req)</code></p>
<p>  Call registered cleanup hooks and clear the request explicitly</p>
</li>
</ul>

<ul>
<li><p><code>api.checkQuery(req, res, next)</code></p>
<p>  Parse incoming query parameters</p>
</li>
</ul>

<ul>
<li><p><code>api.checkBody(req, res, next)</code></p>
<p>  Parse multipart forms for uploaded files</p>
</li>
</ul>

<ul>
<li><p><code>api.checkRouting(req, name, ignore)</code></p>
<p>  Check if the current request must be re-routed to another endpoint</p>
</li>
</ul>

<ul>
<li><p><code>api.checkRedirectPlaceholders(req, pathname)</code></p>
<p>  Replace redirect placeholders</p>
</li>
</ul>

<ul>
<li><p><code>api.checkRedirectSsl(req)</code></p>
<p>  Check a request for possible SSL redirection, it checks the original URL</p>
</li>
</ul>

<ul>
<li><p><code>api.checkRedirectRules(req, name)</code></p>
<p>  Check a request for possible redirection condition based on the configuration.
This is used by API servers for early redirections. It returns null
if no redirects or errors happend, otherwise an object with status that is expected by the <code>api.sendStatus</code> method.
The options is expected to contain the following cached request properties:</p>
<ul>
<li>path - from req.path or the request pathname only</li>
<li>host - from req.hostname or the hostname part only</li>
<li>port - port from the host: header if specified</li>
<li>secure - if the protocol is https</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.checkRateLimits(req, options, callback)</code></p>
<p>  Perform rate limiting by specified property, if not given no limiting is done.</p>
<p>The following options properties can be used:</p>
<ul>
<li><p>type - predefined: <code>ip,  path, opath</code>, determines by which property to perform rate limiting, when using account properties
 the rate limiter should be called after the request signature has been parsed. Any other value is treated as
 custom type and used as is. If it is an array all items will be checked sequentially.
 <strong>This property is required.</strong></p>
<p> The predefined types checked for every request:</p>
<ul>
<li><p>ip - check every IP address</p>
</li>
<li><p>opath - same as path but uses original path before routing</p>
</li>
<li><p>path - limit number of requests for an API path by IP address, * can be used at the end to match only the beginning</p>
<p>  -api-rlimits-rate-ip=100
  -api-rlimits-rate-/api/path=2
  -api-rlimits-ip-/api/path=1
  -api-rlimits-rate-/api/path/*=1</p>
</li>
</ul>
</li>
<li><p>ip - to use the specified IP address</p>
</li>
<li><p>max - max capacity to be used by default</p>
</li>
<li><p>rate - fill rate to be used by default</p>
</li>
<li><p>interval - interval in ms within which the rate is measured, default 1000 ms</p>
</li>
<li><p>message - more descriptive text to be used in the error message for the type, if not specified a generic error message is used</p>
</li>
<li><p>queue - which queue to use instead of the default, some limits is more useful with global queues like Redis instead of the default</p>
</li>
<li><p>delay - time in ms to delay the response, slowing down request rate</p>
</li>
<li><p>multiplier - multiply the interval after it consumed all tokens, subsequent checks use the increased interval, fractions supported,
if the multiplier is positive then the interval will keep increasing indefinitely, if it is negative the interval will reset to the default
value on first successful consumption</p>
</li>
</ul>
<p>The metrics are kept in the LRU cache in the master process by default.</p>
<p>Example:</p>
<pre><code>  api.checkRateLimits(req, { type: &quot;ip&quot;, rate: 100, interval: 60000 }, (err, info) =&gt; {
     if (err) return api.sendReply(err);
     ...
  });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.sendJSON(req, err, data)</code></p>
<p>  Send result back with possibly executing post-process callback, this is used by all API handlers to allow custom post processing in the apps.
If err is not null the error message is returned immediately.</p>
</li>
</ul>

<ul>
<li><p><code>api.sendFormatted(req, err, data, options)</code></p>
<p>  Send result back formatting according to the options properties:</p>
<ul>
<li>format - json, csv, xml, JSON is default</li>
<li>separator - a separator to use for CSV and other formats</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.sendStatus(res, options)</code></p>
<p>  Return reply to the client using the options object, it contains the following properties:</p>
<ul>
<li>status - defines the respone status code</li>
<li>message  - property to be sent as status line and in the body</li>
<li>type - defines Content-Type header, the message will be sent in the body</li>
<li>url - for redirects when status is 301, 302...</li>
</ul>
<p><strong>i18n Note:</strong></p>
<p>The API server attaches fake i18n functions <code>req.__</code> and <code>res.__</code> which are used automatically for the <code>message</code> property
before sending the response.</p>
<p>With real i18n module these can/will be replaced performing actual translation without
using <code>i18n.__</code> method for messages explicitely in the application code for <code>sendStatus</code> or <code>sendReply</code> methods.</p>
<p>Replies can be delayed per status via <code>api.delays</code> if configured, to override any daly set
<code>req.options.sendDelay</code> to nonzero value, negative equals no delay</p>
</li>
</ul>

<ul>
<li><p><code>api.sendReply(res, status, text)</code></p>
<p>  Send formatted JSON reply to an API client, if status is an instance of Error then error message with status 500 is sent back.</p>
<p>If the status is an object it is sent as is.</p>
<p>All Error objects will return a generic error message without exposing the real error message, it will log all error exceptions in the logger
subject to log throttling configuration.</p>
</li>
</ul>

<ul>
<li><p><code>api.sendFile(req, file, redirect)</code></p>
<p>  Send file back to the client, res is Express response object</p>
</li>
</ul>

<ul>
<li><p><code>api.handleLogout(req)</code></p>
<p>  Clear the session and all cookies</p>
</li>
</ul>

<ul>
<li><p><code>api.handleSignature(req, res, callback)</code></p>
<p>  Perform authorization of the incoming request for access and permissions</p>
</li>
</ul>

<ul>
<li><p><code>api.newSignature(req)</code></p>
<p>  Returns a new signature object with all required properties filled form the request object</p>
</li>
</ul>

<ul>
<li><p><code>api.getSignature(req)</code></p>
<p>  Parse incoming request for signature and return all pieces wrapped in an object, this object will be used by <code>verifySignature</code> function.</p>
<p>If the signature successfully recognized it is saved in the request as <code>req.signature</code>,
it always returns a signature object, a new one or existing</p>
</li>
</ul>

<ul>
<li><p><code>api.verifySignature(req, sig, account, callback)</code></p>
<p>  Returns true if the signature <code>sig</code> matches given account secret. <code>account</code> object must be a <code>bk_user</code> record.</p>
</li>
</ul>

<ul>
<li><p><code>api.createSignature(login, secret, method, host, uri, options)</code></p>
<p>  Create secure signature for an HTTP request. Returns an object with HTTP headers to be sent in the response.</p>
<p>The options may contains the following:</p>
<ul>
<li>expires is absolute time in milliseconds when this request will expire, default is 30 seconds from now</li>
<li>version a version number defining how the signature will be signed</li>
<li>type - content-type header, may be omitted</li>
<li>tag - a custom tag, vendor specific, opaque to the bkjs, can be used for passing additional account or session inforamtion</li>
<li>checksum - SHA1 digest of the whole content body, may be omitted</li>
<li>query - on object with query parameters to use instead of parameters in the uri</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.checkRequestSignature(req, callback)</code></p>
<p>  Verify request signature from the request object, uses properties: .host, .method, .url or .originalUrl, .headers</p>
</li>
</ul>

<ul>
<li><p><code>api.checkAccess(req, callback)</code></p>
<p>  Perform URL based access checks, this is called before the signature verification, very early in the request processing step.</p>
<p>Checks access permissions, calls the callback with the following argument:</p>
<ul>
<li>nothing if checkRequestSignature needs to be called</li>
<li>an object with status: 200 to skip authorization and proceed with other routes</li>
<li>an object with status: 0 means response has been sent, just stop</li>
<li>an object with status other than 0 or 200 to return the status and stop request processing,
 for statuses 301,302 there should be url property in the object returned</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.checkAuthorization(req, status, callback)</code></p>
<p>  Perform authorization checks after the account been checked for valid signature, this is called even if the signature verification failed,
in case of a custom authentication middlware this must be called at the end and use the status object returned in the callback to
return an error or proceed with the request. In any case the result of this function is final.</p>
<p>If a user has valid login by default access to all API endpoints is granted, to restrict access to specific APIs use any combinations of
<code>api-allow</code> or <code>api-deny</code> config parameters.</p>
<ul>
<li>req is Express request object</li>
<li>status contains the signature verification status, an object with status: and message: properties, can not be null.
 The status property is passed to each hook in the chain, the result status will be returned to the client.</li>
<li>callback is a function(status) to be called with the resulted status where status must be an object with status and message properties as well</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.getCsrfToken(req)</code></p>
<p>  CSRF token format: TYPE,RANDOM_INT,EXPIRE_MS,[UID]</p>
<p><code>type`` is </code>h<code>for header or</code>c`` for cookie</p>
<p>Implements double cookie protection using HTTP and cookie tokens, both must be present.</p>
<p>In addition a token may contain the account id which must be the same as logged in user.</p>
<p>Return HTTP CSRF token, can be used in templates or forms, the cookie token will reuse the same token</p>
</li>
</ul>

<ul>
<li><p><code>api.verifyCsrfToken(req)</code></p>
<p>  Returns .ok == false if CSRF token verification fails, both header and cookie are checked and retuned as .h and .c</p>
</li>
</ul>

<ul>
<li><p><code>api.checkCsrfToken(req, options)</code></p>
<p>  For configured endpoints check for a token and fail if not present or invalid</p>
</li>
</ul>

<ul>
<li><p><code>api.skipCsrfToken(req)</code></p>
<p>  Do not return CSRF token in cooies or headers</p>
</li>
</ul>

<ul>
<li><p><code>api.clearCsrfToken(req)</code></p>
<p>  Reset CSRF tokens from cookies and headers</p>
</li>
</ul>

<ul>
<li><p><code>api.fileUrl(file, options)</code></p>
<p>  Returns absolute file url if it is configured with any prefix or S3 bucket, otherwise returns empty string</p>
</li>
</ul>

<ul>
<li><p><code>api.getFile(req, file, options)</code></p>
<p>  Send a file to the client</p>
</li>
</ul>

<ul>
<li><p><code>api.readFile(file, options, callback)</code></p>
<p>  Returns contents of a file, all specific parameters are passed as is, the contents of the file is returned to the callback,
see <code>lib.readFile</code> or <code>aws.s3GetFile</code> for specific options.</p>
</li>
</ul>

<ul>
<li><p><code>api.copyFile(source, dest, options, callback)</code></p>
<p>  Copy a file from one location to another, can deal with local and S3 files if starts with s3:// prefix</p>
</li>
</ul>

<ul>
<li><p><code>api.listFile(options, callback)</code></p>
<p>  Returns a list of file names inside the given folder, <code>options.filter</code> can be a regexp to restrict which files to return</p>
</li>
</ul>

<ul>
<li><p><code>api.putFile(req, name, options, callback)</code></p>
<p>  Upload file and store in the filesystem or S3, try to find the file in multipart form, in the body or query by the given name</p>
<ul>
<li>name is the name property to look for in the multipart body or in the request body or query</li>
<li>callback will be called with err and actual filename saved</li>
</ul>
<p>Output file name is built according to the following options properties:</p>
<ul>
<li>name - defines the output name for the file, if not given same name as property will be used</li>
<li>prefix - the folder prefix where the file will be uploaded, all leading folders will be created automatically</li>
<li>ext - what file extention to use, appended to the name, if no ext is given the extension from the uploaded file will be used or no extention if could not determine one.</li>
<li>extkeep - keep actual extention from the uploaded file, ignore the ext parameter</li>
<li>extmap - an object which extensions must be replaced</li>
<li>namekeep - keep the name of the uploaded file if present in the multipart form</li>
<li>encoding - encoding of the body, default is base64</li>
<li>allow - a Regexp with allowed MIME types, this will use detectFile method to discover file type by the contents, make sure `mmmagic`` package is installed</li>
<li>maxsize - refuse to save if the payload exceeds the given size</li>
</ul>
<p>On return the options may have the following properties set:</p>
<ul>
<li>filesize - size of the file in bytes if available</li>
<li>filetype - file extention with dot</li>
<li>mimetype - file mime type if detected</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.storeFile(tmpfile, outfile, options, callback)</code></p>
<p>  Place the uploaded tmpfile to the destination pointed by outfile</p>
</li>
</ul>

<ul>
<li><p><code>api.delFile(file, options, callback)</code></p>
<p>  Delete file by name from the local filesystem or S3 drive if filesS3 is defined in api or options objects</p>
</li>
</ul>

<ul>
<li><p><code>api.detectFile(file, flags, callback)</code></p>
<p>  Returns detected mime type and ext for a file, requires <code>mmmagic</code> package,
if no flags given uses MAGIC_MIME_TYPE by default</p>
</li>
</ul>

<ul>
<li><p><code>api.findHook(type, method, path)</code></p>
<p>  Find registered hooks for given type and path</p>
</li>
</ul>

<ul>
<li><p><code>api.addHook(type, method, path, callback)</code></p>
<p>  Register a hook callback for the type and method and request url, if already exists does nothing.</p>
</li>
</ul>

<ul>
<li><p><code>api.registerRateLimits(name, rate, max, interval, queue)</code></p>
<p>  Register access rate limit for a given name, all other rate limit properties will be applied as described in the <code>checkRateLimits</code></p>
</li>
</ul>

<ul>
<li><p><code>api.registerControlParams(options)</code></p>
<p>  Add special control parameters that will be recognized in the query and placed in the <code>req.options</code> for every request.</p>
<p>Control params start with underscore and will be converted into the configured type according to the spec.
The <code>options</code> is an object in the format that is used by <code>lib.toParams</code>, no default type is allowed, even for string
it needs to be defined as { type: &quot;string&quot; }.</p>
<p>No existing control parameters will be overridden, also care must be taken when defining new control parameters so they do not
conflict with the existing ones.</p>
<p>These are default common parameters that can be used by any module:</p>
<ul>
<li><code>_count, _page, _tm, _sort, _select, _ext, _start, _token, _session, _format, _total, _encoding, _ops</code></li>
</ul>
<p>These are the reserved names that cannot be used for parameters, they are defined by the engine for every request:</p>
<ul>
<li><code>path, apath, ip, host, mtime, cleanup, secure, noscan, appName, appVersion, appLocale, appTimezone, apiVersion</code></li>
</ul>
<p>NOTE: <code>noscan</code> is set to 1 in every request to prevent accidental full scans, this means it cannot be enabled via the API but any module
can do it in the code if needed.</p>
<p>Example:</p>
<pre><code> mod.configureMiddleware = function(options, callback) {
     api.registerControlParams({ notify: { type: &quot;bool&quot; }, level: { type: &quot;int&quot;, min: 1, max: 10 } });
     callback();
 }

 Then if a request arrives for example as `_notify=true&amp;_level=5`, it will be parsed and placed in the `req.options`:

 mod.configureWeb = function(options, callback) {

    api.app.all(&quot;/send&quot;, function(req, res) {
        if (req.options.notify) { ... }
        if (req.options.level &gt; 5) { ... }
    });
    callback()
 }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerAccessCheck(method, path, callback)</code></p>
<p>  Register a handler to check access for any given endpoint, it works the same way as the global accessCheck function and is called before
validating the signature or session cookies. No account information is available at this point yet.</p>
<ul>
<li>method can be &#39;&#39; in such case all methods will be matched</li>
<li>path is a string or regexp of the request URL similar to registering Express routes</li>
<li>callback is a function with the following parameters: function(req, cb) {}, to indicate an error condition pass an object
with the callback with status: and message: properties, status != 200 means error,
status == 0 means continue processing, ignore this match</li>
</ul>
<p>Example:</p>
<pre><code>     api.registerAccessCheck(&#39;&#39;, &#39;account&#39;, function(req, cb) { cb({ status: 500, message: &quot;access disabled&quot;}) }))

     api.registerAccessCheck(&#39;POST&#39;, &#39;/account/add&#39;, function(req, cb) {
        if (!req.query.invitecode) return cb({ status: 400, message: &quot;invitation code is required&quot; });
        cb();
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerAuthCheck(method, path, callback)</code></p>
<p>  This callback will be called after the signature or session is verified but before
the ACL authorizaton is called. The <code>req.account</code> object will always exist at this point but may not contain the user in case of an error.</p>
<p>The purpose of this hook is to perform alternative authentication like API access with keys. Because it is called before the authorization it is
also possible to customize user roles.</p>
<p>To just continue to next hopok or step return nothing in the <code>cb</code>,
any returned status will be final, an error status will be immediately returned in the response,
status 200 will continue to the authorization step</p>
<ul>
<li>method can be &#39;&#39; in such case all methods will be matched</li>
<li>path is a string or regexp of the request URL similr to registering Express routes</li>
<li>callback is a function(req, status, cb) where status is an object { status:..., message: ..} passed from the checkRequestSignature call</li>
</ul>
<p>Example:</p>
</li>
</ul>

<ul>
<li><p><code>api.registerPreProcess(method, path, callback)</code></p>
<p>  Similar to <code>registerAuthCheck</code>, this callback will be called after the signature or session is verified and ACL authorization performed but before
the API route method is called. The <code>req.account</code> object will always exist at this point but may not contain the user in case of an error.</p>
<p>The purpose of this hook is to perform some preparations or check permissions of a valid user to resources or in case of error perform any other action
like redirection or returning something explaining what to do in case of failure.</p>
<ul>
<li>method can be &#39;&#39; in such case all methods will be matched</li>
<li>path is a string or regexp of the request URL similr to registering Express routes</li>
<li>callback is a function(req, status, cb) where status is an object { status:..., message: ..} passed from the checkRequestSignature call, if status != 200 it means
an error condition, the callback must pass the same or modified status object in its own <code>cb</code> callback</li>
</ul>
<p>Example:</p>
<pre><code>      api.registerPreProcess(&#39;GET&#39;, &#39;/account/get&#39;, function(req, status, cb) {
           if (status.status != 200) status = { status: 302, url: &#39;/error.html&#39; };
           cb(status)
      });
</code></pre>
<p>Example with admin access only:</p>
<pre><code>     api.registerPreProcess(&#39;POST&#39;, &#39;/data/&#39;, function(req, status, cb) {
         if (req.account.type != &quot;admin&quot;) return cb({ status: 401, message: &quot;access denied, admins only&quot; });
         cb();
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerPostProcess(method, path, callback)</code></p>
<p>  Register a callback to be called after successfull API action, status 200 only. To trigger this callback the primary response handler must return
results using <code>api.sendJSON</code> or <code>api.sendFormatted</code> methods.</p>
<p>The purpose is to perform some additional actions after the standard API completed or to customize the result</p>
<ul>
<li>method can be &#39;&#39; in such case all methods will be matched</li>
<li>path is a string or regexp of the request URL similar to registering Express routes</li>
<li>callback is a function with the following parameters: function(req, res, rows) where rows is the result returned by the API handler,
the callback may not return data back to the client, in this case next post-process hook will be called and eventually the result will be sent back to the client.
<strong>To indicate that this hook will send the result eventually it must return true, otherwise the rows will be sent afer all hooks are called</strong></li>
</ul>
<p>Note: the <code>req.account,req.options,req.query</code> objects may become empty if any callback decided to do some async action, they are explicitly emptied at the end of the request,
in such cases make a copy of the needed objects if it will needed</p>
<p>Example, just update the rows, it will be sent at the end of processing all post hooks</p>
<pre><code>     api.registerPostProcess(&#39;&#39;, &#39;/data/&#39;, function(req, res, rows) {
         rows.forEach(function(row) { ...});
     });
</code></pre>
<p>Example, add data to the rows and return result after it</p>
<pre><code>     api.registerPostProcess(&#39;&#39;, &#39;/data/&#39;, function(req, res, row) {
         db.get(&quot;bk_user&quot;, { id: row.id }, function(err, rec) {
             row.name = rec.name;
             res.json(row);
         });
         return true;
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerCleanup(method, path, callback)</code></p>
<p>  Register a cleanup callback that will be called at the end of a request, all registered cleanup callbacks will be called in the order
of registration. At this time the result has been sent so connection is not valid anymore but the request and account objects are still available.</p>
<p>Example, do custom logging of all requests</p>
<pre><code>     api.registerCleanup(&#39;&#39;, &#39;/data/&#39;, function(req, next) {
         db.add(&quot;log&quot;, req.query, next);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerSendStatus(method, path, callback)</code></p>
<p>  Register a status callback that will be called when <code>api.sendReply</code> or <code>api.sendStatus</code> is called,
all registered callbacks will be called in the order of registration. At this time the result has NOT been sent yet so connection is
still valid and can be changed. The callback behavior is similar to the <code>api.registerPostProcess</code>.
  <strong>To indicate that this hook will send the result eventually it must return true, otherwise the result will be sent afer all hooks are called</strong></p>
<p>Example, do custom logging of all requests</p>
<pre><code>     api.registerSendStatus(&#39;&#39;, &#39;/data/&#39;, function(req, res, data) {
         logger.info(&quot;response&quot;, req.path, data);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerSignature(method, path, callback)</code></p>
<p>  The purpose of this hook is to manage custom signatures.</p>
<ul>
<li>method can be &#39;&#39; in such case all methods will be matched</li>
<li>path is a string or regexp of the request URL similr to registering Express routes</li>
<li>callback is a function(req, account, sig, cb) where<ul>
<li>if sig is null it means to generate a new signature for the given account and return in the callback, if multiple hooks are registered the processing
stops on first signature returned</li>
<li>if sig is provided that means to verify the signature against given account and return it if valid or return null if it is invalid or
cannot be verified by current hook, multiple hooks can be supported and it stops on first signature returned in the callback</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>      api.registerSignature(&#39;&#39;, &#39;/&#39;, function(req, account, sig, cb) {
           if (sig) {
               if (invalid) sig = null;
           } else {
               sig = api.createSignature(.....);
           }
           cb(sig)
      });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.registerSecret(login, callback)</code></p>
<p>  Register a secret generation method.</p>
<ul>
<li>login is a regexp for logins to have a special secret encryption method</li>
<li>callback is a function(account, options, cb)</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.registerPreHeaders(req, callback)</code></p>
<p>  Register a callback to be called just before HTTP headers are flushed, the callback may update response headers</p>
<ul>
<li>callback is a function(req, res, statusCode)</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.scaleIcon(infile, options, callback)</code></p>
<p>  Scale image return err if failed.</p>
<p>If image module is not set (default) then the input data is returned or saved as is.</p>
<ul>
<li>infile can be a string with file name or a Buffer with actual image data</li>
<li>options can specify image properties:<ul>
<li>outfile - if not empty is a file name where to store scaled image or if empty the new image contents will be returned in the callback as a buffer</li>
<li>width, height - new image dimensions<ul>
<li>if width or height is negative this means do not perform upscale, keep the original size if smaller than given positive value,</li>
<li>if any is 0 that means keep the original size</li>
</ul>
</li>
<li>ext - image format: png, gif, jpg, svg</li>
</ul>
</li>
</ul>
<p>The callback takes 3 arguments: function(err, data, info)</p>
<p>where <code>data</code> will contain a new image data and <code>info</code> is an object with the info about the new or unmodified image: ext, width, height.</p>
</li>
</ul>

<ul>
<li><p><code>api.iconPath(id, options)</code></p>
<p>  Full path to the icon, perform necessary hashing and sharding, id can be a number or any string.</p>
<p><code>options.type</code> may contain special placeholders:</p>
<ul>
<li>@uuid@ - will be replaced with a unique UUID and placed back to the options.type</li>
<li>@now@ - will be replaced with the current timestamp</li>
<li>@filename@ - will be replaced with the basename of the uploaded file from the filename property if present</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.iconUrl(file, options)</code></p>
<p>  Returns constructed icon url from the icon record</p>
</li>
</ul>

<ul>
<li><p><code>api.sendIcon(req, id, options)</code></p>
<p>  Send an icon to the client, only handles files</p>
</li>
</ul>

<ul>
<li><p><code>api.putIcon(req, name, id, options, callback)</code></p>
<p>  Store an icon for account, the options are the same as for the <code>iconPath</code> method</p>
<ul>
<li>name is the name property to look for in the multipart body or in the request body or query</li>
<li>id is used in <code>iconPath</code> along with the options to build the icon absolute path</li>
<li>autodel - if true, auto delete the base64 icon property from the query or the body after it is decoded, this is to
mark it for deallocation while the icon is being processed, the worker queue is limited so with large number of requests
all these query objects will remain in the query wasting memory</li>
<li>verify - check the given image of file header for known image types</li>
<li>extkeep - a regexp with image types to preserve, not to convert into the specified image type</li>
<li>ext - the output file extention without dot, ex: jpg, png, gif....</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.saveIcon(file, id, options, callback)</code></p>
<p>  Save the icon data to the destination, if api.imagesS3 or options.imagesS3 specified then plave the image on the S3 drive.
Store in the proper location according to the types for given id, this function is used after downloading new image or
when moving images from other places. On success the callback will be called with the second argument set to the output
file name where the image has been saved.
Valid properties in the options:</p>
<ul>
<li>type - icon type, this will be prepended to the name of the icon, there are several special types:<ul>
<li>@uuid@ - auto generate an UUID</li>
<li>@now@ - use current timestamp</li>
<li>@filename@ - if filename is present the basename without extension will be used</li>
</ul>
</li>
<li>prefix - top level subdirectory under images/</li>
<li>width, height, filter, ext, quality for <code>scaleIcon</code> function</li>
<li>filesize - file size if available</li>
<li>filename - name of a file uploaded if available</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.delIcon(id, options, callback)</code></p>
<p>  Delete an icon for account, .type defines icon prefix</p>
</li>
</ul>

<ul>
<li><p><code>api.isIconUrl(url)</code></p>
<p>  Return true if the given file or url point ot an image</p>
</li>
</ul>

<ul>
<li><p><code>api.isIcon(buf)</code></p>
<p>  Returns detected image type if the given buffer contains an image, it checks the header only</p>
</li>
</ul>

<ul>
<li><p><code>api.getSessionCookie(req, name)</code></p>
<p>  Return named encrypted cookie</p>
</li>
</ul>

<ul>
<li><p><code>api.setSessionCookie(req, name, value)</code></p>
<p>  Set a cookie by name and domain, the value is always encrypted</p>
</li>
</ul>

<ul>
<li><p><code>api.handleSessionSignature(req, callback)</code></p>
<p>  Setup session cookies or access token for automatic authentication without signing, req must be complete with all required
properties after successful authorization.</p>
</li>
</ul>

<ul>
<li><p><code>api.checkAccountType(account, type)</code></p>
<p>  Return true if the current user belong to the specified type, account type may contain more than one type.
NOTE: after this call the <code>type</code> property is converted into an array</p>
</li>
</ul>

<ul>
<li><p><code>api.setCurrentAccount(req, account)</code></p>
<p>  Assign or clear the current account record for the given request, if account is null the account is cleared.
All columns in the auth table marked with the <code>auth</code> property will be also set in the <code>req.options.account</code> which is used
for permissions when the full account record is not available and only the options are passed.</p>
</li>
</ul>

<ul>
<li><p><code>api.getOptions(req, controls)</code></p>
<p>  Convert query options into internal options, such options are prepended with the underscore to
distinguish control parameters from the query parameters.</p>
<p>For security purposes this is the only place that translates special control query parameters into the options properties,
all the supported options are defined in the <code>api.controls</code> and can be used by the apps freely but with caution. See <code>registerControlParams</code>.</p>
<p>if <code>controls</code> is an object it will be used to define additional control parameters or override existing ones for this request only. Same rules as for
<code>registerControlParams</code> apply.</p>
<pre><code>    api.getOptions(req, { count: { min: 5, max: 100 } })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.getQuery(req, params, options)</code></p>
<p>  Parse query parameters according to the <code>params</code>. Uses global api defaults, if provided in options as well defaults are all merged.</p>
<p>Returns a query object or an error message or null</p>
<pre><code>   var query = api.getQuery(req, { q: { required: 1 } }, { null: 1 });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.getTokenSecret(req)</code></p>
<p>  Return a secret to be used for enrypting tokens, it uses the account property if configured or the global API token
to be used to encrypt data and pass it to the clients. <code>-api-query-token-secret</code> can be configured and if a column in the <code>bk_user</code>
with such name exists it is used as a secret, otherwise the value of this property is used as a secret.</p>
</li>
</ul>

<ul>
<li><p><code>api.getResultPage(req, options, rows, info)</code></p>
<p>  Return an object to be returned to the client as a page of result data with possibly next token
if present in the info. This result object can be used for pagination responses.</p>
</li>
</ul>

<ul>
<li><p><code>api.getPublicColumns(table, options)</code></p>
<p>  Columns that are allowed to be visible, used in select to limit number of columns to be returned by a query</p>
<ul>
<li>pub property means public column</li>
<li>admins property means visible to admins and owners only</li>
</ul>
<p>options may be used to define the following properties:</p>
<ul>
<li><p>skip - a regexp with names to be excluded as well</p>
</li>
<li><p>allow - a list of properties which can be checked along with the <code>pub</code> property for a column to be considered public</p>
</li>
<li><p>disallow - a list of properties which if set will prevent a column to be returned, it is checked before the &#39;allow&#39; rule</p>
<p>api.getPublicColumns(&quot;bk_user&quot;, { allow: [&quot;admins&quot;], skip: /device_id|0$/ });</p>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.cleanupResult(table, data, options)</code></p>
<p>  Process records and keep only public properties as defined in the table columns. This method is supposed to be used in the post process
callbacks after all records have been processes and are ready to be returned to the client, the last step would be to cleanup
all non public columns if necessary.</p>
<p><code>table</code> can be a single table name or a list of table names which combined public columns need to be kept in the rows. List of request tables
is kept in the <code>req.options.cleanup</code> which by default is empty.</p>
<p>By default primary keys are not kept and must be marked with <code>pub</code> property in the table definition to be returned.</p>
<p>If any column is marked with <code>priv</code> property this means never return that column in the result even for the owner of the record</p>
<p>The <code>options.isInternal</code> allows to return everything except secure columns</p>
<p>Columns with the <code>pub_admin</code> property will be returned only if the options contains <code>isAdmin</code>, same with the <code>pub_staff</code> property, it requires <code>options.isStaff</code>.</p>
<p>To return data based on the current account roles a special property in the format <code>pub_types</code> must be set as a string or an array
with roles to be present in the current account <code>type`` field. This is checked only if the column is allowed, this is an additional restriction, i.e. a column must be allowed by the </code>pub` property or other way.</p>
<p>To retstrict by role define <code>priv_types</code> in a column with a list of roles which should be denied access to the field.</p>
<p>The <code>options.pool</code> property must match the actual rowset to be applied properly, in case the records
have been retrieved for the different database pool.</p>
<p>The <code>options.cleanup_strict</code> will enforce that all columns not present in the table definition will be skipped as well, by default all
new columns or columns created on the fly are returned to the client. <code>api.cleanupStrict</code> can be configured globbly.</p>
<p>The <code>options.cleanup_rules</code> can be an object with property names and the values 0, or 1 for <code>pub</code> or <code>2</code> for <code>admin`` or </code>3<code>for</code>staff``</p>
<p>The <code>options.cleanup_copy</code> means to return a copy of every modified record, the original data is preserved</p>
</li>
</ul>

<ul>
<li><p><code>api.clearQuery(table, query, options)</code></p>
<p>  Clear request query properties specified in the table definition or in custom schema.</p>
<p>The <code>table</code> argument can be a table name or an object with properties as columns.</p>
<p>If <code>options.filter</code> is not specified the <code>query</code> will only keep existing columns for the given table.</p>
<p>If <code>options.filter</code> is a list then the <code>query</code> will delete properties for columns that contain any specified
property from the filter list. This is used for the <code>bk_user</code> table to remove properties that supposed to be updated by admins only.
The filter will keep non-existent columns in the <code>query</code>. To remove such columns when using the filter specify <code>options.force</code>.</p>
<p>If a name in the filter is prefixed with ! then the logic is reversed, keep all except this property</p>
<p>If <code>options.keep</code> is a regexp it will be used to keep matched properties by name in the <code>query</code> regardless of any condition.</p>
<p>If <code>options.clear</code> is a regexp it will be used to remove matched properties by name in the <code>query</code>.</p>
<p> Example:</p>
<pre><code>   api.clearQuery(&quot;bk_user&quot;, req.query)
   api.clearQuery(&quot;bk_user&quot;, req.query, &quot;internal&quot;)
   api.clearQuery(&quot;bk_user&quot;, req.query, { filter: &quot;internal&quot; })
   api.clearQuery(&quot;bk_user&quot;, req.query, { filter: [&quot;internal&quot;] })
   api.clearQuery(&quot;bk_user&quot;, req.query, { filter: [&quot;!pub&quot;] })
   api.clearQuery(&quot;bk_user&quot;, req.query, { filter: [&quot;internal&quot;,&quot;priv&quot;] })
   api.clearQuery(&quot;bk_user&quot;, req.query, { filter: [&quot;internal&quot;,&quot;!priv&quot;], keep: /^__/ })
   api.clearQuery({ name: {}, id: { admin: 1 } }, req.query, { filter: [&quot;internal&quot;] })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>api.handleWebSocketUpgrade(req, socket, head)</code></p>
<p>  Check if the request is allowed to upgrade to Websocket</p>
</li>
</ul>

<ul>
<li><p><code>api.handleWebSocketConnect(ws, req)</code></p>
<p>  Wrap external WebSocket connection into the Express routing, respond on backend command</p>
</li>
</ul>

<ul>
<li><p><code>api.handleWebSocketRequest(ws, data)</code></p>
<p>  Wrap WebSocket into HTTP request to be proceses by the Express routes</p>
</li>
</ul>

<ul>
<li><p><code>api.wsSet(type, req, value)</code></p>
<p>  Update a Websocket connection properties:</p>
<ul>
<li>query - set query with a new object, this is used in the wsNotify broadcasts to match who can receive messages. Initially it is set to the
 query from the first connection.</li>
<li>account - update the current socket account object with new properties</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>api.wsSend(wsid, msg)</code></p>
<p>  Send to a websocket inside an api server directly</p>
</li>
</ul>

<ul>
<li><p><code>api.wsNotify(options, msg, callback)</code></p>
<p>  Broadcast a message according to the options, if no websocket queue is defined send directly using <code>wsBroadcast</code></p>
</li>
</ul>

<ul>
<li><p><code>api.wsBroadcast(options, msg)</code></p>
<p>  Send a message to all websockets inside an api process that match the criteria from the options:</p>
<ul>
<li>path - a regexp to match initial Websocket connection url</li>
<li>account_id - send to websockets belonginh to the account, can be a list as well to notify multiple accounts</li>
<li>account - an object to  be used for condition against Websocket&#39;s accounts, <code>lib.isMatched</code> is used for comparison</li>
<li>wsid - send to the specific websocket(s), can be a list</li>
<li>query - an object to be used for condition against Websocket&#39;s query, <code>lib.isMatched</code> is used for comparison</li>
<li>cleanup - a table name to be used for message cleanup using <code>api.cleanupResult</code>, if it is an array then
the first item is a table and the second item is the property name inside the <code>msg</code> to be cleanup only, eg. cleanup: [&quot;bk_user&quot;,&quot;user&quot;].
All properties starting with <code>is`` or </code>cleanup_`` will be passed to the cleanupResult.</li>
<li>preprocess - a function(ws, options, msg) to be called before sending in order to possibly modify the message for this
 particular account, i.e. for permissions checks, if it needs to be modified return a copy otherwise the original will be used, returning
 null will skip this socket</li>
<li>method - a string in the format <code>module.method</code> to run the same way as the <code>preprocess</code> function, this is a more
 reliable way to be use preprocess with <code>wsNotify</code></li>
</ul>
</li>
</ul>

<h2 id="module-app">Module: app</h2>
<p>   Author: Vlad Seryakov <a href="mailto:vseryakov@gmail.com">vseryakov@gmail.com</a>
   backendjs 2018</p>
<p>  This is a skeleton module to be extended by the specific application logic. It provides all
  callbacks and hooks that are called by the core backend modules
  during different phases, like initialization, shutting down, etc...</p>
<p>  It should be used for custom functions and methods to be defined, the <code>app</code> module is always available.</p>
<p>  All app modules in the modules/ subdirectory use the same prototype, i.e. all hooks are available for custom app modules as well.</p>

<ul>
<li><p><code>app.configure(options, callback) </code></p>
<p>  Called after all config files are loaded and command line args are parsed, home directory is set but before the db is initialized,
the primary purpose of this early call is to setup environment before connecting to the database. This is called regardless of the server
to be started and intended to initialize the common environment before the database and other subsystems are initialized.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureModule(options, callback) </code></p>
<p>  Called after the core.init has been initialized successfully, this can be redefined in the applications to add additional
init steps that all processes require to have. All database pools and other confugration is ready at this point. This hook is
called regardless of what kind of server is about to start, it is always called before starting a server or shell.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureMiddleware(options, callback) </code></p>
<p>  This handler is called during the Express server initialization just after the security middleware.</p>
<p>NOTE: <code>api.app</code> refers to the Express instance.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureWeb(options, callback) </code></p>
<p>  This handler is called after the Express server has been setup and all default API endpoints initialized but the Web server
is not ready for incoming requests yet. This handler can setup additional API endpoints, add/modify table descriptions.</p>
<p>NOTE: <code>api.app</code> refers to the Express instance</p>
</li>
</ul>

<ul>
<li><p><code>app.shutdownWeb(options, callback) </code></p>
<p>  Perform shutdown sequence when a Web process is about to exit</p>
<p>NOTE: <code>api.app</code> refers to the Express instance</p>
</li>
</ul>

<ul>
<li><p><code>app.configureMaster(options, callback) </code></p>
<p>  This handler is called during the master server startup, this is the process that monitors the worker jobs and performs jobs scheduling</p>
</li>
</ul>

<ul>
<li><p><code>app.configureServer(options, callback) </code></p>
<p>  This handler is called during the Web server startup, this is the master process that creates Web workers for handling Web requests, this process
interacts with the Web workers via IPC sockets between processes and relaunches them if any Web worker dies.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureWorker(options, callback) </code></p>
<p>  This handler is called on job worker instance startup after the tables are intialized and it is ready to process the job</p>
</li>
</ul>

<ul>
<li><p><code>app.shutdownWorker(options, callback) </code></p>
<p>  Perform last minute operations inside a worker process before exit, the callback must be called eventually which will exit the process.
This method can be overrided to implement custom worker shutdown procedure in order to finish pending tasks like network calls.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureMonitor(options, callback) </code></p>
<p>  This callback is called when the monitor process is ready, there is no any other code is supposed to run inside the monitor, but
in case it is needed, this is the hook to be used.</p>
</li>
</ul>

<ul>
<li><p><code>app.configureShell(options, callback) </code></p>
<p>  This callback is called by the shell process to setup additional command or to execute a command which is not
supported by the standard shell. Setting options.done to 1 will stop the shell, this is a signal that command has already
been processed.</p>
</li>
</ul>

<h2 id="module-auth">Module: auth</h2>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>auth-table</code>, descr: &quot;Table to use for user accounts&quot;</li>
<li><code>auth-err-(.+)</code>, descr: &quot;Error messages for various cases&quot;</li>
<li><code>auth-admin-roles</code>, type: &quot;list&quot;, descr: &quot;List of special super admin roles&quot;</li>
<li><code>auth-sigversion</code>, type: &quot;int&quot;, descr: &quot;Signature version for secrets&quot;</li>
<li><code>auth-hash</code>, descr: &quot;Hashing method to use by default: bcrypt, argon2, none&quot;</li>
<li><code>auth-bcrypt</code>, type: &quot;int&quot;, min: 12, descr: &quot;Number of iterations for bcrypt&quot;</li>
<li><code>auth-argon2</code>, type: &quot;map&quot;, maptype: &quot;auto&quot;, nocamel: 1, descr: &quot;Argon2 parameteres, ex: type:2,memoryCost:1,hashLength:32&quot;</li>
<li><code>auth-max-length</code>, type: &quot;int&quot;, descr: &quot;Max login and name length&quot;</li>
<li><code>auth-users</code>, type: &quot;json&quot;, logger: &quot;error&quot;, descr: &quot;An object with users&quot;</li>
<li><code>auth-users-file</code>, descr: &quot;A JSON file with a list of users&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>auth.loadUsers(callback)</code></p>
<p>  Load users from a JSON file, only add or update records</p>
</li>
</ul>

<ul>
<li><p><code>auth.prepareSecret(query, options, callback)</code></p>
<p>  If specified in the options, prepare credentials to be stored in the db, if no error occurred return null, otherwise an error object</p>
<ul>
<li>hash - use bcrypt or argon2 explicitely, otherwise use the config</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>auth.checkSecret(user, password, callback)</code></p>
<p>  Verify an existing user record with given password,</p>
<ul>
<li>user - if a string it is a hashed secret from an existing user record, otherwise must be an user object</li>
<li>password - plain text password or other secret passed to be verified</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>auth.get(query, options, callback)</code></p>
<p>  Returns an account record by login or id, to make use of a cache add to the config <code>db-cache-keys-bk_user-id=id</code></p>
</li>
</ul>

<ul>
<li><p><code>auth.add(query, options, callback)</code></p>
<p>  Registers a new account, returns new record in the callback, when <code>options.isInternal</code> is true then allow to set all properties
otherwise internal properties will not be added</p>
</li>
</ul>

<ul>
<li><p><code>auth.update(query, options, callback)</code></p>
<p>  Updates an existing account by login or id, if <code>options.isInternal</code> is true then allow to update all properties, returns a new record in the callback</p>
</li>
</ul>

<ul>
<li><p><code>auth.del(query, options, callback)</code></p>
<p>  Deletes an existing account by login or id, no admin checks, returns the old record in the callback</p>
</li>
</ul>

<h2 id="module-aws">Module: aws</h2>
<p>  AWS Cloud API interface</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>aws-key</code>, descr: &quot;AWS access key&quot;</li>
<li><code>aws-secret</code>, descr: &quot;AWS access secret&quot;</li>
<li><code>aws-token</code>, descr: &quot;AWS security token&quot;</li>
<li><code>aws-region</code>, descr: &quot;AWS region&quot;, pass: 1</li>
<li><code>aws-zone</code>, descr: &quot;AWS availability zone&quot;</li>
<li><code>aws-meta</code>, type: &quot;bool&quot;, descr: &quot;Retrieve instance metadata, 0 to disable&quot;</li>
<li><code>aws-sdk-profile</code>, descr: &quot;AWS SDK profile to use when reading credentials file&quot;</li>
<li><code>aws-sns-app-arn</code>, descr: &quot;SNS Platform application ARN to be used for push notifications&quot;</li>
<li><code>aws-key-name</code>, descr: &quot;AWS instance keypair name for remote job instances or other AWS commands&quot;</li>
<li><code>aws-elb-name</code>, descr: &quot;AWS ELB name to be registered with on start up or other AWS commands&quot;</li>
<li><code>aws-target-group</code>, descr: &quot;AWS ELB target group to be registered with on start up or other AWS commands&quot;</li>
<li><code>aws-elastic-ip</code>, descr: &quot;AWS Elastic IP to be associated on start&quot;</li>
<li><code>aws-host-name</code>, type: &quot;list&quot;, descr: &quot;List of hosts to update in Route54 zone with the current private IP address, hosts must be in FQDN format, supports @..@ core.instance placeholders&quot;</li>
<li><code>aws-iam-profile</code>, descr: &quot;IAM instance profile name for instances or commands&quot;</li>
<li><code>aws-image-id</code>, descr: &quot;AWS image id to be used for instances or commands&quot;</li>
<li><code>aws-subnet-id</code>, descr: &quot;AWS subnet id to be used for instances or commands&quot;</li>
<li><code>aws-vpc-id</code>, descr: &quot;AWS VPC id to be used for instances or commands&quot;</li>
<li><code>aws-group-id</code>, array: 1, descr: &quot;AWS security group(s) to be used for instances or commands&quot;</li>
<li><code>aws-instance-type</code>, descr: &quot;AWS instance type to launch on demand&quot;</li>
<li><code>aws-account-id</code>, descr: &quot;AWS account id if not running on an instance&quot;</li>
<li><code>aws-eni-id</code>, type: &quot;list&quot;, descr: &quot;AWS Elastic Network Interfaces to attach on start, format is: eni[:index],eni...&quot;</li>
<li><code>aws-config-parameters</code>, descr: &quot;Prefix for AWS Config Parameters Store to load and parse as config before initializing the database pools, example: /bkjs/config/&quot;</li>
<li><code>aws-set-parameters</code>, type: &quot;list&quot;, descr: &quot;AWS Config Parameters Store to set on start, supports @..@ core.instance placeholders: format is: path:value,....&quot;</li>
<li><code>aws-conf-file</code>, descr: &quot;S3 url for config file to download on start&quot;</li>
<li><code>aws-conf-file-interval</code>, type: &quot;int&quot;, descr: &quot;Load S3 config file every specified interval in minites&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.configure(options, callback)</code></p>
<p>  Initialization of metadata</p>
</li>
</ul>

<ul>
<li><p><code>aws.configureServer(options, callback)</code></p>
<p>  Execute on Web server startup</p>
</li>
</ul>

<ul>
<li><p><code>aws.configureMaster(options, callback)</code></p>
<p>  Execute on master server startup</p>
</li>
</ul>

<ul>
<li><p><code>aws.configureJob(options, callback)</code></p>
<p>  Process AWS alarms and state notifications, if such a job is pulled from SQS queue it is handled here and never get to the jobs.
SNS alarms or EventBridge events must use a SQS qeue as the target.</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryIAM(action, obj, options, callback)</code></p>
<p>  AWS AIM API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.querySTS(action, obj, options, callback)</code></p>
<p>  AWS STS API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryCFN(action, obj, options, callback)</code></p>
<p>  AWS CFN API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryElastiCache(action, obj, options, callback)</code></p>
<p>  AWS Elastic Cache API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryAS(action, obj, options, callback)</code></p>
<p>  AWS Autoscaling API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryRekognition(action, obj, options, callback)</code></p>
<p>  Make a request to the Rekognition service</p>
</li>
</ul>

<ul>
<li><p><code>aws.querySSM(action, obj, options, callback)</code></p>
<p>  AWS SSM API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryACM(action, obj, options, callback)</code></p>
<p>  AWS ACM API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryComprehend(action, obj, options, callback)</code></p>
<p>  AWS Comprehend API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryTranscribe(action, obj, options, callback)</code></p>
<p>  AWS Transcribe API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryECS(action, obj, options, callback)</code></p>
<p>  AWS ECS API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryECR(action, obj, options, callback)</code></p>
<p>  AWS ECR API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.getTagValue(obj, key)</code></p>
<p>  Returns a tag value by key, default key is Name</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryCW(action, obj, options, callback)</code></p>
<p>  AWS CloudWatch API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryCWL(action, obj, options, callback)</code></p>
<p>  AWS CloudWatch Log API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.cwPutMetricAlarm(options, callback)</code></p>
<p>  Creates or updates an alarm and associates it with the specified Amazon CloudWatch metric.
The options specify the following:</p>
<ul>
<li>name - alarm name, if not specified metric name and dimensions will be used to generate alarm name</li>
<li>metric - metric name, default is <code>CPUUtilization</code></li>
<li>namespace - AWS namespace, default is <code>AWS/EC2</code></li>
<li>op - comparison operator, one of =&gt; | &lt;= | &gt; | &lt; | GreaterThanOrEqualToThreshold | GreaterThanThreshold | LessThanThreshold | LessThanOrEqualToThreshold. Default is <code>&gt;=</code>.</li>
<li>statistic - one of SampleCount | Average | Sum | Minimum | Maximum, default is <code>Average</code></li>
<li>period - collection period in seconds, default is <code>60</code></li>
<li>evaluationPeriods - the number of periods over which data is compared to the specified threshold, default is <code>15</code></li>
<li>threshold - the value against which the specified statistic is compared, default is <code>90</code></li>
<li>ok - ARN(s) to be notified on OK state</li>
<li>alarm - ARN(s) to be notified on ALARM state</li>
<li>insufficient_data - ARN(s) to be notified on INSUFFICIENT_DATA state</li>
<li>dimensions - the dimensions for the alarm&#39;s associated metric.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.cwPutMetricData(namespace, data, options, callback)</code></p>
<p>  Publishes metric data points to Amazon CloudWatch.
The argumernts specify the following:</p>
<ul>
<li>namespace - custome namespace, cannot start with <code>AWS</code></li>
<li>data - an object with metric data:
{ metricName: value }, ...
{ metricName: {
   value: Number,
   dimension1: name1,
   ..
},
}, ...
{ metricName: {
   value: [min, max, sum, sample],
   dimension1: ...
},
}, ...</li>
</ul>
<p>The options can specify the following:</p>
<ul>
<li>storageResolution - 1 to use 1 second resolution</li>
<li>timestamp - ms to be used as the timestamp instead of the current time</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.cwListMetrics(options, callback)</code></p>
<p>  Return metrics for the given query, the options can be specified:</p>
<ul>
<li>name - a metric name</li>
<li>namespace - limit by namespace: AWS/AutoScaling, AWS Billing, AWS/CloudFront, AWS/DynamoDB, AWS/ElastiCache, AWS/EBS, AWS/EC2, AWS/ELB, AWS/ElasticMapReduce, AWS/Kinesis, AWS/OpsWorks, AWS/Redshift, AWS/RDS, AWS/Route53, AWS/SNS, AWS/SQS, AWS/SWF, AWS/StorageGateway</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.cwGetMetricData(options, callback)</code></p>
<p>  Return collected metric statistics</p>
<p>Options:</p>
<ul>
<li>start_time - starting timestamp</li>
<li>end_time - ending timestamp</li>
<li>period - aggregation period in seconds, default is 60</li>
<li>age - number of hours to go back in case end_time is not specified, fraction can be used, default is 1h if no timestamp are given</li>
<li>namespace - namespace for all metrics, default is AWS/EC2</li>
<li>metrics - a list with metrics to retrieve: { name: &quot;..&quot;, stat: &quot;..&quot;, dimensions: { key: val, ...}, [namespace: &quot;..&quot;], [label: &quot;..&quot;&quot;] }</li>
</ul>
<p>Example:</p>
<pre><code>aws.cwGetMetricData({ age: 5, metrics: [{ name: &quot;NetworkOut&quot;, label: &quot;Traffic&quot;, stat: &quot;Average&quot;, dimensions: { InstanceId: &quot;i-1234567&quot; } } ] }, lib.log)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.cwlFilterLogEvents(options, callback)</code></p>
<p>  Lists log events from the specified log group. You can list all the log events or filter the results using a filter pattern,
a time range, and the name of the log stream.
Options:</p>
<ul>
<li>name - a group name, required</li>
<li>count - how many events to retrieve in one batch, 10000</li>
<li>limit - total number of events to return</li>
<li>filter - filter pattern</li>
<li>stime - start time in ms</li>
<li>etime - end time in ms</li>
<li>prefix - log stream prefix pattern</li>
<li>names - list of log streams to filter</li>
<li>token - a previous token to start with</li>
<li>timeout - how long to keep reading or waiting, ms</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws._queryDDB(target, service, action, obj, options, callback)</code></p>
<p>  DynamoDB requests</p>
</li>
</ul>

<ul>
<li><p><code>aws.toDynamoDB(value, level)</code></p>
<p>  Convert a Javascript object into DynamoDB object</p>
</li>
</ul>

<ul>
<li><p><code>aws.fromDynamoDB(value, level)</code></p>
<p>  Convert a DynamoDB object into Javascript object</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryExpression(params, obj, options, join)</code></p>
<p>  Build a condition expression for the given object, all properties in the obj are used</p>
</li>
</ul>

<ul>
<li><p><code>aws.ddbListTables(options, callback)</code></p>
<p>  Return list of tables in .TableNames property of the result</p>
<p>Example:</p>
<pre><code>     { TableNames: [ name, ...] }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbDescribeTable(name, options, callback)</code></p>
<p>  Return table definition and parameters in the result structure with property of the given table name</p>
<p>Example:</p>
<pre><code>     { name: { AttributeDefinitions: [], KeySchema: [] ...} }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbCreateTable(name, attrs, options, callback)</code></p>
<p>  Create a table</p>
<ul>
<li>attrs can be an array in native DDB JSON format or an object with name:type properties, type is one of S, N, NN, NS, BS</li>
<li>options may contain any valid native property if it starts with capital letter and the following:<ul>
<li>waitTimeout - number of milliseconds to wait for ACTIVE status</li>
<li>waitDelay - how often to pool for table status, default is 250ms</li>
<li>keys is an array of column ids used for the primary key or a string with the hash key. if omitted, the first attribute will be used for the primary key</li>
<li>local - an object with each property for a local secondary index name defining key format the same way as for primary keys, all Uppercase properties are added to the top index object</li>
<li>global - an object for global secondary indexes, same format as for local indexes</li>
<li>projections - an object with index name and list of projected properties to be included in the index or &quot;ALL&quot; for all properties, if omitted then default KEYS_ONLY is assumed</li>
<li>readCapacity - read capacity units for provisioned throughput</li>
<li>writeCapacity - write capacity units</li>
<li>onDemand - billing mode, auto provision capacity and pay per request, if no read/write capacity is configured on-demand is the default</li>
<li>stream - enable stream support</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     ddbCreateTable(&#39;users&#39;, { id: &#39;S&#39;, mtime: &#39;N&#39;, name: &#39;S&#39;},
                             { keys: [&quot;id&quot;, &quot;name&quot;],
                               local: { mtime: { mtime: &quot;HASH&quot; } },
                               global: { name: { name: &#39;HASH&#39;, ProvisionedThroughput: { ReadCapacityUnits: 50 } } },
                               projections: { mtime: [&#39;gender&#39;,&#39;age&#39;],
                                              name: [&#39;name&#39;,&#39;gender&#39;] },
                               stream: &quot;NEW_IMAGE&quot;,
                               readCapacity: 10,
                               writeCapacity: 10 });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbUpdateTable(options, callback)</code></p>
<p>  Update tables provisioned throughput settings, options is used instead of table name so this call can be used directly in the cron jobs to adjust
provisionined throughput on demand.
Options must provide the following properties:</p>
<ul>
<li>name - table name</li>
<li>readCapacity and writeCapacity - new povisioned throughtput settings, both must be specified</li>
<li>stream - null to disable or one of the NEW_IMAGE | OLD_IMAGE | NEW_AND_OLD_IMAGES | KEYS_ONLY</li>
<li>add - an object with indexes to create</li>
<li>del - delete a global secondary index by name, a string or a list with multiple indexes</li>
<li>update - an object with indexes to update</li>
<li>waitTimeout - how long to wait in ms until the table is active again</li>
<li>onDemand - true to switch to pat per request mode, false to switch to provisioning mode</li>
</ul>
<p> Example</p>
<pre><code>         aws.ddbUpdateTable({ name: &quot;users&quot;, add: { name_id: { name: &quot;S&quot;, id: &#39;N&#39;, readCapacity: 20, writeCapacity: 20, projections: [&quot;mtime&quot;,&quot;email&quot;] } })
         aws.ddbUpdateTable({ name: &quot;users&quot;, add: { name: { name: &quot;S&quot;, readCapacity: 20, writeCapacity: 20, projections: [&quot;mtime&quot;,&quot;email&quot;] } })
         aws.ddbUpdateTable({ name: &quot;users&quot;, del: &quot;name&quot; })
         aws.ddbUpdateTable({ name: &quot;users&quot;, update: { name: { readCapacity: 10, writeCapacity: 10 } })
</code></pre>
<p>Example of crontab job in etc/crontab:</p>
<pre><code>         [
         { &quot;type&quot;: &quot;server&quot;, &quot;cron&quot;: &quot;0 0 1 * * *&quot;, &quot;job&quot;: { &quot;aws.ddbUpdateTable&quot;: { &quot;name&quot;: &quot;bk_user&quot;, &quot;readCapacity&quot;: 1000, &quot;writeCapacity&quot;: 1000 } } },
         { &quot;type&quot;: &quot;server&quot;, &quot;cron&quot;: &quot;0 0 6 * * *&quot;, &quot;job&quot;: { &quot;aws.ddbUpdateTable&quot;: { &quot;name&quot;: &quot;bk_user&quot;, &quot;readCapacity&quot;: 2000, &quot;writeCapacity&quot;: 2000 } } }
         ]
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbUpdateTimeToLive(options, callback)</code></p>
<p>  Update TTL attribute.
The options properties:</p>
<ul>
<li>name - table name</li>
<li>attribute - the attribute name</li>
<li>enabled - true or false</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.ddbDescribeTimeToLive(name, options, callback)</code></p>
<p>  Returns status of Time to live attribute for a table</p>
</li>
</ul>

<ul>
<li><p><code>aws.ddbDeleteTable(name, options, callback)</code></p>
<p>  Remove a table from the database.
By default the callback will ba callled only after the table is deleted, specifying <code>options.nowait</code> will return immediately</p>
</li>
</ul>

<ul>
<li><p><code>aws.ddbWaitForTable(name, item, options, callback)</code></p>
<p>  Call the callback after specified period of time or when table status become different from the given waiting status.
if options.waitTimeout is not specified calls the callback immediately. options.waitStatus is checked if given and keeps waiting
while the status is equal to it. options.waitDelay can be specified how often to request new status, default is 250ms.</p>
</li>
</ul>

<ul>
<li><p><code>aws.ddbPutItem(name, item, options, callback)</code></p>
<p>  Put or add an item</p>
<ul>
<li>item is an object, type will be inferred from the native js type.</li>
<li>options may contain any valid native property if it starts with capital letter or special properties:<ul>
<li>expected - an object with column names to be used in Expected clause and value as null to set condition to { Exists: false } or
any other exact value to be checked against which corresponds to { Exists: true, Value: value }</li>
<li>expectedJoin - how to join conditions, default is AND</li>
<li>expr - condition expression</li>
<li>values - an object with values map to be used for in the update and/or condition expressions, to be used
for ExpressionAttributeValues parameters</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
for ExpressionAttributeNames parameter</li>
<li>returning - values to be returned on success, any value means ALL_OLD</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     ddbPutItem(&quot;users&quot;, { id: 1, name: &quot;john&quot;, mtime: 11233434 }, { expected: { name: null } })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbUpdateItem(name, keys, item, options, callback)</code></p>
<p>  Update an item</p>
<ul>
<li>keys is an object with primary key attributes name and value.</li>
<li>item is an object with properties where value can be:<ul>
<li>number/string/array - action PUT, replace or add new value</li>
<li>null/empty string - action DELETE</li>
</ul>
</li>
<li>item can be a string with Update expression</li>
<li>options may contain any valid native property if it starts with capital letter or special properties:<ul>
<li>expr - condition expression</li>
<li>values - an object with values map to be used for in the update and/or condition expressions, to be used
  for ExpressionAttributeValues parameters</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
  for ExpressionAttributeNames parameter</li>
<li>updateOps - an object with operators to be used for properties, one of the: set, remove, unset, delete, incr, add, append, prepend, not_exists</li>
<li>expected - an object with columns to be used in ConditionExpression, value null means the attribute does not exists,
  any other value to be checked against using regular compare rules. The conditional comparison operator is taken
  from <code>options.ops</code> the same way as for queries.</li>
<li>returning - values to be returned on success, <code>*</code> or <code>new</code> means ALL_NEW, <code>old</code> means ALL_OLD,
        <code>updated</code> means UPDATED_NEW, <code>old_updated</code> means UPDATED_OLD</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     ddbUpdateItem(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, { gender: &#39;male&#39;, icons: &#39;1.png&#39; }, { action: { icons: &#39;add&#39; }, expected: { id: 1 }, returning: &quot;*&quot; })
     ddbUpdateItem(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, { gender: &#39;male&#39;, icons: &#39;1.png&#39; }, { action: { icons: &#39;incr&#39; }, expected: { id: null } })
     ddbUpdateItem(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, { gender: &#39;male&#39;, icons: &#39;1.png&#39;, num: 1 }, { action: { num: &#39;add&#39;, icons: &#39;add&#39; }, expected: { id: null, num: 0 }, ops: { num: &quot;gt&quot; } })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbDeleteItem(name, keys, options, callback)</code></p>
<p>  Delete an item from a table</p>
<ul>
<li>keys is an object with name: value for hash/range attributes</li>
<li>options may contain any valid native property if it starts with capital letter and the following special options:<ul>
<li>expr - condition expression</li>
<li>values - an object with values map to be used for in the update and/or condition expressions, to be used
  for ExpressionAttributeValues parameters</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
  for ExpressionAttributeNames parameter</li>
<li>returning - values to be returned on success, any value means ALL_OLD</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     ddbDeleteItem(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, {})
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbBatchWriteItem(items, options, callback)</code></p>
<p>  Update items from the list at the same time</p>
<ul>
<li>items is a list of objects with table name as property and list of operations, an operation can be PutRequest or DeleteRequest</li>
<li>options may contain any valid native property if it starts with capital letter.</li>
</ul>
<p>Example:</p>
<pre><code>     { table: [ { put: { id: 1, name: &quot;tt&quot; } }, { del: { id: 2 } }] }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbBatchGetItem(items, options, callback)</code></p>
<p>  Retrieve all items for given list of keys</p>
<ul>
<li>items is an object with table name as property name and list of options for GetItem request</li>
<li>options may contain any valid native property if it starts with capital letter.</li>
</ul>
<p>Example:</p>
<pre><code>     { users: { keys: [{ id: 1, name: &quot;john&quot; },{ id: .., name: .. }], select: [&#39;name&#39;,&#39;id&#39;], consistent: true }, ... }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbGetItem(name, keys, options, callback)</code></p>
<p>  Retrieve one item by primary key</p>
<ul>
<li>keys - an object with primary key attributes name and value.</li>
<li>select - list of columns to return, otherwise all columns will be returned</li>
<li>options may contain any native property allowed in the request or special properties:<ul>
<li>consistent - set consistency level for the request</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
  for ExpressionAttributeNames parameter</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>  ddbGetItem(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, { select: &#39;id,name&#39; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbQueryTable(name, condition, options, callback)</code></p>
<p>  Query on a table, return all matching items</p>
<ul>
<li>condition is an object with name: value pairs, by default EQ opeartor is used for comparison</li>
<li>options may contain any valid native property if it starts with capital letter or special property:<ul>
<li>start - defines starting primary key when paginating, can be a string/number for hash or an object with hash/range properties</li>
<li>consistent - set consistency level for the request</li>
<li>select - list of attributes to get only</li>
<li>total - return number of matching records</li>
<li>count - limit number of record in result</li>
<li>desc - descending order</li>
<li>sort - index name to use, indexes are named the same as the corresponding column, with index primary keys for Keycondition will be used</li>
<li>ops - an object with operators to be used for properties if other than EQ.</li>
<li>keys - list of primary key columns, if there are other properties in the condition then they will be
   put into QueryFilter instead of KeyConditions. If keys are absent, all properties in the condition are treated as primary keys.</li>
<li>projection - projection expression</li>
<li>values - an object with values map to be used for in the update and/or condition expressions, to be used
  for ExpressionAttributeValues parameters</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
  for ExpressionAttributeNames parameter</li>
<li>expr - filtering expression</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     aws.ddbQueryTable(&quot;users&quot;, { id: 1, name: &quot;john&quot; }, { select: &#39;id,name&#39;, ops: { name: &#39;gt&#39; } })
     aws.ddbQueryTable(&quot;users&quot;, { id: 1, name: &quot;john&quot;, status: &quot;ok&quot; }, { keys: [&quot;id&quot;], select: &#39;id,name&#39;, ops: { name: &#39;gt&#39; } })
     aws.ddbQueryTable(&quot;users&quot;, { id: 1 }, { expr: &quot;status=:s&quot;, values: { s: &quot;status&quot; } })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbScanTable(name, condition, options, callback)</code></p>
<p>  Scan a table for all matching items</p>
<ul>
<li>condition is an object with name: value pairs or a string with FilterExpression</li>
<li>options may contain any valid native property if it starts with capital letter or special property:<ul>
<li>start - defines starting primary key</li>
<li>ops - an object with operators to be used for properties if other than EQ.</li>
<li>projection - projection expression</li>
<li>values - an object with values map to be used for in the update and/or condition expressions, to be used
  for ExpressionAttributeValues parameters</li>
<li>names - an object with a map to be used for attribute names in condition and update expressions, to be used
  for ExpressionAttributeNames parameter</li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code>     aws.ddbScanTable(&quot;users&quot;, { id: 1, name: &#39;a&#39; }, { ops: { name: &#39;gt&#39; }})
     aws.ddbScanTable(&quot;users&quot;, &quot;id=:id AND name=:name&quot;, { values: { id: 1, name: &#39;a&#39; } });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ddbTransactWriteItems(items, options, callback)</code></p>
<p>  Update items from the list at the same time in one transaction, on any failure everything is rolled back</p>
<ul>
<li>items is a list of operations to be performed in the same format as for aws.ddbPutItem, aws.ddbUpdateItem, aws.ddbDeleteItem and aws.ddbQueryItem</li>
<li>options may contain any valid native property if it starts with capital letter.</li>
</ul>
<p>Example:</p>
<pre><code>     { op: &quot;put&quot;: table: &quot;table-name&quot;, obj: { id: 1, name: &quot;tt&quot; } },
     { op: &quot;del&quot;: table: &quot;table-name&quot;, obj: { id: 2 } },
     { op: &quot;update&quot;: table: &quot;table-name&quot;, obj: { id: 1, name: &quot;test&quot; }, options: { expected: { status: &quot;ok&quot; } } },
     { op: &quot;check&quot;: table: &quot;table-name&quot;, obj: { id: 1 }, options: { expected: { status: &quot;ok&quot; } } }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.queryEC2(action, obj, options, callback)</code></p>
<p>  AWS EC2 API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryELB(action, obj, options, callback)</code></p>
<p>  AWS ELB API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2RunInstances(options, callback)</code></p>
<p>  Run AWS instances, supports all native EC2 parameters with first capital letter but also accepts simple parameters in the options:</p>
<ul>
<li>min - min number of instances to run, default 1</li>
<li>max - max number of instances to run, default 1</li>
<li>imageId - AMI id, use aws.imageId if not given or options.ImageId attribute</li>
<li>instanceType - instance type, use aws.instanceType if not given or options.InstanceType attribute</li>
<li>keyName - Keypair, use aws.keyName if not given or options.KeyName attribute</li>
<li>data - user data, in clear text</li>
<li>terminate - set instance initiated shutdown behaviour to terminate</li>
<li>stop - set instance initiated shutdown behaviour to stop</li>
<li>groupId - one group id or an array with security group ids</li>
<li>ip - a static private IP adress to assign</li>
<li>publicIp - associate with a public IP address</li>
<li>file - pass contents of a file as user data, contents are read using sync method</li>
<li>noPrepare - even with additional tasks specified do not wai but return the context for aws.ec2PrepareInstance</li>
<li>waitTimeout - how long to wait in ms for instance to be runnable</li>
<li>waitDelay  - now often in ms to poll for status while waiting</li>
<li>waitRunning - if 1 then wait for instance to be in running state, this is implied also by elbName, name, elasticIp properties in the options</li>
<li>name - assign a tag to the instance as <code>Name:</code>, any occurences of %i will be replaced with the instance index</li>
<li>tags - additional tags to be assigned, an object with key:value</li>
<li>elbName - join elastic balancer after the startup</li>
<li>targetGroup - join ELB target group after the startup</li>
<li>elasticIp - asociate with the given Elastic IP address after the start</li>
<li>iamProfile - IAM profile to assign for instance credentials, if not given use aws.iamProfile or options[&#39;IamInstanceProfile.Name&#39;] attribute</li>
<li>availabilityZone - availability zone, if not given use aws.zone or options[&#39;Placement.AvailabilityZone&#39;] attribute</li>
<li>subnetId - subnet id, if not given use aws.subnetId or options.SubnetId attribute</li>
<li>alarms - a list with CloudWatch alarms to create for the instance, each value of the object represent an object with options to be
  passed to the cwPutMetricAlarm method.</li>
</ul>
<p>The callback will take 3 arguments: callback(err, rc, info) where info will contain properties that can be used by `aws.ec2PrepareInstance</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2AfterRunInstances(options, callback)</code></p>
<p>  Perform the final tasks after an instance has been launched like wait for status, assign Elastic IP or tags..</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2WaitForInstance(instanceId, status, options, callback)</code></p>
<p>  Check an instance status and keep waiting until it is equal what we expect or timeout occurred.
The <code>status</code> can be one of: pending | running | shutting-down | terminated | stopping | stopped
The options can specify the following:</p>
<ul>
<li>waitTimeout - how long to wait in ms until give up, default is 30 secs</li>
<li>waitDelay - how long in ms between polls</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.ec2DescribeSecurityGroups(options, callback)</code></p>
<p>  Describe security groups, optionally if <code>options.filter</code> regexp is provided then limit the result to the matched groups only,
return list of groups to the callback</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2DescribeInstances(options, callback)</code></p>
<p>  Describe instances according to the query filters, returns a list with instances, the following properties
can be used:</p>
<ul>
<li>vpcId - VPC to get instances from</li>
<li>instanceId - list of instances to show only</li>
<li>tagName - filter by tag name(s)</li>
<li>tagKey - filter by tag key(s)</li>
<li>groupName - filter by group name(s)</li>
<li>stateName - instances state(s)</li>
<li>filters - an object with filters to send as is</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.ec2ParseInstances(rc)</code></p>
<p>  Pare DescribeInstances results and return a list of instances as a plain list</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2CreateTags(id, name, options, callback)</code></p>
<p>  Create tags for a resource.
The name is a string, an array or an object with tags. The options also may contain tags property which is an object with tag key and value</p>
<p>Example</p>
<pre><code> aws.ec2CreateTags(&quot;i-1234&quot;,&quot;My Instance&quot;, { tags: { tag2 : &quot;val2&quot;, tag3: &quot;val3&quot; } } )
 aws.ec2CreateTags(&quot;i-1234&quot;, { tag2: &quot;val2&quot;, tag3: &quot;val3&quot; })
 aws.ec2CreateTags(&quot;i-1234&quot;, [ &quot;tag2&quot;, &quot;val2&quot;, &quot;tag3&quot;, &quot;val3&quot; ])
</code></pre>
</li>
</ul>

<ul>
<li><p><code>aws.ec2AssociateAddress(instanceId, elasticIp, options, callback)</code></p>
<p>  Associate an Elastic IP with an instance. Default behaviour is to reassociate if the EIP is taken.
The options can specify the following:</p>
<ul>
<li>subnetId - required for instances in VPC, allocation id will be retrieved for the given ip address automatically</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.ec2CreateImage(options, callback)</code></p>
<p>  Create an EBS image from the instance given or the current instance running</p>
</li>
</ul>

<ul>
<li><p><code>aws.ec2DeregisterImage(ami_id, options, callback)</code></p>
<p>  Deregister an AMI by id. If <code>options.snapshots</code> is set, then delete all snapshots for this image as well</p>
</li>
</ul>

<ul>
<li><p><code>aws.elbRegisterInstances(name, instance, options, callback)</code></p>
<p>  Register an instance(s) with ELB, instance can be one id or a list of ids</p>
</li>
</ul>

<ul>
<li><p><code>aws.elbDeregisterInstances(name, instance, options, callback)</code></p>
<p>  Deregister an instance(s) from ELB, instance can be one id or a list of ids</p>
</li>
</ul>

<ul>
<li><p><code>aws.elb2RegisterInstances(target, instance, options, callback)</code></p>
<p>  Register an instance(s) with ELB, instance can be one id or a list of ids</p>
</li>
</ul>

<ul>
<li><p><code>aws.ssmSendCommand(cmds, instances, options, callback)</code></p>
<p>  Run a shell command</p>
</li>
</ul>

<ul>
<li><p><code>aws.ssmWaitForCommand(cmdId, instanceId, options, callback)</code></p>
<p>  Return a command details</p>
</li>
</ul>

<ul>
<li><p><code>aws.readCredentials(profile, callback)</code></p>
<p>  Read key and secret from the AWS SDK credentials file, if no profile is given in the config or command line only the default peofile
will be loaded.</p>
</li>
</ul>

<ul>
<li><p><code>aws.readConfig(callback)</code></p>
<p>  Read and apply config from S3 bucket</p>
</li>
</ul>

<ul>
<li><p><code>aws.getInstanceMeta(path, callback)</code></p>
<p>  Retrieve instance meta data</p>
</li>
</ul>

<ul>
<li><p><code>aws.getInstanceCredentials(path, callback)</code></p>
<p>  Retrieve instance credentials using EC2 instance profile and setup for AWS access</p>
</li>
</ul>

<ul>
<li><p><code>aws.getInstanceInfo(options, callback)</code></p>
<p>  Retrieve instance launch index from the meta data if running on AWS instance</p>
</li>
</ul>

<ul>
<li><p><code>aws.stsAssumeRole(options, callback)</code></p>
<p>  Assume a role and return new credentials that can be used in other API calls</p>
</li>
</ul>

<ul>
<li><p><code>aws.detectLabels(name, options, callback)</code></p>
<p>  Detect image featires using AWS Rekognition service, the <code>name</code> can be a Buffer, a local file or an url to the S3 bucket. In the latter case
the url can be just apath to the file inside a bucket if <code>options.bucket</code> is specified, otherwise it must be a public S3 url with the bucket name
to be the first part of the host name. For CDN/CloudFront cases use the <code>option.bucket</code> option.</p>
</li>
</ul>

<ul>
<li><p><code>aws.listCertificates(options, callback)</code></p>
<p>  Return a list of certificates,</p>
<ul>
<li><code>status</code> can limit which certs to return, PENDING_VALIDATION | ISSUED | INACTIVE | EXPIRED | VALIDATION_TIMED_OUT | REVOKED | FAILED</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.parseXMLResponse(err, params, options, callback)</code></p>
<p>  Parse AWS response and try to extract error code and message, convert XML into an object.</p>
</li>
</ul>

<ul>
<li><p><code>aws.getServiceRegion(service, region)</code></p>
<p>  Check for supported regions per service, return the first one if the given region is not supported</p>
</li>
</ul>

<ul>
<li><p><code>aws.copyCredentials(obj, options)</code></p>
<p>  Copy all credentials properties from the options into the obj</p>
</li>
</ul>

<ul>
<li><p><code>aws.querySign(region, service, host, method, path, body, headers, credentials, options)</code></p>
<p>  Build version 4 signature headers</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryPrepare(action, version, obj, options)</code></p>
<p>  Return a request object ready to be sent to AWS, properly formatted</p>
</li>
</ul>

<ul>
<li><p><code>aws.querySigner()</code></p>
<p>  It is called in the context of a http request</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryAWS(region, service, proto, host, path, obj, options, callback)</code></p>
<p>  Make AWS request, return parsed response as Javascript object or null in case of error</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryEndpoint(service, version, action, obj, options, callback)</code></p>
<p>  AWS generic query interface</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryRoute53(method, path, data, options, callback)</code></p>
<p>  Make a request to Route53 service</p>
</li>
</ul>

<ul>
<li><p><code>aws.route53List(options, callback)</code></p>
<p>  List all zones</p>
</li>
</ul>

<ul>
<li><p><code>aws.route53Get(options, callback)</code></p>
<p>  Return a zone by domain or id</p>
</li>
</ul>

<ul>
<li><p><code>aws.route53Change(names, options, callback)</code></p>
<p>  Create or update a host in the Route53 database.</p>
<ul>
<li><code>names</code> is a host name to be set with the current IP address or a list with objects in the format
[ { name: &quot;..&quot;, value: &quot;1.1.1.1&quot;, type: &quot;A&quot;, ttl: 300, zoneId: &quot;Id&quot;, alias: &quot;dnsname&quot;, hostedzone: &quot;/hostedzone/id&quot; } ...]</li>
</ul>
<p>The <code>options</code> may contain the following:</p>
<ul>
<li>type - default record type, A</li>
<li>ttl - default TTL, 300 seconds</li>
<li>op - an operation, default is UPSERT</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.signS3(method, bucket, path, body, options)</code></p>
<p>  Sign S3 AWS request, returns url to be send to S3 server, options will have all updated headers to be sent as well</p>
</li>
</ul>

<ul>
<li><p><code>aws.queryS3(bucket, path, options, callback)</code></p>
<p>  S3 requests
Options may contain the following properties:</p>
<ul>
<li>method - HTTP method</li>
<li>query - query parameters for the url as an object</li>
<li>postdata - any data to be sent with POST</li>
<li>postfile - file to be uploaded to S3 bucket</li>
<li>expires - absolute time when this request is expires</li>
<li>headers - HTTP headers to be sent with request</li>
<li>file - file name where to save downloaded contents</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.s3List(path, options, callback)</code></p>
<p>  Retrieve a list of files from S3 bucket, only files inside the path will be returned</p>
</li>
</ul>

<ul>
<li><p><code>aws.s3GetFile(path, options, callback)</code></p>
<p>  Retrieve a file from S3 bucket, root of the path is a bucket, path can have a protocol prepended like s3://, it will be ignored</p>
</li>
</ul>

<ul>
<li><p><code>aws.s3PutFile(path, file, options, callback)</code></p>
<p>  Upload a file to S3 bucket, <code>file</code> can be a Buffer or a file name</p>
</li>
</ul>

<ul>
<li><p><code>aws.s3CopyFile(path, source, options, callback)</code></p>
<p>  Copy existing S3 file, source must be in the format <code>bucket/path</code></p>
</li>
</ul>

<ul>
<li><p><code>aws.s3ParseUrl(link)</code></p>
<p>  Parse an S3 URL and return an object with bucket and path</p>
</li>
</ul>

<ul>
<li><p><code>aws.s3Proxy(res, bucket, file, options, callback)</code></p>
<p>  Proxy a file from S3 bucket into the existing HTTP response <code>res</code></p>
</li>
</ul>

<ul>
<li><p><code>aws.querySES(action, obj, options, callback)</code></p>
<p>  AWS SES API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.sesSendEmail(to, subject, body, options, callback)</code></p>
<p>  Send an email via SES
The following options supported:</p>
<ul>
<li>from - an email to use in the From: header</li>
<li>cc - list of email to use in CC: header</li>
<li>bcc - list of emails to use in Bcc: header</li>
<li>replyTo - list of emails to ue in ReplyTo: header</li>
<li>returnPath - email where to send bounces</li>
<li>charset - charset to use, default is UTF-8</li>
<li>html - if set the body is sent as MIME HTML</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.sesSendRawEmail(body, options, callback)</code></p>
<p>  Send raw email
The following options accepted:</p>
<ul>
<li>to - list of email addresses to use in RCPT TO</li>
<li>from - an email to use in from header</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.querySNS(action, obj, options, callback)</code></p>
<p>  AWS SNS API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsCreatePlatformEndpoint(token, options, callback)</code></p>
<p>  Creates an endpoint for a device and mobile app on one of the supported push notification services, such as GCM and APNS.</p>
<p>The following properties can be specified in the options:</p>
<ul>
<li>appArn - an application ARN to be used for push notifications, if not passed, global <code>-sns-app-arn</code> will be used.</li>
<li>data - a user data to be associated with the endpoint arn</li>
</ul>
<p>All capitalized properties in the options will be pased as is. The callback will be called with an error if any and the endpoint ARN</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsSetEndpointAttributes(arn, options, callback)</code></p>
<p>  Sets the attributes for an endpoint for a device on one of the supported push notification services, such as GCM and APNS.</p>
<p>The following properties can be specified in the options:</p>
<ul>
<li>token - a device token for the notification service</li>
<li>data - a user data to be associated with the endpoint arn</li>
<li>enabled - true or false to enable/disable the deliver of notifications to this endpoint</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.snsDeleteEndpoint(arn, options, callback)</code></p>
<p>  Deletes the endpoint from Amazon SNS.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsPublish(arn, msg, options, callback)</code></p>
<p>  Sends a message to all of a topic&#39;s subscribed endpoints or to a mobile endpoint.
If msg is an object, then it will be pushed as JSON.
The options may take the following properties:</p>
<ul>
<li>subject - optional subject to be included in the message if the target supports it</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.snsCreateTopic(name, options, callback)</code></p>
<p>  Creates a topic to which notifications can be published. The callback returns topic ARN on success.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsSetTopicAttributes(arn, options, callback)</code></p>
<p>  Updates the topic attributes.
The following options can be used:</p>
<ul>
<li>name - new topic name</li>
<li>policy - an object with access policy</li>
<li>deliveryPolicy - an object with delivery attributes, can specify all or only the ones that needed to be updated</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.snsDeleteTopic(arn, options, callback)</code></p>
<p>  Deletes the topic from Amazon SNS.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsSubscribe(arn, endpoint, options, callback)</code></p>
<p>  Creates a topic to which notifications can be published. The callback returns topic ARN on success, if the topic requires
confirmation the arn returned will be null and a token will be sent to the endpoint for confirmation.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsConfirmSubscription(arn, token, options, callback)</code></p>
<p>  Verifies an endpoint owner&#39;s intent to receive messages by validating the token sent to the
endpoint by an earlier Subscribe action. If the token is valid, the action creates a new subscription
and returns its Amazon Resource Name (ARN) in the callback.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsSetSubscriptionAttributes(arn, options, callback)</code></p>
<p>  Updates the subscription attributes.
The following options can be used:</p>
<ul>
<li>name - new topic name</li>
<li>deliveryPolicy - an object with delivery attributes, can specify all or only the ones that needed to be updated</li>
<li>minDelayTarget - update delivery policy by attribute name</li>
<li>maxDelayTarget</li>
<li>numRetries</li>
<li>numMaxDelayRetries</li>
<li>backoffFunction - one of linear|arithmetic|geometric|exponential</li>
<li>maxReceivesPerSecond</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.snsUnsubscribe(arn, options, callback)</code></p>
<p>  Creates a topic to which notifications can be published. The callback returns topic ARN on success.</p>
</li>
</ul>

<ul>
<li><p><code>aws.snsListTopics(options, callback)</code></p>
<p>  Creates a topic to which notifications can be published. The callback returns topic ARN on success.</p>
</li>
</ul>

<ul>
<li><p><code>aws.querySQS(action, obj, options, callback)</code></p>
<p>  AWS SQS API request</p>
</li>
</ul>

<ul>
<li><p><code>aws.sqsReceiveMessage(url, options, callback)</code></p>
<p>  Receive message(s) from the SQS queue, the callback will receive a list with messages if no error.
The following options can be specified:</p>
<ul>
<li>count - how many messages to receive</li>
<li>timeout - how long to wait, in milliseconds, this is for Long Poll</li>
<li>visibilityTimeout - the duration (in milliseconds) that the received messages are hidden from subsequent retrieve requests</li>
<li>attempt - request attempt id for FIFO queues
 after being retrieved by a ReceiveMessage request.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>aws.sqsSendMessage(url, body, options, callback)</code></p>
<p>  Send a message to the SQS queue.
The options can specify the following:</p>
<ul>
<li>delay - how long to delay this message in milliseconds</li>
<li>group - a group id for FIFO queues</li>
<li>unique - deduplication id for FIFO queues</li>
<li>attrs - an object with additional message attributes to send, use only string, numbers or binary values,
 all other types will be converted into strings</li>
</ul>
</li>
</ul>

<h2 id="module-core">Module: core</h2>
<p>  The primary object containing all config options and common functions</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>help</code>, type: &quot;callback&quot;, callback: function() { this.showHelp()  descr: &quot;Print help and exit&quot;</li>
<li><code>log</code>, type: &quot;callback&quot;, callback: function(v) { logger.setLevel(v)  descr: &quot;Set debugging level to any of &quot; + Object.keys(logger.levels), pass: 2</li>
<li><code>log-file</code>, type: &quot;callback&quot;, callback: function(v) { if (v) this.logFile=v;logger.setFile(this.logFile, this)  descr: &quot;Log to a file, if not specified used default logfile, disables syslog&quot;, pass: 1</li>
<li><code>log-ignore</code>, type: &quot;regexp&quot;, obj: &quot;logInspect&quot;, strip: /log-/, nocamel: 1, descr: &quot;Regexp with property names which must not be exposed in the log when using custom logger inspector&quot;</li>
<li><code>log-inspect</code>, type: &quot;callback&quot;, callback: function(v) { this.setLogInspect(v)  descr: &quot;Install custom secure logger inspection instead of util.inspect&quot;</li>
<li><code>log-filter</code>, type: &quot;callback&quot;, callback: function(v) { if (v) logger.setDebugFilter(v)  descr: &quot;Enable debug filters, format is: label,... to enable, and !label,... to disable. Only first argument is used for label in logger.debug&quot;, pass: 1</li>
<li><code>no-log-filter</code>, type: &quot;bool&quot;, onupdate: function(v) { if (v) logger.filters={}  descr: &quot;Clear all log filters&quot;, pass: 1</li>
<li><code>syslog</code>, type: &quot;callback&quot;, callback: function(v) { logger.setSyslog(v || 1, this.name)  descr: &quot;Log messages to syslog, pass 0 to disable, 1 or url (tcp|udp|unix):[//host:port]/path?[facility=F][&amp;tag=T][&amp;retryCount=N]...&quot;, pass: 1</li>
<li><code>console</code>, type: &quot;callback&quot;, callback: function() { logger.setFile(null)  descr: &quot;All logging goes to the console resetting all previous log related settings, this is used in the development mode mostly&quot;, pass: 1</li>
<li><code>home</code>, type: &quot;callback&quot;, callback: &quot;setHome&quot;, descr: &quot;Specify home directory for the server, the server will try to chdir there or exit if it is not possible, the directory must exist&quot;, pass: 2</li>
<li><code>conf-file</code>, descr: &quot;Name of the config file to be loaded instead of the default etc/config, can be relative or absolute path&quot;, pass: 1</li>
<li><code>err-file</code>, type: &quot;path&quot;, descr: &quot;Path to the error log file where daemon will put app errors and crash stacks&quot;, pass: 1</li>
<li><code>etc-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep config files&quot;, pass: 1</li>
<li><code>tmp-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep temp files&quot;</li>
<li><code>spool-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep modifiable files&quot;</li>
<li><code>log-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep other log files, log-file and err-file are not affected by this&quot;, pass: 1</li>
<li><code>files-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep uploaded files&quot;</li>
<li><code>images-dir</code>, type: &quot;path&quot;, obj: &quot;path&quot;, strip: /Dir/, descr: &quot;Path where to keep images&quot;</li>
<li><code>web-path</code>, type: &quot;path&quot;, array: 1, obj: &quot;path&quot;, strip: /Path/, descr: &quot;Path where to keep web pages and other static files to be served by the web servers&quot;</li>
<li><code>views-path</code>, type: &quot;path&quot;, array: 1, obj: &quot;path&quot;, strip: /Path/, descr: &quot;Path where to keep virtual hosts web pages, every subdirectory name is a host name to match with Host: header, www. is always stripped before matching vhost directory&quot;</li>
<li><code>modules-path</code>, type: &quot;path&quot;, array: 1, obj: &quot;path&quot;, strip: /Path/, descr: &quot;Directory from where to load modules, these are the backendjs modules but in the same format and same conventions as regular node.js modules, the format of the files is NAME_{web,worker,shell}.js. The modules can load any other files or directories, this is just an entry point&quot;, pass: 1</li>
<li><code>locales-path</code>, type: &quot;path&quot;, array: 1, obj: &quot;path&quot;, strip: /Path/, descr: &quot;Path where to keep locale translations&quot;</li>
<li><code>role</code>, descr: &quot;Override servers roles, this may have very strange side effects and should only be used for testing purposes&quot;</li>
<li><code>umask</code>, descr: &quot;Permissions mask for new files, calls system umask on startup, if not specified the current umask is used&quot;, pass: 1</li>
<li><code>force-uid</code>, type: &quot;list&quot;, onupdate: function(v) { lib.dropPrivileges(v[0], v[1])  descr: &quot;Drop privileges if running as root by all processes as early as possibly, this reqiures uid being set to non-root user. A convenient switch to start the backend without using any other tools like su or sudo.&quot;, pass: 1</li>
<li><code>port</code>, type: &quot;number&quot;, min: 0, descr: &quot;port to listen for the HTTP server, this is global default&quot;</li>
<li><code>bind</code>, descr: &quot;Bind to this address only, if not specified listen on all interfaces&quot;</li>
<li><code>backlog</code>, type: &quot;int&quot;, descr: &quot;The maximum length of the queue of pending connections, used by HTTP server in listen.&quot;</li>
<li><code>ws-port</code>, type: &quot;number&quot;, obj: &#39;ws&#39;, min: 0, descr: &quot;Port to listen for WebSocket server, it can be the same as HTTP/S ports to co-exist on existing web servers&quot;</li>
<li><code>ws-bind</code>, obj: &#39;ws&#39;, descr: &quot;Bind to this address only for WebSocket, if not specified listen on all interfaces, only when the port is different from existing web ports&quot;</li>
<li><code>ws-ping</code>, type: &quot;number&quot;, obj: &#39;ws&#39;, min: 0, descr: &quot;How often to ping Websocket connections&quot;</li>
<li><code>ws-path</code>, type: &quot;regexp&quot;, obj: &#39;ws&#39;, descr: &quot;Websockets will be accepted only if request path maches the pattern&quot;</li>
<li><code>ws-origin</code>, type: &quot;regexp&quot;, obj: &#39;ws&#39;, descr: &quot;Websockets will be accepted only if request Origin: header maches the pattern&quot;</li>
<li><code>ws-queue</code>, obj: &quot;ws&quot;, descr: &quot;A queue where to publish messages for websockets, API process will listen for messages and proxy it to all macthing connected websockets &quot;</li>
<li><code>ssl-port</code>, type: &quot;number&quot;, obj: &#39;ssl&#39;, min: 0, descr: &quot;port to listen for HTTPS server, this is global default&quot;</li>
<li><code>ssl-bind</code>, obj: &#39;ssl&#39;, descr: &quot;Bind to this address only for HTTPS server, if not specified listen on all interfaces&quot;</li>
<li><code>ssl-key</code>, type: &quot;file&quot;, obj: &#39;ssl&#39;, descr: &quot;Path to SSL prvate key&quot;</li>
<li><code>ssl-cert</code>, type: &quot;file&quot;, obj: &#39;ssl&#39;, descr: &quot;Path to SSL certificate&quot;</li>
<li><code>ssl-pfx</code>, type: &quot;file&quot;, obj: &#39;ssl&#39;, descr: &quot;A string or Buffer containing the private key, certificate and CA certs of the server in PFX or PKCS12 format. (Mutually exclusive with the key, cert and ca options.)&quot;</li>
<li><code>ssl-ca</code>, type: &quot;file&quot;, obj: &#39;ssl&#39;, array: 1, descr: &quot;An array of strings or Buffers of trusted certificates in PEM format. If this is omitted several well known root CAs will be used, like VeriSign. These are used to authorize connections.&quot;</li>
<li><code>ssl-passphrase</code>, obj: &#39;ssl&#39;, descr: &quot;A string of passphrase for the private key or pfx&quot;</li>
<li><code>ssl-crl</code>, type: &quot;file&quot;, obj: &#39;ssl&#39;, array: 1, descr: &quot;Either a string or list of strings of PEM encoded CRLs (Certificate Revocation List)&quot;</li>
<li><code>ssl-ciphers</code>, obj: &#39;ssl&#39;, descr: &quot;A string describing the ciphers to use or exclude. Consult <a href="http://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT">http://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT</a> for details on the format&quot;</li>
<li><code>ssl-request-cert</code>, type: &quot;bool&quot;, obj: &#39;ssl&#39;, descr: &quot;If true the server will request a certificate from clients that connect and attempt to verify that certificate. &quot;</li>
<li><code>ssl-reject-unauthorized</code>, type: &quot;bool&quot;, obj: &#39;ssl&#39;, decr: &quot;If true the server will reject any connection which is not authorized with the list of supplied CAs. This option only has an effect if ssl-request-cert is true&quot;</li>
<li><code>concurrency</code>, type: &quot;number&quot;, min: 1, max: 4, descr: &quot;How many simultaneous tasks to run at the same time inside one process, this is used by async module only to perform several tasks at once, this is not multithreading but and only makes sense for I/O related tasks&quot;</li>
<li><code>daemon</code>, type: &quot;none&quot;, descr: &quot;Daemonize the process, go to the background, can be specified only in the command line&quot;</li>
<li><code>shell</code>, type: &quot;none&quot;, descr: &quot;Run command line shell, load the backend into the memory and prompt for the commands, can be specified only in the command line&quot;</li>
<li><code>monitor</code>, type: &quot;none&quot;, descr: &quot;For production use, monitors the master and Web server processes and restarts if crashed or exited, can be specified only in the command line&quot;</li>
<li><code>master</code>, type: &quot;none&quot;, descr: &quot;Start the master server, can be specified only in the command line, this process handles job schedules and starts Web server, keeps track of failed processes and restarts them&quot;</li>
<li><code>web</code>, type: &quot;callback&quot;, callback: function() { this.noWeb=0  descr: &quot;Start Web server processes, spawn workers that listen on the same port, for use without master process which starts Web servers automatically&quot;</li>
<li><code>salt</code>, type: &quot;callback&quot;, callback: function(v) { this.salt=lib.salt=v;  descr: &quot;Set random or specific salt value to be used for consistent suuid generation&quot;, pass: 1</li>
<li><code>app-name</code>, type: &quot;callback&quot;, callback: function(v) { if (!v) return;v = v.split(/[/-]/);this.appName=v[0].trim();if (v[1]) this.appVersion=v[1].trim(); descr: &quot;Set appName and version explicitely an skip reading it from package.json, it can be just a name or name-version&quot;, pass: 1</li>
<li><code>app-package</code>, descr: &quot;NPM package containing the application package.json, it will be added to the list of package.json files for app name and version discovery. The package must be included in the -preload-packages list.&quot;, pass: 1</li>
<li><code>instance-(.+)</code>, obj: &#39;instance&#39;, make: &quot;$1&quot;, descr: &quot;Set instance properties explicitly: tag, region, zone&quot;, pass: 1</li>
<li><code>run-mode</code>, dns: 1, descr: &quot;Running mode for the app, used to separate different running environment and configurations&quot;, pass: 1</li>
<li><code>no-monitor</code>, type: &quot;none&quot;, descr: &quot;Disable monitor process, for cases when the master will be monitored by other tool like monit...&quot;</li>
<li><code>no-master</code>, type: &quot;none&quot;, descr: &quot;Do not start the master process&quot;</li>
<li><code>no-watch</code>, type: &quot;bool&quot;, descr: &quot;Disable source code watcher&quot;</li>
<li><code>no-web</code>, type: &quot;bool&quot;, descr: &quot;Disable Web server processes, without this flag Web servers start by default&quot;</li>
<li><code>no-db</code>, type: &quot;bool&quot;, descr: &quot;Do not initialize DB drivers&quot;, pass: 1</li>
<li><code>no-db-config</code>, type: &quot;bool&quot;, descr: &quot;Do not retrieve config from the DB&quot;, pass: 1</li>
<li><code>no-dns</code>, type: &quot;bool&quot;, descr: &quot;Do not use DNS configuration during the initialization&quot;, pass: 1</li>
<li><code>no-modules</code>, type: &quot;bool&quot;, descr: &quot;Do not load any external modules&quot;, pass: 1</li>
<li><code>no-packages</code>, type: &quot;bool&quot;, descr: &quot;Do not load any NPM packages&quot;, pass: 1</li>
<li><code>no-configure</code>, type: &quot;bool&quot;, descr: &quot;Do not run configure hooks during the initialization&quot;, pass: 1</li>
<li><code>repl-port-([a-z]+)$</code>, type: &quot;number&quot;, obj: &quot;repl&quot;, make: &quot;$1Port&quot;, min: 1001, descr: &quot;Base REPL port for process role (server, master, web, worker), if specified it initializes REPL in the processes, for workers the port is computed by adding a worker id to the base port, for example if specified <code>-repl-port-web 2090</code> then a web worker will use any available 2091,2092...&quot;</li>
<li><code>repl-bind</code>, obj: &quot;repl&quot;, descr: &quot;Listen only on specified address for REPL server in the master process&quot;</li>
<li><code>repl-file</code>, obj: &quot;repl&quot;, descr: &quot;User specified file for REPL history&quot;</li>
<li><code>repl-size</code>, obj: &quot;repl&quot;, type: &quot;int&quot;, descr: &quot;Max size to read on start from the end of the history file&quot;</li>
<li><code>worker</code>, type: &quot;bool&quot;, descr: &quot;Set this process as a worker even it is actually a master, this skips some initializations&quot;</li>
<li><code>preload-packages</code>, type: &quot;list&quot;, array: 1, push: 1, descr: &quot;NPM packages to load on startup, the modules, locales, viewes, web subfolders from the package will be added automatically to the system paths, modules will be loaded if present, the config file in etc subfolder will be parsed if present&quot;, pass: 1</li>
<li><code>preload-modules</code>, type: &quot;regexp&quot;, descr: &quot;Modules to preload first from any modules/ folders including the system folder, this can be used to preload default bkjs system modules&quot;, pass: 1</li>
<li><code>exclude-modules</code>, type: &quot;regexp&quot;, descr: &quot;Modules not to load, the whole path is checked&quot;, pass: 1</li>
<li><code>depth-modules</code>, type: &quot;int&quot;, descr: &quot;How deep to go looking for modules, it uses lib.findFileSync to locate all .js files&quot;, pass: 1</li>
<li><code>user-agent</code>, array: 1, descr: &quot;Add HTTP user-agent header to be used in HTTP requests, for scrapers or other HTTP requests that need to be pretended coming from Web browsers&quot;</li>
<li><code>backend-host</code>, descr: &quot;Host of the master backend, can be used for backend nodes communications using core.sendRequest function calls with relative URLs, also used in tests.&quot;</li>
<li><code>backend-login</code>, descr: &quot;Credentials login for the master backend access when using core.sendRequest&quot;</li>
<li><code>backend-secret</code>, descr: &quot;Credentials secret for the master backend access when using core.sendRequest&quot;</li>
<li><code>host-name</code>, type: &quot;callback&quot;, callback: function(v) { if (v) this.hostName=v;this.domain = lib.domainName(this.hostName);this._name = &quot;hostName&quot;  descr: &quot;Hostname/domain to use for communications, default is current domain of the host machine&quot;</li>
<li><code>config-domain</code>, descr: &quot;Domain to query for configuration TXT records, must be specified to enable DNS configuration&quot;</li>
<li><code>config-roles</code>, type: &quot;list&quot;, array: 1, descr: &quot;Roles to assume when pulling config parameters from the config, used in config files or config database&quot;</li>
<li><code>locales</code>, array: 1, type: &quot;list&quot;, descr: &quot;A list of locales to load from the locales/ directory, only language name must be specified, example: en,es. It enables internal support for <code>res.__</code> and <code>req.__</code> methods that can be used for translations, for each request the internal language header will be honored forst, then HTTP Accept-Language&quot;</li>
<li><code>no-locales</code>, type: &quot;bool&quot;, descr: &quot;Do not load locales on start&quot;</li>
<li><code>email-from</code>, descr: &quot;Email address to be used when sending emails from the backend&quot;</li>
<li><code>email-transport</code>, descr: &quot;Send emails via supported transports: ses:, sendgrid://?key=SG, if not set default SMTP settings are used&quot;</li>
<li><code>sendgrid-key</code>, descr: &quot;SendGrid API key&quot;</li>
<li><code>smtp-(.+)</code>, obj: &quot;smtp&quot;, make: &quot;$1&quot;, descr: &quot;SMTP server parameters, user, password, host, ssl, tls...see nodemailer for details&quot;</li>
<li><code>tmp-watcher-(.+)</code>, obj: &quot;tmp-watcher&quot;, type: &quot;int&quot;, strip: &quot;tmpWatcher&quot;, descr: &quot;How long to keep files per subdirectory in seconds&quot;</li>
<li><code>stop-on-error</code>, type: &quot;bool&quot;, descr: &quot;Exit the process on any error when loading modules, for dev purposes&quot;, pass: 1</li>
<li><code>allow-methods-(.+)</code>, obj: &quot;allow-methods&quot;, type: &quot;regexp&quot;, nocamel: 1, descr: &quot;Modules that allowed to run methods by name, useful to restrict configure methods. Ex: -allow-methods-configureWeb app&quot;, pass: 1</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.init(options, callback)</code></p>
<p>  Main initialization, must be called prior to perform any actions.</p>
<p>If options are given they may contain the following properties:</p>
<ul>
<li>noDb - if true do not initialize database</li>
<li>noConfigure - do not run all configure methods</li>
<li>noDns - do not retrieve config from DNS</li>
<li>noWatch - do not watch and reload config files</li>
<li>noModules - do not load modules</li>
<li>noLocales - do not load locales</li>
<li>preloadModules - list of modules to load first</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.run(options, callback)</code></p>
<p>  Run any backend function after environment has been initialized, this is to be used in shell scripts,
core.init will parse all command line arguments, the simplest case to run from /data directory and it will use
default environment or pass -home dir so the script will reuse same config and paths as the server
context can be specified for the callback, if no then it run in the core context</p>
<ul>
<li>require(&#39;backendjs&#39;).run(function() {}) is one example where this call is used as a shortcut for ad-hoc scripting</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.exit(code, msg)</code></p>
<p>  Exit the process with possible message to be displayed and status code</p>
</li>
</ul>

<ul>
<li><p><code>core.setHome(home)</code></p>
<p>  Switch to new home directory, exit if we cannot, this is important for relative paths to work if used,
no need to do this in worker because we already switched to home directory in the master and all child processes
inherit current directory
Important note: If run with combined server or as a daemon then this MUST be an absolute path, otherwise calling
it in the spawned web master will fail due to the fact that we already set the home and relative path will not work after that.</p>
</li>
</ul>

<ul>
<li><p><code>core.loadConfig(file, callback)</code></p>
<p>  Parse the config file, configFile can point to a file or can be skipped and the default file will be loaded</p>
</li>
</ul>

<ul>
<li><p><code>core.reloadConfig(callback)</code></p>
<p>  Reload all config files</p>
</li>
</ul>

<ul>
<li><p><code>core.loadDnsConfig(options, callback)</code></p>
<p>  Load configuration from the DNS TXT records</p>
</li>
</ul>

<ul>
<li><p><code>core.runMethods(name, params, options, callback)</code></p>
<p>  Run a method for every module, a method must conform to the following signature: <code>function(options, callback)</code> and
call the callback when finished. The callback second argument will be the parameters passed to each method, the options if provided can
specify the conditions or parameters which wil be used by the `runMethods`` only.</p>
<p>The following properties can be specified in the options or params:</p>
<ul>
<li>allow - regexp with allowed modules, in options only</li>
<li>allowModules - a regexp of the modules names to be called only</li>
<li>stopOnError - on first error stop and return, otherwise all errors are ignored and all modules are processed</li>
<li>stopFilter - a function to be called after each pass to check if the processing must be stopped, it must return true to stop</li>
<li>logger_error - logger level, if not specified an error with status 200 will be reported with log level &#39;info&#39; and other errors with level &#39;error&#39;</li>
<li>logger_inspect - an object with inspect options to pverride current inspect parameters</li>
<li>logger_allow - a list of properties allowed in the log on error, this is to prevent logging too much or sensitive data</li>
<li>parallel - if true run methods for all modules in parallel using lib.forEach</li>
<li>concurrency - if a number greater than 1 run that many methods in parallel using lib.forEachLimit</li>
<li>sync - if true treat methods as simple functions without callbacks, methods MUST NOT call the second callback argument but simply return</li>
<li>direct - if true call all methods directly othwerwise via setImmediate</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.addModule(...args)</code></p>
<p>  Adds reference to the objects in the core for further access, specify module name, module reference pairs.
This is used the the core itcore to register all internal modules and makes it available in the shell and in the <code>core.modules</code> object.</p>
<p>Also this is used when creating modular backend application by separating the logic into different modules, by registering such
modules with the core it makes the module a first class citizen in the backendjs core and exposes all the callbacks and methods.</p>
<p>For example, the module below will register API routes and some methods</p>
<pre><code>  const bkjs = require(&quot;backendjs&quot;);
  const mymod = { name: &quot;mymod&quot; }
  exports.module = mymod;
  core.addModule(mymod);

  mymod.configureWeb = function(options, callback) {
     bkjs.api.app.all(&quot;/mymod&quot;, function(req, res) {
          res.json({});
     });
  }
</code></pre>
<p>In the main app.js just load it and the rest will be done automatically, i.e. routes will be created ...</p>
<pre><code>  const mymod = require(&quot;./mymod.js&quot;);
</code></pre>
<p>Running the shell will make the object <code>mymod</code> available</p>
<pre><code>  ./app.sh -shell
  &gt; mymod
    { name: &quot;mymod&quot; }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>core.loadModules(dir, options, callback)</code></p>
<p>  Dynamically load services from the specified directory.</p>
<p>The modules are loaded using <code>require</code> as a normal nodejs module but in addition if the module exports
<code>init</code> method it is called immediately with options passed as an argument. This is a synchronous function so it is supposed to be
called on startup, not dynamically during a request processing.</p>
<p>Only .js files from top level are loaded by default unless the depth is provided. <code>core.addModule</code> is called automatically.</p>
<p>Each module is put in the global <code>core.modules`` object by name, the name can be a property </code>name` or the module base file name.</p>
<p>Modules can be sorted by a priority, if .priority property is defined in the module it will be used to sort the modules, the higher priority the
closer to the top the module will be. The position of a module in the <code>core.modules</code> will define the order <code>runMethods</code> will call.</p>
<p>it uses lib.findFileSync to locate the modules, options <code>depth</code>, <code>include or </code>exclude` can be provided</p>
<p><strong>Caution must be taken for module naming, it is possible to override any default bkjs module which will result in unexpected behaviour</strong></p>
<p> Example, to load all modules from the local relative directory</p>
<pre><code>  core.loadModules(&quot;modules&quot;)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>core.loadPackages(list, options)</code></p>
<p>  Load NPM packages and auto configure paths from each package,
etc/config file inside each package will be parsed immediately.
Returns all config files concatenated.</p>
</li>
</ul>

<ul>
<li><p><code>core.httpGet(uri, params, callback)</code></p>
<p>  Make a HTTP request, see <code>httpGet</code> module for more details.</p>
</li>
</ul>

<ul>
<li><p><code>core.sendRequest(options, callback)</code></p>
<p>  Make a HTTP request using <code>httpGet</code> with ability to sign requests.</p>
<p>The POST request is made, if data is an object, it is converted into string.</p>
<p>Returns params as in <code>httpGet</code> with .json property assigned with an object from parsed JSON response.</p>
<p><em>When used with API endpoints, the <code>backend-host</code> parameter must be set in the config or command line to the base URL of the backend,
like <a href="http://localhost:8000">http://localhost:8000</a>, this is when <code>uri</code> is relative URL. Absolute URLs do not need this parameter.</em></p>
<p>Special parameters for options:</p>
<ul>
<li>url - url if options is first argument</li>
<li>login - login to use for access credentials instead of global credentials</li>
<li>secret - secret to use for access instead of global credentials</li>
<li>checksum - calculate checksum from the data</li>
<li>obj - return just the result object, not the whole params</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.parseConfig(data, pass, file)</code></p>
<p>  Parse config lines for the file or other place,
Examples of sections from modules:</p>
<pre><code>tag=T, instance.tag=T, runMode=M, appName=N, role=R, db.configRoles=dev, aws.region=R, aws.tags=T
</code></pre>
</li>
</ul>

<ul>
<li><p><code>core.parseArgs(argv, pass, file)</code></p>
<p>  Parse command line arguments</p>
</li>
</ul>

<ul>
<li><p><code>core.processArgs(mod, argv, pass, file)</code></p>
<p>  Config parameters defined in a module as a list of parameter names prefixed with module name, a parameters can be
a string which defines text parameter or an object with the properties: name, type, value, decimals, min, max, separator
type can be bool, number, list, json</p>
</li>
</ul>


<ul>
<li><p><code>core.describeArgs(module, args)</code></p>
<p>  Add custom config parameters to be understood and processed by the config parser</p>
<ul>
<li>module - a module object or name of the module to add these params to, if it is an empty string or skipped then the module where any
 parameter goes is determined by the prefix, for example if name is &#39;aws-elastic-ip&#39; then it will be added to the aws module,
 all not matched parameters will be added to the core module.</li>
<li>args - a list of objects in the format: { name: N, type: T, descr: D, min: M, max: M, array: B }, all except name are optional.</li>
</ul>
<p>Example:</p>
<pre><code> core.describeArgs(&quot;api&quot;, [ { name: &quot;num&quot;, type: &quot;int&quot;, descr: &quot;int param&quot; }, { name: &quot;list&quot;, array: 1, descr: &quot;list of words&quot; } ]);
 core.describeArgs([ { name: &quot;api-list&quot;, array: 1, descr: &quot;list of words&quot; } ]);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>core.watchLogs(options, callback)</code></p>
<p>  Watch log files for errors and report via email or POST url, see config parameters starting with <code>logwatcher-</code> about how this works</p>
</li>
</ul>

<ul>
<li><p><code>core.watchLogsSave(file, pos, callback)</code></p>
<p>  Save current position for a log file</p>
</li>
</ul>


<ul>
<li><p><code>core.processName()</code></p>
<p>  Return unique process name based on the cluster status, worker or master and the role. This is can be reused by other workers within the role thus
making it usable for repeating environments or storage solutions.</p>
</li>
</ul>

<ul>
<li><p><code>core.showHelp(options)</code></p>
<p>  Print help about command line arguments and exit</p>
</li>
</ul>

<ul>
<li><p><code>core.sendmail(options, callback)</code></p>
<p>  Send email via <code>nodemailer</code> with SMTP transport, other supported transports:</p>
<ul>
<li>fake: - same as json</li>
<li>json: - return message as JSON</li>
<li>file: - save to a file in the <code>tmp/</code></li>
<li>sendgrid: - send via SendGrid</li>
<li>ses: - send via AWS SES service</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.killBackend(name, signal, callback)</code></p>
<p>  Kill all backend processes that match name and not the current process</p>
</li>
</ul>

<ul>
<li><p><code>core.shutdown()</code></p>
<p>  Shutdown the machine now</p>
</li>
</ul>

<ul>
<li><p><code>core.setTimeout(name, callback, timeout)</code></p>
<p>  Set or reset a timer</p>
</li>
</ul>

<ul>
<li><p><code>core.createServer(options, callback)</code></p>
<p>  Create a Web server with options and request handler, returns a server object.</p>
<p>Options can have the following properties:</p>
<ul>
<li>port - port number is required</li>
<li>bind - address to bind</li>
<li>restart - name of the processes to restart on address in use error, usually &quot;web&quot;</li>
<li>ssl - an object with SSL options for TLS createServer call</li>
<li>timeout - number of milliseconds for the request timeout</li>
<li>keepAliveTimeout - number of milliseconds to keep the HTTP connecton alive</li>
<li>requestTimeout - number of milliseconds to receive the entire request from the client</li>
<li>maxRequestsPerSocket - number of requests a socket can handle before closing keep alive connection</li>
<li>maxHeaderSize - maximum length of request headers in bytes</li>
<li>name - server name to be assigned</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.createRepl(options)</code></p>
<p>  Create REPL interface with all modules available</p>
</li>
</ul>

<ul>
<li><p><code>core.startRepl(port, bind, options)</code></p>
<p>  Start command prompt on TCP socket, context can be an object with properties assigned with additional object to be accessible in the shell</p>
</li>
</ul>

<ul>
<li><p><code>core.watchTmp(dir, options, callback)</code></p>
<p>  Watch temp files and remove files that are older than given number of seconds since now, remove only files that match pattern if given
Options properties:</p>
<ul>
<li>match - a regexp that specifies only files to be watched</li>
<li>ignore - a regexp of files to be ignored</li>
<li>seconds - number of seconds a file to be older to be deleted</li>
<li>nodirs - if 1 skip deleting directories</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>core.parseCookies(header)</code></p>
<p>  Parse Set-Cookie header and return an object of cookies: { NAME: { value: VAL, secure: true, expires: N ... } }</p>
</li>
</ul>

<ul>
<li><p><code>core.loadLocales(options, callback)</code></p>
<p>  Load configured locales</p>
</li>
</ul>

<h2 id="module-db">Module: db</h2>
<p>  The Database API, a thin abstraction layer on top of SQLite, PostgreSQL, DynamoDB and Cassandra.
  The idea is not to introduce new abstraction layer on top of all databases but to make
  the API usable for common use cases. On the source code level access to all databases will be possible using
  this API but any specific usage like SQL queries syntax or data types available only for some databases will not be
  unified or automatically converted but passed to the database directly. Only conversion between JavaScript types and
  database types is unified to some degree meaning JavaScript data type will be converted into the corresponding
  data type supported by any particular database and vice versa.</p>
<p>  Basic operations are supported for all database and modelled after NoSQL usage, this means no SQL joins are supported
  by the API, only single table access. SQL joins can be passed as SQL statements directly to the database using low level db.query
  API call, all high level operations like add/put/del perform SQL generation for single table on the fly.</p>
<p>  The common convention is to pass options object with flags that are common for all drivers along with specific,
  this options object can be modified with new properties but all driver should try not to
  modify or delete existing properties, so the same options object can be reused in subsequent operations.</p>
<p>  All queries and update operations ignore properties that starts with underscore.</p>
<p>  Before the DB functions can be used the <code>core.init</code> MUST be called first, the typical usage:</p>
<pre><code>       var backend = require(&quot;backendjs&quot;), core = backend.core, db = backend.db;
       core.init(function(err) {
           db.add(...
           ...
       });
</code></pre>
<p>  All database methods can use default db pool or any other available db pool by using <code>pool: name</code> in the options. If not specified,
  then default db pool is used, sqlite is default if no -db-pool config parameter specified in the command line or the config file.
  Even if the specified pool does not exist, the default pool will be returned, this allows to pre-confgure the app with different pools
  in the code and enable or disable any particular pool at any time.</p>
<p>   Example, use PostgreSQL db pool to get a record and update the current pool</p>
<pre><code>       db.get(&quot;bk_user&quot;, { login: &quot;123&quot; }, { pool: &quot;pg&quot; }, (err, row) =&gt; {
           if (row) db.update(&quot;bk_user&quot;, row);
       });

       const user = await db.aget(&quot;bk_user&quot;, { login: &quot;123&quot; });
</code></pre>
<p>  Most database pools can be configured with options <code>min</code> and <code>max</code> for number of connections to be maintained, so no overload will happen and keep warm connection for
  faster responses. Even for DynamoDB which uses HTTPS this can be configured without hitting provisioned limits which will return an error but
  put extra requests into the waiting queue and execute once some requests finished.</p>
<p>   Example:</p>
<pre><code>       db-pg-pool-max = 100
       db-dynamodb-pool-max = 100
</code></pre>
<p>  Also, to spread functionality between different databases it is possible to assign some tables to the specific pools using <code>db-X-pool-tables</code> parameters
  thus redirecting the requests to one or another databases depending on the table, this for example can be useful when using fast but expensive
  database like DynamoDB for real-time requests and slower SQL database running on some slow instance for rare requests, reports or statistics processing.</p>
<p>   Example, run the backend with default PostgreSQL database but keep all config parametrs in the DynamoDB table for availability:</p>
<pre><code>       db-pool = pg
       db-dynamodb-pool = default
       db-dynamodb-pool-tables = bk_config
</code></pre>
<p>  The following databases are supported with the basic db API methods: Sqlite, PostgreSQL, DynamoDB, Elasticsearch</p>
<p>  Multiple connections of the same type can be opened, just add <code>N</code> suffix to all database config parameters where N is a number,
  referer to such pools in the code as <code>poolN</code> or by an alias.</p>
<p>  Example:</p>
<pre><code>       db-sqlite1-pool = billing
       db-sqlite1-pool-max = 10
       db-sqlite1-pool-options-path = /data/db
       db-sqlite1-pool-options-journal_mode = OFF
       db-sqlite1-pool-alias = billing

       in the Javascript:

       db.select(&quot;bills&quot;, { status: &quot;ok&quot; }, { pool: &quot;billing&quot; }, lib.log)
       await db.aselect(&quot;bills&quot;, { status: &quot;ok&quot; }, { pool: &quot;billing&quot; })
</code></pre>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>db-none</code>, type: &quot;bool&quot;, descr: &quot;disable all db pools&quot;</li>
<li><code>db-pool</code>, dns: 1, descr: &quot;Default pool to be used for db access without explicit pool specified&quot;</li>
<li><code>db-name</code>, key: &quot;db-name&quot;, descr: &quot;Default database name to be used for default connections in cases when no db is specified in the connection url&quot;</li>
<li><code>db-create-tables</code>, key: &quot;_createTables&quot;, type: &quot;bool&quot;, nocamel: 1, master: 1, pass: 1, descr: &quot;Create tables in the database or perform table upgrades for new columns in all pools, only shell or server process can perform this operation&quot;</li>
<li><code>db-create-tables-roles</code>, type: &quot;list&quot;, pass: 1, descr: &quot;Only processes with these roles can create tables&quot;</li>
<li><code>db-cache-tables</code>, array: 1, type: &quot;list&quot;, descr: &quot;List of tables that can be cached: bk_user, bk_counter. This list defines which DB calls will cache data with currently configured cache. This is global for all db pools.&quot;</li>
<li><code>db-skip-tables</code>, array: 1, type: &quot;list&quot;, descr: &quot;List of tables that will not be created or modified, this is global for all pools&quot;</li>
<li><code>db-cache-pools</code>, array: 1, type: &quot;list&quot;, descr: &quot;List of pools which trigger cache flushes on update.&quot;</li>
<li><code>db-cache-sync</code>, array: 1, type: &quot;list&quot;, descr: &quot;List of tables that perform synchronized cache updates before returning from a DB call, by default cache updates are done in the background&quot;</li>
<li><code>db-cache-keys-([a-z0-9_]+)-(.+)</code>, obj: &quot;cacheKeys.$1&quot;, make: &quot;$2&quot;, nocamel: 1, type: &quot;list&quot;, descr: &quot;List of columns to be used for the table cache, all update operations will flush the cache if the cache key can be created from the record columns. This is for ad-hoc and caches to be used for custom selects which specified the cache key.&quot;</li>
<li><code>db-describe-tables</code>, type: &quot;callback&quot;, callback: function(v) { this.describeTables(lib.jsonParse(v, { datatype: &quot;obj&quot;,logger: &quot;error&quot; }))  descr: &quot;A JSON object with table descriptions to be merged with the existing definitions&quot;</li>
<li><code>db-cache-ttl</code>, type: &quot;int&quot;, obj: &quot;cacheTtl&quot;, key: &quot;default&quot;, descr: &quot;Default global TTL for cached tables&quot;,</li>
<li><code>db-cache-ttl-(.+)</code>, type: &quot;int&quot;, obj: &quot;cacheTtl&quot;, nocamel: 1, strip: /cache-ttl-/, descr: &quot;TTL in milliseconds for each individual table being cached&quot;,</li>
<li><code>db-cache-name-(.+)</code>, obj: &quot;cacheName&quot;, nocamel: 1, make: &quot;$1&quot;, descr: &quot;Cache client name to use for cache reading and writing for each table instead of the default in order to split cache usage for different tables, it can be just a table name or <code>pool.table</code>, use <code>*</code> to set default cache for all tables&quot;,</li>
<li><code>db-cache-update-(.+)</code>, obj: &quot;cacheUpdate&quot;, nocamel: 1, make: &quot;$1&quot;, descr: &quot;Cache client name to use for updating only for each table instead of the default in order to split cache usage for different tables, it can be just a table name or <code>pool.table</code> or <code>*</code>. This cache takes precedence for updating cache over <code>cache-name</code> parameter&quot;,</li>
<li><code>db-cache2-max</code>, type: &quot;int&quot;, min: 1, obj: &quot;lru&quot;, make: &quot;max&quot;, descr: &quot;Max number of items to keep in the LRU Level 2 cache&quot;</li>
<li><code>db-cache2-(.+)</code>, obj: &quot;cache2&quot;, type: &quot;int&quot;, nocamel: 1, strip: /cache2-/, min: 0, descr: &quot;Tables with TTL for level2 cache, i.e. in the local process LRU memory. It works before the primary cache and keeps records in the local LRU cache for the given amount of time, the TTL is in ms and must be greater than zero for level 2 cache to work&quot;</li>
<li><code>db-custom-column-([a-zA-Z0-9_]+)-(.+)</code>, obj: &quot;customColumn.$1&quot;, make: &quot;$2&quot;, nocamel: 1, descr: &quot;A column that is allowed to be used in any table, the name is a column name regexp with the value to be a type, Ex: -db-custom-column-bk_user-^stats=counter&quot;,</li>
<li><code>db-describe-column-([a-z0-9_]+)-([a-zA-Z0-9_]+)</code>, obj: &quot;columns.$1&quot;, make: &quot;$2&quot;, type: &quot;map&quot;, maptype: &quot;auto&quot;, nocamel: 1, descr: &quot;Describe a table column properties, can be a new or existing column, overrides existing property, ex: -db-describe-column-bk_user-name max:255&quot;,</li>
<li><code>db-local</code>, descr: &quot;Local database pool for properties, cookies and other local instance only specific stuff&quot;</li>
<li><code>db-config</code>, descr: &quot;Configuration database pool to be used to retrieve config parameters from the database, must be defined to use remote db for config parameters, set to <code>default</code> to use current default pool&quot;</li>
<li><code>db-config-interval</code>, type: &quot;number&quot;, min: 0, descr: &quot;Interval between loading configuration from the database configured with -db-config, in minutes, 0 disables refreshing config from the db&quot;</li>
<li><code>db-config-count</code>, type: &quot;number&quot;, min: 0, descr: &quot;Max number of records to read fron the config table&quot;</li>
<li><code>db-local-tables</code>, type: &quot;bool&quot;, key: &quot;_localTables&quot;, descr: &quot;Only enable local, default and config pools&quot;</li>
<li><code>db-no-cache-columns</code>, type: &quot;bool&quot;, descr: &quot;Do not read/cache table columns&quot;</li>
<li><code>db-cache-columns-interval</code>, type: &quot;int&quot;, min: 0, descr: &quot;How often in minutes to refresh tables columns from the database, it calls cacheColumns for each pool which supports it&quot;</li>
<li><code>db-skip-drop</code>, type: &quot;regexpobj&quot;, descr: &quot;A pattern of table names which will skipped in db.drop operations to prevent accidental table deletion&quot;</li>
<li><code>db-aliases-(.+)</code>, obj: &quot;aliases&quot;, nocamel: 1, reverse: 1, onparse: function(v,o) { o.name=this.table(o.name); return this.table(v)  descr: &quot;Table aliases to be used instead of the requested table name, only high level db operations will use it, al low level utilities use the real table names&quot;</li>
<li><code>db-([a-z0-9]+)-pool$</code>, obj: &#39;poolParams.$1&#39;, make: &quot;url&quot;, novalue: &quot;default&quot;, descr: &quot;A database pool name, depending on the driver it can be an URL, name or pathname, examples of db pools: <code>-db-pg-pool, -db-dynamodb-pool</code>, url format: <code>protocol://[user:password@]hostname[:port]/dbname</code> or <code>default</code>&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(disabled)$</code>, obj: &#39;poolParams.$1&#39;, make: &quot;$2&quot;, type: &quot;bool&quot;, descr: &quot;Disable the specified pool but keep the configuration&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(max)$</code>, obj: &#39;poolParams.$1&#39;, make: &quot;$2&quot;, type: &quot;number&quot;, min: 1, descr: &quot;Max number of open connections for a pool, default is Infinity&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(min)$</code>, obj: &#39;poolParams.$1&#39;, make: &quot;$2&quot;, type: &quot;number&quot;, min: 1, descr: &quot;Min number of open connections for a pool&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(idle)$</code>, obj: &#39;poolParams.$1&#39;, make: &quot;$2&quot;, type: &quot;number&quot;, min: 1000, descr: &quot;Number of ms for a db pool connection to be idle before being destroyed&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(tables)$</code>, obj: &#39;poolParams.$1.configOptions&#39;, make: &quot;$2&quot;, array: 1, type: &quot;list&quot;, onupdate: function(v,o) {this.applyPoolOptions(v,o) descr: &quot;Tables to be created only in this pool, to prevent creating all tables in every pool&quot;</li>
<li><code>db-([a-z0-9]+)-pool-connect$</code>, obj: &#39;poolParams.$1.connectOptions&#39;, type: &quot;json&quot;, logger: &quot;warn&quot;, descr: &quot;Connect options for a DB pool driver for new connection, driver specific&quot;</li>
<li><code>db-([a-z0-9]+)-pool-options$</code>, obj: &#39;poolParams.$1.configOptions&#39;, type: &quot;map&quot;, maptype: &quot;auto&quot;, merge: 1, onupdate: function(v,o) {this.applyPoolOptions(v,o) descr: &quot;General options for a DB pool&quot;</li>
<li><code>db-([a-z0-9]+)-pool-options-([a-zA-Z0-9_.-]+)$</code>, obj: &#39;poolParams.$1.configOptions&#39;, camel: &#39;-&#39;, autotype: 1, make: &quot;$2&quot;, onupdate: function(v,o) {this.applyPoolOptions(v,o) descr: &quot;General options for a DB pool&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(create-tables)$</code>, master: 1, obj: &#39;poolParams.$1.configOptions&#39;, make: &quot;$2&quot;, type: &quot;bool&quot;, descr: &quot;Create tables for this pool on startup&quot;</li>
<li><code>db-([a-z0-9]+)-pool-(skip-tables)$</code>, obj: &#39;poolParams.$1.configOptions&#39;, make: &quot;$2&quot;, array: 1, type: &quot;list&quot;, descr: &quot;Tables not to be created in this pool&quot;</li>
<li><code>db-([a-z0-9]+)-pool-cache2-(.+)</code>, obj: &#39;cache2&#39;, nocamel: 1, strip: /pool-cache2-/, type: &quot;int&quot;, descr: &quot;Level 2 cache TTL for the specified pool and table, data is JSON strings in the LRU cache&quot;</li>
<li><code>db-([a-z0-9]+)-pool-alias</code>, obj: &#39;poolAliases&#39;, make: &quot;$1&quot;, reverse: 1, descr: &quot;Pool alias to refer by an alternative name&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Database tables</code></p>
<pre><code>  // Configuration store, same parameters as in the commandline or config file, can be placed in separate config groups
  // to be used by different backends or workers
  bk_config: {
      name: { primary: 1 },            // name of the parameter
      type: { primary: 2 },            // config type or tag
      value: { type: &quot;text&quot; },         // the value
      status: { value: &quot;ok&quot; },         // ok - availaible
      ttl: { type: &quot;int&quot; },            // refresh interval in seconds since last read
      version: { type: &quot;text&quot; },       // version conditions, &gt;M.N,&lt;M.N
      sort: { type: &quot;int&quot; },           // sorting order
      ctime: { type: &quot;now&quot;, readonly: 1 },
      mtime: { type: &quot;now&quot; }
  },
</code></pre>
</li>
</ul>

<ul>
<li><p><code>createPool:(opts) </code></p>
<p>  None database driver</p>
</li>
</ul>

<ul>
<li><p><code>db.dropTables(tables, options, callback)</code></p>
<p>  Delete all specified tables from the specific pool or all active pools if <code>options.pool</code> is empty, <code>tables</code> can be a list of tables or an
object with table definitions</p>
</li>
</ul>

<ul>
<li><p><code>db.query(req, options, callback)</code></p>
<p>  Execute query using native database driver, the query is passed directly to the driver.</p>
<ul>
<li><p>req - an object with the following properties:</p>
<ul>
<li>text - SQL statement or other query in the format of the native driver, can be a list of statements</li>
<li>values - parameter values for SQL bindings or other driver specific data</li>
<li>op - operations to be performed, used by non-SQL drivers</li>
<li>obj - actual object with data for non-SQL drivers</li>
<li>table - table name for the operation</li>
</ul>
</li>
<li><p>options may have the following properties:</p>
<ul>
<li>pool - name of the database pool where to execute this query.
The difference with the high level functions that take a table name as their firt argument, this function must use pool
explicitely if it is different from the default. Other functions can resolve
the pool by table name if some tables are assigned to any specific pool by configuration parameters <code>db-pool-tables</code>.</li>
<li>unique - perform sorting the result and eliminate any duplicate rows by the column name specified in the <code>unique</code> property</li>
<li>filterrows - function to filter rows not to be included in the result, returns a new result set, args are: function(req, rows)</li>
<li>processrows - function to process rows in the result, returns a new result, args are: function(req, rows), this result will be put in cache
if requested so this may be used for preparing cached results, it must return an array</li>
<li>processasync - function to process result rows via async callback, return a new result in the callback, the function is: function(req, rows, callback),
the callback is function(err, rows)</li>
<li>syncMode - skip columns preprocessing and dynamic values for pool sync and backup restore</li>
<li>quiet - report errors in debug level</li>
<li>first - return the first row from the result</li>
<li>logger_db - log results at the end with this level or debug by default</li>
<li>logger_error - a log level to report about the errors, default is &#39;error&#39;, if an object it can specify different log levels by err.code, * is default level for not matched codes</li>
<li>ignore_error - clear errors occurred as it never happen, do not report in the log, if an array then only matched codes will be cleared</li>
<li>noprocessrows - if true then skip post processing result rows, return the data as is, this will result in returning combined columns as it is</li>
<li>noconvertrows - if true skip converting the data from the database format into Javascript data types, it uses column definitions</li>
<li>nopreparerow - if true skip row preparation and columns processing, the req.obj is passed as is, useful for syncing between pools
for the table to convert values returned from the db into the the format defined by the column</li>
<li>cached - if true perform cache invalidation for the operations that resulted in modification of the table record(s)</li>
<li>total - if true then it is supposed to return only one record with property <code>count</code>, skip all post processing and convertion</li>
<li>info_obj - to return the record just processed in the info object as <code>obj</code> property, it will include all generated and updated columns</li>
<li>result_obj - to return the query record as result including all post processing and new generated columns, this is not what <code>returning</code> property does, it only
returns the query record with new columns from memory</li>
<li>keep_req - on return do not clear out the request object, by default all properties are deleted to free up memory</li>
<li>keep_obj - only preserve op, obj, table properties in the reqest after return</li>
</ul>
</li>
<li><p>callback(err, rows, info) where</p>
<ul>
<li>info is an object with information about the last query: inserted_oid,affected_rows,next_token,consumed_capacity</li>
<li>rows is always returned as a list, even in case of error it is an empty list</li>
</ul>
</li>
</ul>
<p> Example with SQL driver</p>
<pre><code>     db.query({ text: &quot;SELECT a.id,c.type FROM bk_user a,bk_icon c WHERE a.id=c.id and a.id=?&quot;, values: [&#39;123&#39;] }, { pool: &#39;pg&#39; }, (err, rows, info) =&gt; {
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.queryProcessSync(pool, req, row)</code></p>
<p>  Post process hook to be used for replicating records to another pool, this is supposed to be used as this:</p>
<pre><code>   db.setProcessRow(&quot;post&quot;, &quot;*&quot;, (req, row) =&gt; { db.queryProcessSync(&quot;elasticsearch&quot;, req, row) });
</code></pre>
<p>The conditions when to use it is up to the application logic.</p>
<p>It does not deal with the destination pool to be overloaded, all errors will be ignored, this is for simple and light load only</p>
<p>The destination poll must have tables to be synced configured:</p>
<pre><code> db-elasticsearch-pool-tables=table1,table2
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.get(table, query, options, callback)</code></p>
<p>  Retrieve one record from the database by primary key, returns found record or null if not found
Options can use the following special properties:</p>
<ul>
<li>select - a list of columns or expressions to return, default is to return all columns</li>
<li>ops - operators to use for comparison for properties, see <code>db.select</code></li>
<li>cached - if specified it runs getCached version</li>
<li>nocache - disable caching even if configured for the table</li>
</ul>
<p>NOTE: On return the <code>info.cached</code> will be set to</p>
<ul>
<li>1 if retrieved from top level cache</li>
<li>2 if retrieved from level 2 cache</li>
<li>0 if retrieved from db and put in the cache</li>
</ul>
<p>Example</p>
<pre><code>     db.get(&quot;bk_user&quot;, { login: &#39;12345&#39; }, function(err, row) {
        if (row) console.log(row.name);
     });
     const user = await db.aget(&quot;bk_user&quot;, { login: &#39;12345&#39; });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.select(table, query, options, callback)</code></p>
<p>  Select objects from the database that match supplied conditions.</p>
<ul>
<li>query - can be an object with properties for the condition, all matching records will be returned,
also can be a list where each item is an object with primary key condition. Only records specified in the list must be returned.</li>
<li>options can use the following special properties:<ul>
<li>ops - operators to use for comparison for properties, an object with column name and operator. The following operators are available:
 <code>&gt;, gt, &lt;, lt, =, !=, &lt;&gt;, &gt;=, ge, &lt;=, le, in, all_in, between, regexp, iregexp, begins_with, not_begins_with, like%, ilike%, contains, not_contains</code></li>
<li>opsMap - operator mapping between supplied operators and actual operators supported by the db</li>
<li>typesMap - type mapping between supplied and actual column types, an object</li>
<li>select - a list of columns or expressions to return or all columns if not specified, only existing columns will be returned</li>
<li>select_all - a list of columns or expressions to return, passed as is to the underlying driver</li>
<li>start - start records with this primary key, this is the next_token passed by the previous query</li>
<li>count - how many records to return</li>
<li>first - a convenient option to return the first record from the result or null (similar to <code>db.get</code> method)</li>
<li>join - how to join condition expressions, default is AND</li>
<li>joinOps - operators to use to combine several expressions in case when an array of values is given, supports `and|or|AND|OR``</li>
<li>sort - sort by this column. if null then no sorting must be done at all, records will be returned in the order they are kept in the DB.
 <em>NOTE: For DynamoDB this may affect the results if columns requsted are not projected in the index, with sort
  <code>select</code> property might be used to get all required properties. For Elasticsearch if sort is null then scrolling scan will be used,
  if no <code>timeout</code> or <code>scroll</code> are given the default is 1m.</em></li>
<li>sort_timeout - for pagination how long to keep internal state in millisecons, depends on the DB, for example for Elasticsearch it corresponds
 to the scroll param and defaults to 60000 (1m)</li>
<li>desc - if sorting, do in descending order</li>
<li>page - starting page number for pagination, uses count to find actual record to start, for SQL databases mostly</li>
<li>unique - specified the column name to be used in determining unique records, if for some reasons there are multiple records in the location
 table for the same id only one instance will be returned</li>
<li>cacheKey - exlicit key for caching, return from the cache or from the DB and then cache it with this key, works the same as <code>get</code></li>
<li>cacheKeyName - a name of one of the cache keys to use, it must be defined by a <code>db-cache-keys-table-name</code> parameter</li>
<li>nocache - do not use cache even if cache key is given</li>
<li>aliases - an object with mapping between artificial name to real column name, useful in $or/$and conditions with same column but different values</li>
<li>custom_columns - an array of pairs to define global or artificial columns, the format is: [ RegExp, type, ...], useful with aliases</li>
</ul>
</li>
</ul>
<p>On return, the callback can check third argument which is an object with some predefined properties along with driver specific state returned by the query:</p>
<ul>
<li>affected_rows - how many records this operation affected, for add/put/update</li>
<li>inserted_oid - last created auto generated id</li>
<li>next_token - next primary key or offset for pagination by passing it as .start property in the options, if null it means there are no more pages availabe for this query</li>
</ul>
<p>Example: get by primary key, refer above for default table definitions</p>
<pre><code>   db.select(&quot;bk_message&quot;, { id: &#39;123&#39; }, { count: 2 }, (err, rows) =&gt; {

   });

   const rows = await db.aselect(&quot;bk_message&quot;, { id: &#39;123&#39; }, { count: 2 });
</code></pre>
<p>Example: get all icons with type greater or equal to 2</p>
<pre><code>   db.select(&quot;bk_icon&quot;, { id: &#39;123&#39;, type: &#39;2&#39; }, { select: &#39;id,type&#39;, ops: { type: &#39;ge&#39; } }, (err, rows) =&gt; {

   });
</code></pre>
<p>Example: get unread msgs sorted by time, recent first</p>
<pre><code>   db.select(&quot;bk_message&quot;, { id: &#39;123&#39;, status: &#39;N:&#39; }, { sort: &quot;status&quot;, desc: 1, ops: { status: &quot;begins_with&quot; } }, (err, rows) =&gt; {

   });
</code></pre>
<p>Example: allow all accounts icons to be visible</p>
<pre><code>   db.select(&quot;bk_user&quot;, {}, (err, rows) =&gt; {
       rows.forEach(function(row) {
           row.acl_allow = &#39;auth&#39;;
           db.update(&quot;bk_icon&quot;, row);
       });
   });
</code></pre>
<p>Example: scan accounts with custom filter, not by primary key: by exact zipcode</p>
<pre><code>   db.select(&quot;bk_user&quot;, { zipcode: &#39;20000&#39; }, (err, rows) =&gt; {

   });
</code></pre>
<p>Example: select accounts by type for the last day</p>
<pre><code>   db.select(&quot;bk_user&quot;, { type: &#39;admin&#39;, mtime: Date.now()-86400000 }, { ops: { type: &quot;contains&quot;, mtime: &quot;gt&quot; } }, (err, rows) =&gt; {

   });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.search(table, query, options, callback)</code></p>
<p>  Perform full text search on the given table, the database implementation may ignore table name completely
in case of global text index.</p>
<p>Query in general is a text string with the format that is supported by the underlying driver,
the db module <em>DOES NOT PARSE</em> the query at all if the driver supports full text search, otherwise it behaves like <code>select</code>.</p>
<p>Options make take the same properties as in the <code>select</code> method.</p>
<p>A special query property <code>q</code> may be used for generic search in all fields.</p>
<p>Without full text search support in the driver this may return nothing or an error.</p>
<p> Example
       db.search(&quot;bk_user&quot;, { type: &quot;admin&quot;, q: &quot;john*&quot; }, { pool: &quot;elasticsearch&quot; }, lib.log);
       db.search(&quot;bk_user&quot;, &quot;john*&quot;, { pool: &quot;elasticsearch&quot; }, lib.log);
       await db.asearch(&quot;bk_user&quot;, &quot;john*&quot;, { pool: &quot;elasticsearch&quot; });</p>
</li>
</ul>

<ul>
<li><p><code>db.add(table, obj, options, callback)</code></p>
<p>  Insert new object into the database</p>
<ul>
<li>obj - an JavaScript object with properties for the record, primary key properties must be supplied</li>
<li>options may contain the following properties:<ul>
<li>no_columns - do not check for actual columns defined in the pool tables and add all properties from the obj, only will work for NoSQL dbs,
by default all properties in the obj not described in the table definition for the given table will be ignored.</li>
<li>skip_columns - ignore properties by name listed in the this array, the most use case is to skip autogeneratd columns like &quot;now&quot;</li>
</ul>
</li>
</ul>
<p>On return the <code>obj</code> will contain all new columns generated before adding the record</p>
<p>Note: SQL, DynamoDB, MongoDB, Redis drivers are fully atomic but other drivers may be subject to race conditions</p>
<p>Example</p>
<pre><code>  db.add(&quot;bk_user&quot;, { id: &#39;123&#39;, login: &#39;admin&#39;, name: &#39;test&#39; }, function(err, rows, info) {
  });

  await db.aadd(&quot;bk_user&quot;, { id: &#39;123&#39;, login: &#39;admin&#39;, name: &#39;test&#39; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.incr(table, obj, options, callback)</code></p>
<p>  Counter operation, increase or decrease column values, similar to update but all specified columns except primary
key will be incremented, use negative value to decrease the value.</p>
<p>If no <code>options.updateOps</code> object specified or no &#39;incr&#39; operations are provided then
all columns with type &#39;counter&#39; will be used for the action <code>incr</code></p>
<p><em>Note: The record must exist already for SQL databases, for DynamoDB and Cassandra a new record will be created
if does not exist yet.</em> To disable upsert pass <code>noupsert</code> in the options.</p>
<p>Example</p>
<pre><code>  db.incr(&quot;bk_counter&quot;, { id: &#39;123&#39;, like0: 1, invite0: 1 }, (err, rows, info) =&gt; {
  });

  await db.aincr(&quot;bk_counter&quot;, { id: &#39;123&#39;, like0: 1, invite0: 1 })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.put(table, obj, options, callback)</code></p>
<p>  Add/update an object in the database, if object already exists it will be replaced with all new properties from the obj</p>
<ul>
<li>obj - an object with record properties, primary key properties must be specified</li>
<li>options - same properties as for <code>db.add</code> method</li>
</ul>
<p>Example</p>
<pre><code>  db.put(&quot;bk_user&quot;, { id: &#39;123&#39;, login: &#39;test&#39;, name: &#39;test&#39; }, function(err, rows, info) {
  });

  await db.aput(&quot;bk_user&quot;, { id: &#39;123&#39;, login: &#39;test&#39;, name: &#39;test&#39; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.update(table, obj, options, callback)</code></p>
<p>  Update existing object in the database.</p>
<ul>
<li>obj - is an actual record to be updated, primary key properties must be specified</li>
<li>options - same properties as for <code>db.add</code> method with the following additional properties:<ul>
<li>ops - object for comparison operators for primary key, default is equal operator</li>
<li>opsMap - operator mapping into supported by the database</li>
<li>typesMap - type mapping for properties to be used in the condition</li>
<li>aliases - an object to map column aliases in the query in case the same column is used ultiple times</li>
<li>expected - an object with the condition for the update, it is used in addition to the primary keys condition from the <code>obj</code>,
 a property named $or or $and will be treated as a sub-expression if it is an object.</li>
<li>expectedJoin - how to join expected expressions: OR, AND, default is AND</li>
<li>upsert - create a new record if it does not exist</li>
<li>syncMode - skip columns preprocessing and dynamic values for pool sync and backup restore</li>
<li>updateOps - an object with column names and operations to be performed on the named column<ul>
<li>incr - increment by given value</li>
<li>add - add an item to the list</li>
<li>del - remove an item from the list</li>
<li>set - to update as it is, for reseting counters forexample</li>
<li>concat - concatenate given value, for strings if the database supports it</li>
<li>append - append to the list of values, only for lists if the database supports it</li>
<li>prepend - insert at the beginning of the list, depends on the database</li>
<li>not_exists - only update if not exists or null</li>
</ul>
</li>
<li>typesOps - an object that defines updateOps operation by column type, for example <code>typesOps: { list: &quot;add&quot; }</code> will
 make sure all lists will have updateOps set as add if not specified explicitly</li>
</ul>
</li>
</ul>
<p>Note: not all database drivers support atomic update with conditions, all drivers for SQL, DynamoDB, MongoDB, Redis fully atomic, but other drivers
perform get before put and so subject to race conditions</p>
<p>Example</p>
<pre><code>     db.update(&quot;bk_user&quot;, { login: &#39;test&#39;, id: &#39;123&#39; }, (err, rows, info) =&gt; {
         console.log(&#39;updated:&#39;, info.affected_rows);
     });

     await db.aupdate(&quot;bk_user&quot;, { login: &#39;test&#39;, name: &#39;Test&#39;)

     db.update(&quot;bk_user&quot;, { login: &#39;test&#39;, id: &#39;123&#39;, first_name: &#39;Mr&#39; }, { pool: pg&#39; }, (err, rows, info) =&gt; {
         console.log(&#39;updated:&#39;, info.affected_rows);
     });

     db.update(&quot;bk_user&quot;, { login: &#39;test&#39;, first_name: &#39;John&#39; }, { expected: { first_name: &quot;Carl&quot; } }, (err, rows, info) =&gt; {
         console.log(&#39;updated:&#39;, info.affected_rows);
     });

     db.update(&quot;bk_user&quot;, { login: &#39;test&#39;, first_name: &#39;John&#39; }, { expected: { &quot;$or&quot;: { first_name: &quot;Carl&quot;, g1: null }, aliases: { g1: &quot;first_name&quot; } }, (err, rows, info) =&gt; {
         console.log(&#39;updated:&#39;, info.affected_rows);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.updateAll(table, query, obj, options, callback)</code></p>
<p>  Update all records that match given condition in the <code>query</code>, one by one, the input is the same as for <code>db.select</code> and every record
returned will be updated using <code>db.update</code> call by the primary key, so make sure options.select include the primary key for every row found by the select.</p>
<p>All properties from the <code>obj</code> will be set in every matched record.</p>
<p>The callback will receive on completion the err and all rows found and updated. This is mostly for non-SQL databases and for very large range it may take a long time
to finish due to sequential update every record one by one.
Special properties that can be in the options for this call:</p>
<ul>
<li>updateOptions - options to be passed to the db.update if needed, this is useful so select and update options will not be mixed up</li>
<li>updateCollect - if true return all updated rows in the callback otherwise just the number of updated rows</li>
<li>factorCapacity - write capacity factor for update operations, default is 0.25</li>
<li>op - by default it uses db.update but the <code>op</code> can be set to <code>put</code> or <code>add</code></li>
<li>updateProcess - a function callback that will be called for each row before updating it, this is for some transformations of the record properties
 in case of complex columns that may contain concatenated values as in the case of using DynamoDB. The callback will be called
 as <code>options.updateProcess(row, options)</code>. If it returns non-empty value the update will stop and return it as the error.</li>
<li>updateFilter - a function that must return something to the callback in order to skip the current record. <code>options.updateFilter(row, options, (skip) =&gt; {})</code></li>
</ul>
<p> If no <code>options.select</code> is specified only the primary keys will be returned or collected</p>
<p>Example, update birthday format if not null</p>
<pre><code>     db.updateAll(&quot;bk_user&quot;,
                 { birthday: 1 },
                 { mtime: Date.now() },
                 { ops: { birthday: &quot;not null&quot; },
                   updateProcess: function(r, o) {
                      r.birthday = lib.strftime(new Date(r.birthday, &quot;%Y-%m-D&quot;));
                   },
                   updateFilter: function(r, o, cb) {
                      cb(r.status == &#39;ok&#39;);
                   } },
     function(err, count) {
        console.log(count, &quot;rows updated&quot;);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.del(table, obj, options, callback)</code></p>
<p>  Delete an object in the database, no error if the object does not exist</p>
<ul>
<li>obj - an object with primary key properties only, other properties will be ignored</li>
<li>options - same properties as for <code>db.update</code> method</li>
</ul>
<p>Example</p>
<pre><code>  db.del(&quot;bk_user&quot;, { login: &#39;123&#39; }, function(err, rows, info) {
      console.log(&#39;updated:&#39;, info.affected_rows);
  });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.delAll(table, query, options, callback)</code></p>
<p>  Delete all records that match given condition, one by one, the input is the same as for <code>db.select</code> and every record
returned will be deleted using <code>db.del</code> call. The callback will receive on completion the err and all rows found and deleted.
Special properties that can be in the options for this call:</p>
<ul>
<li>ops - query operations to retrieve records to be deleted</li>
<li>count - how many matching records to delete</li>
<li>delScan - if true force to use db.scan instead of native <code>delAll</code> for the given pool</li>
<li>delOptions - options to be passed to the db.del if needed, this is useful so select and del options will not be mixed up</li>
<li>delCollect - if true return all deleted rows in the callback, oherwise just the number of rows deleted</li>
<li>factorCapacity - write capqcity factor for delete operations, default is 0.35</li>
<li>concurrency - how many delete requests to execute at the same time by using lib.forEachLimit.</li>
<li>ignore_error - continue deleting records even after an error</li>
<li>delProcess - a function callback that will be called for each row before deleting it, this is for some transformations of the record properties
in case of complex columns that may contain concatenated values as in the case of using DynamoDB. The callback will be called
as <code>options.delProcess(row, options, info)</code>. If it returns non-empty value the scan will stop and return it as the error.</li>
<li>delFilter - a function that must return something to the callback in order to skip the current record. <code>options.delFilter(row, options, (skip) =&gt; {})</code></li>
<li>batch - delete using bulk operations, all functions must accept an array of rows instead</li>
</ul>
<p> If no <code>options.select</code> is specified only the primary keys will be returned or collected</p>
<p>If <code>db-skip-drop</code> matches the table name and there is no query provided it will exit with error</p>
</li>
</ul>

<ul>
<li><p><code>db.list(table, query, options, callback)</code></p>
<p>  Convenient helper to retrieve all records by primary key, the obj must be a list with key property or a string with list of primary key column
Example</p>
<pre><code> db.list(&quot;bk_user&quot;, [&quot;id1&quot;, &quot;id2&quot;], function(err, rows) { console.log(err, rows) });
 db.list(&quot;bk_user&quot;, &quot;id1,id2&quot;, function(err, rows) { console.log(err, rows) });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.batch(list, options, callback)</code></p>
<p>  Perform a batch of operations at the same time, all operations for the same table will be run
 together one by one but different tables will be updated in parallel.</p>
<ul>
<li><code>list</code> an array of objects to put/delete from the database in the format:<ul>
<li>op - is one of add, incr, put, update, del</li>
<li>table - which table to use</li>
<li>obj - an object with data</li>
<li>options - params for the operation, optional</li>
</ul>
</li>
<li>options can have the follwoing:<ul>
<li>concurrency - number of how many operations to run at the same time, 1 means sequential</li>
<li>no_errors - will stop on first error, because operations will be run in parallel some operations still may be performed</li>
<li>factorCapacity - a capacity factor to apply to the write capacity if present, by default it is used write capacity at 100%</li>
</ul>
</li>
</ul>
<p>On return the second arg to the callback is a list of records with errors, same input record with added property <code>errstatus</code> and <code>errmsg</code></p>
<p> Example:</p>
<pre><code>     var ops = [ { op: &quot;add&quot;, table: &quot;bk_counter&quot;, obj: { id:1, like:1 } },
                 { op: &quot;add&quot;, table: &quot;bk_user&quot;, obj: { login: &quot;test&quot;, id:1, name:&quot;test&quot; }]
     db.batch(ops, { factorCapacity: 0.5 }, lib.log);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.bulk(list, options, callback)</code></p>
<p>  Bulk operations, it will be noop if the driver does not support it.
The input format is the same as for the <code>db.batch</code> method.</p>
<p>On return the second arg to the callback is a list of records with errors, same input record with added property <code>errstatus</code> and <code>errmsg</code></p>
<p>NOTE: DynamoDB only supports add/put/del only and 25 at a time, if more specified it will send multiple batches</p>
<p>Example</p>
<pre><code>     var ops = [ { op: &quot;add&quot;, table: &quot;bk_counter&quot;, obj: { id:1, like:1 } },
                 { op: &quot;del&quot;, table: &quot;bk_user&quot;, obj: { login: &quot;test1&quot; } },
                 { op: &quot;incr&quot;, table: &quot;bk_counter&quot;, obj: { id:2, like:1 } },
                 { op: &quot;add&quot;, table: &quot;bk_user&quot;, obj: { login: &quot;test2&quot;, id:2, name:&quot;test2&quot; } }]
     db.bulk(ops, { pool: &quot;elasticsearch&quot; }, lib.log);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.transaction(list, options, callback)</code></p>
<p>  Same as the <code>db.bulk</code> but in transaction mode, all operations must succeed or fail. Not every driver can support it,
in DynamoDB case only 10 operations can be done at the same time, if the list is larger then it will be sequentially run with batches of 25 records.</p>
<p>In case of error the second arg will contain the records of the failed batch</p>
</li>
</ul>

<ul>
<li><p><code>db.scan(table, query, options, rowCallback, endCallback)</code></p>
<p>  Convenient helper for scanning a table for some processing, rows are retrieved in batches and passed to the callback until there are no more
records matching given criteria. The obj is the same as passed to the <code>db.select</code> method which defined a condition which records to get.
The rowCallback must be present and is called for every row or batch retrieved and second parameter which is the function to be called
once the processing is complete. At the end, the callback will be called just with 1 argument, err, this indicates end of scan operation.
Basically, db.scan is the same as db.select but can be used to retrieve large number of records in batches and allows async processing of such records.
To hint a driver that scanning is in progress the <code>options.scanning</code> will be set to true.</p>
<p>Parameters:</p>
<ul>
<li>table - table to scan</li>
<li>query - an object with query conditions, same as in <code>db.select</code></li>
<li>options - same as in <code>db.select</code>, with the following additions:<ul>
<li>count - size of every batch, default is 100</li>
<li>limit - total number of records to scan</li>
<li>start - the primary key to start the scan from</li>
<li>search - use search instead of select, for ElasticSearch,...</li>
<li>batch - if true rowCallback will be called with all rows from the batch, not every row individually, batch size is defined by the count property</li>
<li>sync - as batch mode but the rowCallback is called synchronously as <code>rowCallback(row, info)</code></li>
<li>concurrency - how many rows to process at the same time, if not given process sequentially</li>
<li>noscan - if 1 no scan will be performed if no primary keys are specified</li>
<li>emptyscan - if 0 no empty scan will be performed when no table columns in the query to be used as a filter</li>
<li>fullscan - if 1 force to scan full table without using any primary key conditons, use all query properties for all records (DynamoDB)</li>
<li>useCapacity - triggers to use specific capacity, default is <code>read</code></li>
<li>factorCapacity - a factor to apply for the read capacity limit and triggers the capacity check usage, default is <code>0.9</code></li>
<li>tableCapacity - use a different table for capacity throttling instead of the <code>table</code>, useful for cases when the row callback performs
 writes into that other table and capacity is different</li>
<li>capacity - a full capacity object to pass to select calls</li>
</ul>
</li>
<li>rowCallback - process records when called like this `callback(rows, next, info)</li>
<li>endCallback - end of scan when called like this: `callback(err)</li>
</ul>
<p> Example:</p>
<pre><code>     db.scan(&quot;bk_user&quot;, {}, { count: 10, pool: &quot;dynamodb&quot; }, function(row, next) {
         // Copy all accounts from one db into another
         db.add(&quot;bk_user&quot;, row, { pool: &quot;pg&quot; }, next);
     }, function(err) { });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.copy(table, query, options, callback)</code></p>
<p>  Copy records from one table to another between different DB pools or regions</p>
<p>Parameters:</p>
<ul>
<li>table - name of the table to copy</li>
<li>query - a query condition for the table</li>
<li>options properties<ul>
<li>sort - index to use for query</li>
<li>minCapacity - capacity minimum for read/writes, it will override actual DB capacity</li>
<li>factorCapacity - factor the actual capacity for reads/writes</li>
<li>stopOnError - stop the copy on first DB error, otherwise ignore errors</li>
<li>region - other region where to copy</li>
<li>pool - other DB pool</li>
<li>file - dump the data into a file as JSON</li>
<li>preprocess - a function(table, row, options) to be called before the update, if it returns true the record will be skipped</li>
<li>posprocess - a function(table, row, options, next) to be called after the record is copied, for recursive or joined cases</li>
<li>reget - if set the actual record will read using db.get, for cases when db.scan returns only partial record as in DynamoDB cases with indexes</li>
<li>incremental - if set, try to read the latest record in the other table and continue from there, uses <code>sort</code> index in desc order</li>
<li>batch - a number of records to copy at once using the bulk operation</li>
<li>syncMode - if set enabled the update mode in which all values are preserved and not pre-processed, default is 1</li>
<li>updateOptions - pass options to update/bulk operations</li>
</ul>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.join(table, rows, options, callback)</code></p>
<p>  Join the given list of records with the records from other table by primary key.
The properties from the joined table will be merged with the original rows preserving the existing properties</p>
<ul>
<li>options.keys defines custom primary key to use instead of table&#39;s primary key</li>
<li>options.keysMap - an object that defines which property should be used for a key in the given rows, this is
for cases when actual primary keys in the table are different from the rows properties.</li>
<li>options.columnsMap - save properties with a different name using this mapping object</li>
<li>options.existing is 1 then return only joined records.</li>
<li>options.override - joined table properties will replace the original table existing properties</li>
<li>options.attach - specifies a property name which will be used to attach joined record to the original record, no merging will occur, for
 non-existing records an empty object will be attached</li>
<li>options.incr can be a list of property names that need to be summed up with each other, not overriden</li>
<li>options.nomerge - do not merge lists, just return new rows as is</li>
</ul>
<p>A special case when table is empty <code>db.join</code> just returns same rows to the callback, this is
for convenience of doing joins on some conditions and trigger it by setting the table name or skip the join completely.</p>
<p>Example:</p>
<pre><code>     db.join(&quot;bk_user&quot;, [{id:&quot;123&quot;,key1:1},{id:&quot;234&quot;,key1:2}], lib.log)
     db.join(&quot;bk_user&quot;, [{aid:&quot;123&quot;,key1:1},{aid:&quot;234&quot;,key1:2}], { keysMap: { id: &quot;aid&quot; }}, lib.log)
     db.join(&quot;bk_user&quot;, [{id:&quot;123&quot;,state:&quot;NY&quot;},{id:&quot;234&quot;,state:&quot;VA&quot;}], { columnsMap: { state: &quot;astate&quot; }}, lib.log)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.create(table, columns, options, callback)</code></p>
<p>  Create a table using column definitions represented as a list of objects. Each column definition may
contain the following properties:</p>
<ul>
<li><code>name</code> - column name</li>
<li><code>type</code> - column type: int, bigint, real, string, now, counter or other supported type</li>
<li><code>primary</code> - column is part of the primary key</li>
<li><code>unique</code> - column is part of an unique key</li>
<li><code>index</code> - column is part of an index, the value is a number for the column position in the index</li>
<li><code>indexN</code> - additonal inxdexes where N is 1..5</li>
<li><code>value</code> - default value for the column</li>
<li><code>len</code> - column length</li>
<li><code>max</code> - ignore the column if a <code>text</code>, <code>json</code> or <code>obj</code> value is greater than specified limit, unless <code>trunc</code> is provided</li>
<li><code>trunc</code> - truncate the column value, the value will be truncated before saving into the DB, uses the <code>max</code> as the limit</li>
<li><code>maxlist</code> - max number of items in the <code>list</code> or <code>array</code> column types</li>
<li><code>pub</code> - columns is public, <em>this is very important property because it allows anybody to see it when used in the default API functions, i.e. anybody with valid
 credentials can retrieve all public columns from all other tables, and if one of the other tables is account table this may expose some personal information,
 so by default only a few columns are marked as public in the <code>bk_user</code> table</em></li>
<li><code>pub_admin</code> - a generic read permission requires <code>options.isAdmin</code> when used with <code>api.cleanResult</code></li>
<li><code>pub_staff</code> - a generic read permission requires <code>options.isStaff</code> when used with <code>api.cleanResult</code></li>
<li><code>pub_types</code> - a role or a list of roles which further restrict access to a public column to only users with specified roles</li>
<li><code>priv_types</code> - a role or a list of roles which excplicitely deny access to a column for users with specified roles</li>
<li><code>priv</code> - an opposite for the pub property, if defined this property should never be returned to the client by the API handlers</li>
<li><code>auth</code> - this property will be set in <code>req.options.account</code> for access permissions checks when only options are available</li>
<li><code>internal</code> - if set then this property can only be updated by admin/root or with <code>isInternal`` property, implemented by the </code>auth` module only</li>
<li><code>hidden</code> - completely ignored by all update operations but could be used by the public columns cleaning procedure, if it is computed and not stored in the db
 it can contain pub property to be returned to the client</li>
<li><code>readonly</code> - only add/put operations will use the value, incr/update will not affect the value</li>
<li><code>writeonly</code> - only incr/update can change this value, add/put will ignore it</li>
<li><code>noresult</code> - delete this property from the result, mostly for joined artificial columns which used for indexes only</li>
<li><code>random</code> - add a random number between 0 and this value, useful with type: &quot;now&quot;</li>
<li><code>lower</code> - make string value lowercase</li>
<li><code>upper</code> - make string value uppercase</li>
<li><code>strip</code> - if a regexp perform replace on the column value before saving</li>
<li><code>trim</code> - strim string value of whitespace</li>
<li><code>cap</code> - capitalize into a title with lib.toTitle</li>
<li><code>word</code> - if a number only save nth word from the value, split by <code>separator</code></li>
<li><code>clock</code> - for <code>now</code> type use high resolution clock in nanoseconds</li>
<li><code>epoch</code> - for <code>now</code> type save as seconds since the Epoch, not milliseconds</li>
<li><code>multiplier</code> - for numeric columns apply this multipliers before saving</li>
<li><code>incrememnt</code> - for numeric columns add this value before saving</li>
<li><code>decimal</code> - for numeric columns convert into fixed number using this number of decimals</li>
<li><code>format</code> - a function (val, req) =&gt; {} that must return new value for the given column, for custom formatting</li>
<li><code>prefix</code> - prefix to be prepended for autogenerated columns: <code>uuid</code>, <code>suud</code>, <code>tuud</code></li>
<li><code>separator</code> - to be used as a separator in join or split depending on the column properties</li>
<li><code>list</code> - splits the column value into an array, optional <code>separator</code> property can be used, default separator is <code>,|</code></li>
<li><code>autoincr</code> - for counter tables, mark the column to be auto-incremented by the connection API if the connection type has the same name as the column name</li>
<li><code>join</code> - a list with property names that must be joined together before performing a db operation, it will use the given record to produce new property,
  this will work both ways, to the db and when reading a record from the db it will split joined property and assign individual
  properties the value from the joined value. See <code>db.joinColumns</code> for more options.</li>
<li><code>unjoin</code> - split the join column into respective columns on retrieval</li>
<li><code>keepjoined</code> - keep the joined column value, if not specified the joined column is deleted after unjoined</li>
<li><code>notempty</code> - do not allow empty columns, if not provided it is filled with the default value</li>
<li><code>skip_empty</code> - ignore the column if the value is empty, i.e. null or empty string</li>
<li><code>fail_ifempty</code> - returtn an error if there is no  value for the column, this is checked during record preprocessing</li>
<li><code>values</code> - an array with allowed values, ignore the column if not present</li>
<li><code>values_map</code> - an array of pairs to be checked for exact match and be replaced with the next item, [&quot;&quot;, null, &quot;&quot;, undefined, &quot;null&quot;, &quot;&quot;]</li>
</ul>
<p><em>Some properties may be defined multiple times with number suffixes like: <code>unique1, unique2, index1, index2</code> to create more than one index for the table, same
properties define a composite key in the order of definition or sorted by the property value, for example: <code>{ a: { index:2 }, b: { index:1 } }</code> will create index (b,a)
because of the <code>index:</code> property value being not the same. If all index properties are set to 1 then a composite index will use the order of the properties.</em></p>
<p><em>Special column types</em>:</p>
<ul>
<li><code>uuid</code> - autogenerate the column value with UUID, optional <code>prefix</code> property will be prepended, <code>{ type: &quot;uuid&quot;, prefix: &quot;u_&quot; }</code></li>
<li><code>now</code> - defines a column to be automatically filled with the current timestamp, <code>{ type: &quot;now&quot; }</code></li>
<li><code>counter</code> - defines a columns that will be automatically incremented by the <code>db.incr</code> command, on creation it is set with 0</li>
<li><code>uid</code> - defines a columns to be automatically filled with the current user id, this assumes that account object is passed in the options from the API level</li>
<li><code>uname</code> - defines a columns to be automatically filled with the current user name, this assumes that account object is passed in the options from the API level</li>
<li><code>ttl</code> - mark the column to be auto expired, can be set directly to time in the future or use one of: <code>days</code>, <code>hours</code>, <code>minutes</code> as a interval in the future</li>
</ul>
<p>NOTE: Index creation is not required and all index properties can be omitted, it can be done more effectively using native tools for any specific database,
this format is for simple and common use cases without using any other tools but it does not cover all possible variations for every database. But all indexes and
primary keys created outside of the backend application will be detected properly by <code>db.cacheColumns</code> and by each pool <code>cacheIndexes</code> methods.</p>
<p>Each database pool also can support native options that are passed directly to the driver in the options, these properties are
defined in the object with the same name as the db driver, all properties are combined, for example to define provisioned throughput for the DynamoDB index:</p>
<pre><code>     db.create(&quot;test_table&quot;, { id: { primary: 1, type: &quot;int&quot;, index: 1, dynamodb: { readCapacity: 50, writeCapacity: 50 } },
                               type: { primary: 1, pub: 1, projections: 1 },
                               name: { index: 1, pub: 1 } }
                             });
</code></pre>
<p>Create DynamoDB table with global secondary index, the first index property if not the same as primary key hash defines global index, if it is the same then local,
or if the second key column contains <code>global</code> property then it is a global index as well, below we create global secondary index on property &#39;name&#39; only,
in the example above it was local secondary index for id and name. Also a local secondary index is created on <code>id,title</code>.</p>
<p>DynamoDB projection is defined by a <code>projections</code> property, can be a number/boolean or an array with index numbers:</p>
<pre><code>     db.create(&quot;test_table&quot;, { id: { primary: 1, type: &quot;int&quot;, index1: 1 },
                               type: { primary: 1, projections: [0] },
                               name: { index: 1, projections: 1 },
                               title: { index1: 1, projections: [1] } },
                               descr: { index: 1, projections: [0, 1] },
                             });
</code></pre>
<p> When using real DynamoDB creating a table may take some time, for such cases if <code>options.waitTimeout</code> is not specified it defaults to 1min,
 so the callback is called as soon as the table is active or after the timeout whichever comes first.</p>
<p>Pass MongoDB options directly:
       db.create(&quot;test_table&quot;, { id: { primary: 1, type: &quot;int&quot;, mongodb: { w: 1, capped: true, max: 100, size: 100 } },
                                 type: { primary: 1, pub: 1 },
                                 name: { index: 1, pub: 1, mongodb: { sparse: true, min: 2, max: 5 } }
                               });</p>
</li>
</ul>

<ul>
<li><p><code>db.upgrade(table, columns, options, callback)</code></p>
<p>  Upgrade a table with missing columns from the definition list, if after the upgrade new columns must be re-read from the database
then <code>info.affected_rows</code> must be non zero.</p>
</li>
</ul>

<ul>
<li><p><code>db.drop(table, options, callback)</code></p>
<p>  Drop a table</p>
</li>
</ul>

<ul>
<li><p><code>db.sql(text, values, options, callback)</code></p>
<p>  Execute arbitrary SQL-like statement if the pool supports it, values must be an Array with query parameters or can be omitted.</p>
<p>Example:</p>
<pre><code>  db.sql(&quot;SELECT * FROM bk_property WHERE value=? LIMIT 1&quot;, [1], { pool: &quot;sqlite&quot;, count: 10 }, lib.log)
  db.sql(&quot;SELECT * FROM bk_property&quot;, { pool: &quot;dynamodb&quot; }, lib.log)
  db.sql(&quot;SELECT * FROM bk_property&quot;, { pool: &quot;dynamodb&quot;, count: 10 }, lib.log)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.getCached(op, table, query, options, callback)</code></p>
<p>  Retrieve cached result or put a record into the cache prefixed with table:key[:key...]
Options accept the same parameters as for the usual get action but it is very important that all the options
be the same for every call, especially <code>select</code> parameters which tells which columns to retrieve and cache.
Additional options:</p>
<ul>
<li>prefix - prefix to be used for the key instead of table name</li>
</ul>
<p> Example:</p>
<pre><code> db.getCached(&quot;get&quot;, &quot;bk_user&quot;, { login: req.query.login }, { select: &quot;latitude,longitude&quot; }, function(err, row) {
     var distance = lib.geoDistance(req.query.latitude, req.query.longitude, row.latitude, row.longitudde);
 });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.getCache(table, query, options, callback)</code></p>
<p>  Retrieve an object from the cache by key, sets <code>cacheKey</code> in the options for later use</p>
</li>
</ul>

<ul>
<li><p><code>db.putCache(table, query, options)</code></p>
<p>  Store a record in the cache</p>
</li>
</ul>

<ul>
<li><p><code>db.delCache(table, query, options)</code></p>
<p>  Notify or clear cached record, this is called after del/update operation to clear cached version by primary keys</p>
</li>
</ul>

<ul>
<li><p><code>db.getCacheKey(table, query, options)</code></p>
<p>  Returns concatenated values for the primary keys, this is used for caching records by primary key</p>
</li>
</ul>

<ul>
<li><p><code>db.getCacheOptions(table, options, update)</code></p>
<p>  Setup common cache properties</p>
</li>
</ul>

<ul>
<li><p><code>db.getCache2Ttl(table, options)</code></p>
<p>  Return TTL for level 2 cache, negative means use js cache</p>
</li>
</ul>

<ul>
<li><p><code>db.getCacheKeys(table, query, name)</code></p>
<p>  Return a list of global cache keys, if a name is given only returns the matching key</p>
</li>
</ul>

<ul>
<li><p><code>db.delCacheKeys(req, result, options, callback)</code></p>
<p>  Delete all global cache keys for the table record</p>
</li>
</ul>

<ul>
<li><p><code>db.init(options, callback)</code></p>
<p>  Initialize all database pools. the options may containt the following properties:</p>
<ul>
<li>createTables - if true then create new tables or upgrade tables with new columns</li>
<li>localTables - if true only enable local, default and config pools</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.initConfig(options, callback)</code></p>
<p>  Load configuration from the config database, must be configured with <code>db-config-type</code> pointing to the database pool where bk_config table contains
configuration parameters.</p>
<p>The priority of the paramaters is fixed and goes from the most broad to the most specific, most specific always wins, this allows
for very flexible configuration policies defined by the app or place where instances running and separated by the run mode.</p>
<p>The following list of properties will be queried from the config database and the sorting order is very important, the last values
will override values received for the earlier properties, for example, if two properties defined in the <code>bk_config</code> table with the
types <code>myapp</code> and <code>prod-myapp</code>, then the last value will be used only.</p>
<p>The major elements are the following:</p>
<ul>
<li>the run mode specified in the command line <code>-run-mode: production</code></li>
<li>the application name from the package.json: <code>myapp</code></li>
<li>the process role: <code>-worker</code></li>
<li>the instance tag, AWS name tag or other name: <code>-nat</code></li>
</ul>
<p>The modifiers which are appended to each major attributes:</p>
<ul>
<li>the network where the instance is running, first 2 octets from the current IP address: <code>-192.168</code></li>
<li>the region where the instance is running, AWS region or other: <code>us-east-1</code></li>
</ul>
<p>The top level list is the following:</p>
<ul>
<li>runMode</li>
<li>appName</li>
<li>runMode-appName</li>
<li>runMode-role</li>
<li>runMode-tag</li>
<li>runMode-tag-role</li>
<li>runMode-appName-role</li>
<li>runMode-appName-tag</li>
</ul>
<p>All modifiers are appended for every item in the list like <code>runMode-network</code>, <code>runMode-appName-tag-region</code>,...</p>
<p>The options takes the following properties:</p>
<ul>
<li>force - if true then force to refresh and reopen all db pools</li>
<li>delta - if true then pull only records updated since the last config pull using the max mtime from received records.</li>
<li>table - a table where to read the config parameters, default is bk_config</li>
</ul>
<p><strong>NOTE: The config parameters from the DB always take precedence even over config.local.</strong></p>
<p>On return, the callback second argument will receive all parameters received form the database as a list: -name value ...</p>
</li>
</ul>

<ul>
<li><p><code>db.getConfig(options, callback)</code></p>
<p>  Return all config records for the given instance, the result will be sorted most relevant at the top</p>
</li>
</ul>

<ul>
<li><p><code>db.refreshConfig(options, callback)</code></p>
<p>  Refresh parameters which are configured with a TTL</p>
</li>
</ul>


<ul>
<li><p><code>Pool.prototype.convertError(table, op, err, options)</code></p>
<p>  Convert into recognizable error codes</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.query(client, req, options, callback)</code></p>
<p>  Simulate query as in SQL driver but performing AWS call, text will be a table name and values will be request options</p>
</li>
</ul>

<p>  Create a database pool that works with ElasticSearch server, only the hostname and port will be used, by default each table
  is stored in its own index.</p>
<p>  To define shards and replicas per index:</p>
<ul>
<li><code>-db-elasticsearch-pool-options-shards-INDEX_NAME=NUM</code></li>
<li><code>-db-elasticsearch-pool-options-replicas-INDEX_NAME=NUM</code></li>
</ul>
<p>  To support multiple seed nodes a parameter <code>-db-elasticsearch-pool-options-servers=1.1.1.1,2.2.2.2</code> can be specified, if the primary node
  fails it will switch to other configured nodes. To control the switch retries and timeout there are options:</p>
<ul>
<li><code>-db-elasticsearch-pool-options-retry-count=3</code></li>
<li><code>-db-elasticsearch-pool-options-retry-timeout=250</code></li>
</ul>
<p>  On successful connect to any node the driver retrieves full list of nodes in the cluster and switches to a random node, this happens
  every <code>discovery-interval</code> in milliseconds, default is 1h, it can be specified as <code>-db-elasticserch-pool-options-discovery-interval=300000</code></p>


<ul>
<li><p><code>Pool.prototype.cacheIndexes(options, callback)</code></p>
<p>  Cache indexes using the information_schema</p>
</li>
</ul>

<ul>
<li><p><code>db.getPool(options)</code></p>
<p>  Return database pool by name or default pool, options can be a pool name or an object with { pool: name } to return
the pool by given name. This call always returns a valid pool object, in case no requested pool found, it returns
the default pool, in case of invalid pool name it returns <code>none</code> pool.
A special pool <code>none</code> always returns empty result and no errors.</p>
</li>
</ul>

<ul>
<li><p><code>db.getPoolTables(name, options)</code></p>
<p>  Return all tables know to the given pool, returned tables are in the object with
column information merged from cached columns from the database with description columns
given by the application. If <code>options.names</code> is 1 then return just table names as a list.</p>
</li>
</ul>

<ul>
<li><p><code>db.getPools()</code></p>
<p>  Return a list of all active database pools, returns list of objects with name: and type: properties</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool(options, defaults)</code></p>
<p>  Create a new database pool with default methods and properties</p>
<ul>
<li>options - an object with default pool properties<ul>
<li>type - pool type, this is the db driver name</li>
<li>pool or name - pool name</li>
<li>watchfile - file path to be watched for changes, all clients will be destroyed gracefully</li>
<li>min - min number of open database connections</li>
<li>max - max number of open database connections, all attempts to run more will result in clients waiting for the next available db connection, if set to 0 no
  pooling will be enabled and will result in the unlimited connections, this is default for DynamoDB</li>
<li>max_queue - how many db requests can be in the waiting queue, above that all requests will be denied instead of putting in the waiting queue</li>
</ul>
</li>
</ul>
<p>The db methods cover most use cases but in case native driver needs to be used this is how to get the client and use it with its native API,
it is required to call <code>pool.release</code> at the end to return the connection back to the connection pool.</p>
<pre><code>     var pool = db.getPool(&quot;mongodb&quot;);
     pool.get(function(err, client) {
         var collection = client.collection(&#39;bk_user&#39;);
         collection.findOne({ id: &#39;123&#39; }, function() {
             pool.release(client);
         });
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.configure(options)</code></p>
<p>  Reconfigure properties, only subset of properties are allowed here so it is safe to apply all of them directly,
this is called during realtime config update</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.open(callback)</code></p>
<p>  Open a connection to the database, default is to return an empty object as a client</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.close(client, callback)</code></p>
<p>  Close a connection, default is do nothing</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.query(client, req, options, callback)</code></p>
<p>  Query the database, always return an array as a result (i.e. the second argument for the callback)</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.cacheColumns(options, callback)</code></p>
<p>  Cache columns for all tables</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.cacheIndexes(options, callback)</code></p>
<p>  Cache indexes for all tables</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.nextToken(client, req, rows)</code></p>
<p>  Return next token from the client object</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.prepareOptions(options)</code></p>
<p>  Update the options with pool config parameters if needed, the options is from the request</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.prepareRow(req)</code></p>
<p>  Default prepareRow is to perform pool specific actions for prepared row before passing it to the op specific columns filterting</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.prepare(req)</code></p>
<p>  Default prepare is to return all parameters in an object</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.bindValue(req, name, value, op)</code></p>
<p>  Return the value to be used in binding, mostly for SQL drivers, on input value and col info are passed, this callback
may convert the value into something different depending on the DB driver requirements, like timestamp as string into milliseconds</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.convertError(table, op, err, options)</code></p>
<p>  Converts native DB driver error into other human readable format</p>
</li>
</ul>

<ul>
<li><p><code>db.Pool.prototype.processColumns(pool)</code></p>
<p>  that is called after this pool cached columms from the database, it is called sychnroniously inside the <code>db.cacheColumns</code> method.</p>
</li>
</ul>

<ul>
<li><p><code>db.prepare(op, table, obj, options)</code></p>
<p>  Prepare for execution for the given operation: add, del, put, update,...
Returns prepared object to be passed to the driver&#39;s .query method. This method is a part of the driver
helpers and is not used directly in the applications.</p>
</li>
</ul>

<ul>
<li><p><code>db.prepareRow(pool, req)</code></p>
<p>  Preprocess an object for a given operation, convert types, assign defaults...</p>
</li>
</ul>

<ul>
<li><p><code>db.prepareForUpdate(pool, req)</code></p>
<p>  Keep only columns from the table definition if we have it
Go over all properties in the object and makes sure the types of the values correspond to the column definition types,
this is for those databases which are very sensitive on the types like DynamoDB.</p>
</li>
</ul>

<ul>
<li><p><code>db.joinColumn(req, obj, name, col)</code></p>
<p>  Join several columns to produce a combined property if configured, given a column description and an object record
it replaces the column value with joined value if needed. Empty properties will be still joined as empty strings.
It always uses the original value even if one of the properties has been joined already.</p>
<p>Checks for <code>join</code> property in the column definition.</p>
<ul>
<li><code>join_ops</code> - an array with operations for which perform columns join only, if not specified it applies for all operations,
  allowed values: add, put, incr, update, del, get, select</li>
<li><code>join_ifempty</code> - only join if the column value is not provided</li>
<li><code>skip_join</code> can be used to restrict joins, it is a list with columns that should not be joined</li>
<li><code>join_pools</code> can be an array with pool names which are allowed to do the join, other pools will skip joining this column.</li>
<li><code>nojoin_pools</code> can be an array with pool names which are not allowed to do the join, other pools will skip joining this column</li>
<li><code>join_strict</code> can be used to perform join only if all columns in the list are not empty, so the join
is for all columns or none</li>
<li><code>join_all</code> can be used to proceed and join empty values, without it the any join stops on firtst empty value but
marked to be checked later in case the empty column is not empty anymore in case of uuid or other auto-generated column type.</li>
<li><code>join_force</code> can be used to force the join regardless of the existing value, without it if the existing value contains the
separator it is skipped</li>
<li><code>join_hash</code> can be used to store a hash of the joined column to reduce the space and make the result value easier to use</li>
<li><code>join_cap, join_lower, join_upper</code> - convert the joined value with toTitle, lower or upper case</li>
<li>`join_process`` - a function(req, value, obj, col) - must return a value to be used, the value is joined already</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.unjoinColumns(rows, name, col, options)</code></p>
<p>  Split joined columns for all rows</p>
</li>
</ul>

<ul>
<li><p><code>db.convertRows(pool, req, rows, options)</code></p>
<p>  Convert rows returned by the database into the Javascript format or into the format
defined by the table columns.
The following special properties in the column definition chnage the format:</p>
<ul>
<li><p>type = json - if a column type is json and the value is a string returned will be converted into a Javascript object</p>
</li>
<li><p>dflt property is defined for a json type and record does not have a value it will be set to specified default value</p>
</li>
<li><p>list - split the value into an array, optional .separator property can be specified</p>
</li>
<li><p>unjoin - a true value or a list of names, it produces new properties by splitting the value by a separator and assigning pieces to
  separate properties using names from the list, this is the opposite of the <code>join</code> property and is used separately if
  splitting is required, if joined properties already in the record then no need to split it. If not a list
  the names are used form the join property.</p>
<p>  Example:
      db.describeTables([ { user: { id: {}, name: {}, pair: { join: [&quot;left&quot;,&quot;right&quot;], unjoin: 1 } } ]);

      db.put(&quot;test&quot;, { id: &quot;1&quot;, type: &quot;user&quot;, name: &quot;Test&quot;, left: &quot;123&quot;, right: &quot;000&quot; })
      db.select(&quot;test&quot;, {}, lib.log)</p>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.setProcessColumns(callback)</code></p>
<p>  Add a callback to be called after each cache columns event, it will be called for each pool separately.
The callback to be called may take options argument and it is called in the context of the pool.</p>
<p>The primary goal for this hook is to allow management of the existing tables which are not own by the
backendjs application. For such tables, because we have not created them, we need to define column properties
after the fact and to keep column definitions in the app for such cases is not realistic. This callback will
allow to handle such situations and can be used to set necessary propeties to the table columns.</p>
<p>Example, a few public columns, allow an admin to see all the columns</p>
<pre><code>    db.setProcessColumns(function() {
        var cols = db.getColumns(&quot;users&quot;, { pool: this.name });
        for (var p in  cols) {
            if ([&quot;id&quot;,&quot;name&quot;].indexOf(p) &gt; -1) cols[p].pub = 1; else cols[p].admin = 1;
        }
    })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.getProcessRows(type, table, options)</code></p>
<p>  Returns a list of hooks to be used for processing rows for the given table</p>
</li>
</ul>

<ul>
<li><p><code>db.runProcessRows(type, table, req, rows)</code></p>
<p>  Run registered pre- or post- process callbacks.</p>
<ul>
<li><code>type</code> is one of the <code>pre</code> or &#39;post`</li>
<li><code>table</code> - the table to run the hooks for, usually the same as req.table but can be &#39;*&#39; for global hooks</li>
<li><code>req</code> is the original db request object with the following required properties: <code>op, table, obj, options, info</code>,</li>
<li><code>rows</code> is the result rows for post callbacks and the same request object for pre callbacks.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.setProcessRow(type, table, options, callback)</code></p>
<p>  Assign a processRow callback for a table, this callback will be called for every row on every result being retrieved from the
specified table thus providing an opportunity to customize the result.</p>
<p>type defines at what time the callback will be called:</p>
<ul>
<li><code>pre</code> - making a request to the db on the query record</li>
<li><code>post</code> - after the request finished to be called on the result rows</li>
</ul>
<p>All assigned callback to this table will be called in the order of the assignment.</p>
<p>The callback accepts 2 arguments: function(req, row)
  where:</p>
<ul>
<li><code>req</code> - the original request for a db operation with required<ul>
<li><code>op</code> - current db operation, like add, put, ....</li>
<li><code>table</code> -  current table being updated</li>
<li><code>obj</code> - the record with data</li>
<li><code>pool</code> - current request db pool name</li>
<li><code>options</code> - current request db options</li>
<li><code>info</code> - an object returned with special properties like affected_rows, next_token, only passed to the <code>post</code> callbacks</li>
</ul>
</li>
<li><code>row</code> - a row from the result</li>
</ul>
<p>When producing complex properties by combining other properties it needs to be synchronized using both pre and post
callbacks to keep the record consistent.</p>
<p><strong>For queries returning rows, if the callback returns true for a row it will be filtered out and not included in the final result set.</strong></p>
<p> Example</p>
<pre><code> db.setProcessRow(&quot;post&quot;, &quot;bk_user&quot;, function(req, row) {
     if (row.birthday) row.age = Math.floor((Date.now() - lib.toDate(row.birthday))/(86400000*365));
 });

 db.setProcessRow(&quot;post&quot;, &quot;bk_icon&quot;, function(req, row) {
     if (row.type == &quot;private&quot; &amp;&amp; row.id != req.options.account.id) return true;
 });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.SqlPool(options, defaults)</code></p>
<p>  Create a database pool for SQL like databases</p>
<ul>
<li>options - an object defining the pool, the following properties define the pool:<ul>
<li>pool - pool name/type, if not specified the SQLite is used</li>
<li>max - max number of clients to be allocated in the pool</li>
<li>idle - after how many milliseconds an idle client will be destroyed</li>
</ul>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.SqlPool.prototype.cacheColumns(options, callback)</code></p>
<p>  Call column caching callback with our pool name</p>
</li>
</ul>

<ul>
<li><p><code>db.SqlPool.prototype.prepare(req)</code></p>
<p>  Prepare for execution, return an object with formatted or transformed SQL query for the database driver of this pool</p>
</li>
</ul>

<ul>
<li><p><code>db.SqlPool.prototype.query(client, req, options, callback)</code></p>
<p>  Execute a query or if req.text is an Array then run all queries in sequence</p>
</li>
</ul>

<ul>
<li><p><code>db.SqlPool.prototype.nextToken(client, req, rows)</code></p>
<p>  Support for pagination, for SQL this is the OFFSET for the next request</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlQuery(pool, client, req, options, callback)</code></p>
<p>  Execute one or more SQL statements</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlCacheColumns(pool, options, callback)</code></p>
<p>  Cache columns using the information_schema</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlPrepare(pool, req)</code></p>
<p>  Prepare SQL statement for the given operation</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlQuote(val)</code></p>
<p>  Quote value to be used in SQL expressions</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlValue(value, options)</code></p>
<p>  Return properly quoted value to be used directly in SQL expressions, format according to the type</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlValueIn(list, type)</code></p>
<p>  Return list in format to be used with SQL IN ()</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlExpr(pool, name, value, options)</code></p>
<p>  Build SQL expressions for the column and value
options may contain the following properties:</p>
<ul>
<li>op - SQL operator, default is =</li>
<li>type - can be data, string, number, float, expr, default is string</li>
<li>value - default value to use if passed value is null or empty</li>
<li>min, max - are used for numeric values for validation of ranges</li>
<li>expr - for op=expr, contains sprintf-like formatted expression to be used as is with all &#39;%s&#39; substituted with actual value</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.sqlTime(d)</code></p>
<p>  Return time formatted for SQL usage as ISO, if no date specified returns current time</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlLimit(pool, req)</code></p>
<p>  Build SQL orderby/limit/offset conditions, config can define defaults for sorting and paging</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlWhere(pool, req, query, keys, join)</code></p>
<p>  Build SQL where condition from the keys and object values, returns SQL statement to be used in WHERE</p>
<ul>
<li>query - properties for the condition, in case of an array the primary keys for IN condition will be used only,
 a property named $or or $and will be treated as a sub-expression if it is an object.</li>
<li>keys - a list of columns to use for the condition, other properties will be ignored</li>
<li>options may contains the following properties:<ul>
<li>pool - pool to be used for driver specific functions</li>
<li>ops - an object for comparison operators for primary key, default is equal operator</li>
<li>aliases - an object with column aliases, for cases when more than one time the same column mut be used</li>
</ul>
</li>
<li>join - how to join all expressions, default is AND</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.sqlCreate(pool, req)</code></p>
<p>  Create SQL table using table definition</p>
<ul>
<li>table - name of the table to create</li>
<li>obj - object with properties as column names and each property value is an object:<ul>
<li>name - column name</li>
<li>type - type of the column, default is TEXT, options: int, real or other supported types</li>
<li>value - default value for the column</li>
<li>primary - part of the primary key</li>
<li>index - indexed column, part of the composite index</li>
<li>unique - must be combined with index property to specify unique composite index</li>
<li>len - max length of the column</li>
<li>notnull - true if should be NOT NULL</li>
<li>auto - true for AUTO_INCREMENT column</li>
<li>hidden - skip column completely</li>
</ul>
</li>
<li>options may contains:<ul>
<li>upgrade - perform alter table instead of create</li>
<li>typesMap - type mapping, convert lowercase type into other type supported by any specific database</li>
<li>noDefaults - ignore default value if not supported (Cassandra)</li>
<li>noNulls - NOT NULL restriction is not supported (Cassandra)</li>
<li>noMultiSQL - return as a list, the driver does not support multiple SQL commands</li>
<li>noLengths - ignore column length for columns (Cassandra)</li>
<li>noIfExists - do not support IF EXISTS on table or indexes</li>
<li>noCompositeIndex - does not support composite indexes (Cassandra)</li>
<li>noAuto - no support for auto increment columns</li>
<li>skipNull - object with operations which dont support null(empty) values (DynamoDB cannot add/put empty/null values)</li>
</ul>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.sqlUpgrade(pool, req)</code></p>
<p>  Create ALTER TABLE ADD COLUMN statements for missing columns</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlDrop(pool, req)</code></p>
<p>  Create SQL DROP TABLE statement</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlGet(pool, req)</code></p>
<p>  Get one object from the database,
options may define the following properties:</p>
<ul>
<li>select is list of columns or expressions to return</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.sqlSelect(pool, req)</code></p>
<p>  Select object from the database,
options may define the following properties:</p>
<ul>
<li>keys is a list of columns for the condition</li>
<li>select is list of columns or expressions to return</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.sqlInsert(pool, req)</code></p>
<p>  Build SQL insert statement</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlUpdate(pool, req)</code></p>
<p>  Build SQL statement for update</p>
</li>
</ul>

<ul>
<li><p><code>db.sqlDelete(pool, req)</code></p>
<p>  Build SQL statement for delete</p>
</li>
</ul>


<ul>
<li><p><code>db.initTables()</code></p>
<p>  Merge all tables from all modules</p>
</li>
</ul>

<ul>
<li><p><code>db.createTables(options, callback)</code></p>
<p>  Create or upgrade the tables for the given pool</p>
</li>
</ul>

<ul>
<li><p><code>db.describeTables(tables, callback)</code></p>
<p>  Define new tables or extend/customize existing tables. Table definitions are used with every database operation,
on startup, the backend read all existing table columns from the database and cache them in the memory but some properties
like public columns are only specific to the backend so to mark such columns the table with such properties must be described
using this method. Only columns with changed properties need to be specified, other columns will be left as it is.</p>
<p>Example</p>
<pre><code>     db.describeTables({
         bk_user: { name: { pub: 1 },
                    test: { id: { primary: 1, type: &quot;int&quot; },
                    name: { pub: 1, index: 1 }
     }});
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.convertError(pool, table, op, err, options)</code></p>
<p>  Convert native database error in some generic human readable string</p>
</li>
</ul>

<ul>
<li><p><code>db.refreshColumns(options, callback)</code></p>
<p>  Refresh columns for all pools which need it</p>
</li>
</ul>

<ul>
<li><p><code>db.cacheColumns(options, callback)</code></p>
<p>  Reload all columns into the cache for the pool, options can be a pool name or an object like <code>{ pool: name }</code>.
if <code>tables</code> property is an arary it asks to refresh only specified tables if that is possible.</p>
</li>
</ul>

<ul>
<li><p><code>db.existsPool(name)</code></p>
<p>  Returns true if a pool exists</p>
</li>
</ul>

<ul>
<li><p><code>db.table(table)</code></p>
<p>  Return a normalized table name</p>
</li>
</ul>

<ul>
<li><p><code>db.alias(table)</code></p>
<p>  Returns a table alias if mapped or the same table name normalized</p>
</li>
</ul>

<ul>
<li><p><code>db.existsTable(table, options)</code></p>
<p>  Returns true if a table exists</p>
</li>
</ul>

<ul>
<li><p><code>db.getColumns(table, options)</code></p>
<p>  Return columns for a table or null, columns is an object with column names and objects for definition.</p>
</li>
</ul>

<ul>
<li><p><code>db.getColumn(table, name, options)</code></p>
<p>  Return the column definition for a table, for non-existent columns it returns an empty object</p>
</li>
</ul>

<ul>
<li><p><code>db.getCapacity(table, options)</code></p>
<p>  Return an object with capacity property which is the max write capacity for the table, for DynamoDB only.
By default it checks <code>writeCapacity</code> property of all table columns and picks the max.</p>
<p>The options can specify the capacity explicitely:</p>
<ul>
<li>useCapacity - what to use for capacity rating, can be <code>write</code>, <code>read</code> or a number with max capacity to use</li>
<li>factorCapacity - a number between 0 and 1 to multiple the rate capacity</li>
<li>rateCapacity - if set it will be used for rate capacity limit</li>
<li>maxCapacity - if set it will be used as the max burst capacity limit</li>
<li>minCapacity - if set it will be used as the minimum threshold</li>
<li>intervalCapacity - default is 1000 ms</li>
<li>sort - an index to use for capacity, for systems like DynamoDB which has different capacity for
global indexes, it makes sense for indexed reads or partial updates where only global index is affected and not the whole record</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.checkCapacity(cap, consumed, callback)</code></p>
<p>  Check if number of requests exceeds the capacity per second, delay if necessary, for DynamoDB only but can be used for pacing
requests with any database or can be used generically. The <code>cap</code> must be initialized with <code>db.getCapacity</code> call.</p>
</li>
</ul>

<ul>
<li><p><code>db.getSelectedColumns(req)</code></p>
<p>  Return list of selected or allowed only columns, empty list if no <code>options.select</code> is specified or it is equal to <code>*</code>. By default only allowed or existing
columns will be returned, to pass the list as is to the driver just use <code>options.select_all</code> instead.</p>
</li>
</ul>

<ul>
<li><p><code>db.getFilteredColumns(table, filter, options)</code></p>
<p>  Return table columns that match the given filter.
The filter can be:</p>
<ul>
<li>a string, means return all columns that contain the given property</li>
<li>an object, match column properties by value,<ul>
<li><code>undefined</code> means skip columns,</li>
<li><code>null</code> means column does not exist,</li>
<li><code>Infinity</code> means column is not undefined,</li>
<li><code>name</code> will match against the column name not a property</li>
</ul>
</li>
</ul>
<p>The options can contain:</p>
<ul>
<li>list - return just column names</li>
<li>select - an array with properties to return, this will create a new list of columns with specified properties only</li>
<li>strict - only return columns that match all conditions in the filter, default is at least one</li>
</ul>
<p>Example:</p>
<pre><code> db.getFilteredColumns(&quot;bk_user&quot;, &quot;pub&quot;)
 db.getFilteredColumns(&quot;bk_user&quot;, { pub: undefined })
 db.getFilteredColumns(&quot;bk_user&quot;, { pub: null, internal: 1 })
 db.getFilteredColumns(&quot;bk_user&quot;, { type: &quot;now&quot; }, { list: 1 })
 db.getFilteredColumns(&quot;bk_user&quot;, { name: /^email/ }, { select: [&quot;type&quot;] })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>db.checkCustomColumn(req, name)</code></p>
<p>  Returns type for a global custom column if exists otherwise null, all resolved
columns will be saved in <code>req.custom</code> for further reference as name: type.
For request specific custom columns pass <code>options.custom_columns</code> array in the format: [ RegExp, type, ...]</p>
</li>
</ul>

<ul>
<li><p><code>db.skipColumn(req, name, val)</code></p>
<p>  Verify column against common options for inclusion/exclusion into the operation, returns 1 if the column must be skipped</p>
<ul>
<li>to enable all properties to be saved in the record without column definition set <code>options.no_columns=1</code></li>
<li>to skip specific columns define <code>options.skip_columns=[&quot;a&quot;,&quot;b&quot;]</code></li>
<li>to restrict to specific DB pools only define <code>options.allow_pools=[&quot;sqlite&quot;,&quot;mysql&quot;]</code></li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.filterRows(query, rows, options)</code></p>
<p>  Given an object with data and list of keys perform comparison in memory for all rows, return only rows that match all keys. This method is used
by custom filters in <code>db.select</code> by the drivers which cannot perform comparisons with non-indexes columns like DynamoDb, Cassandra.
The rows that satisfy primary key conditions are returned and then called this function to eliminate the records that do not satisfy non-indexed column conditions.</p>
<p>Options support the following propertis:</p>
<ul>
<li>keys - list of columns to check, these may or may not be the primary keys, any columns to be compared</li>
<li>cols - an object with columns definition</li>
<li>ops - operations for columns</li>
<li>typesMap - types for the columns if different from the actual Javascript type</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>db.getKeys(table, options)</code></p>
<p>  Return primary keys for a table or empty array, if <code>allkeys</code> is given in the options then return
a list of all properties involed in primary keys including joined columns</p>
</li>
</ul>

<ul>
<li><p><code>db.getIndexes(table, options)</code></p>
<p>  Return indexes for a table or empty object, each item in the object is an array with index columns</p>
</li>
</ul>

<ul>
<li><p><code>db.getIndexColumns(table, options)</code></p>
<p>  Return columns for all indexes as alist</p>
</li>
</ul>

<ul>
<li><p><code>db.getIndexForKeys(table, keys, options)</code></p>
<p>  Return an index name that can be used for searching for the given keys, the index match is performed on the index columns
from the left to right  and stop on the first missing key, for example for given keys { id: &quot;1&quot;, name: &quot;2&quot;, state: &quot;VA&quot; }
the index [&quot;id&quot;, &quot;state&quot;] or [&quot;id&quot;,&quot;name&quot;] will be returned but the index [&quot;id&quot;,&quot;city&quot;,&quot;state&quot;] will not.</p>
</li>
</ul>

<ul>
<li><p><code>db.getSearchKeys(table, options)</code></p>
<p>  Return keys for the table search, if options.keys provided and not empty it will be used otherwise
table&#39;s primary keys will be returned. This is a wrapper that makes sure that valid keys are used and
deals with input errors like empty keys list to be consistent between different databases.
This function always returns an Array even if it is empty.</p>
</li>
</ul>

<ul>
<li><p><code>db.getSearchQuery(table, obj, options)</code></p>
<p>  Return query object based on the keys specified in the options or primary keys for the table, only search properties
will be returned in the query object</p>
</li>
</ul>

<ul>
<li><p><code>db.getQueryForKeys(keys, obj, options)</code></p>
<p>  Returns an object based on the list of keys, basically returns a subset of properties.
<code>options.keysMap</code> defines an object to map record properties with the actual names to be returned.</p>
</li>
</ul>

<h2 id="module-events">Module: events</h2>
<p>  Event queue processor</p>
<p>  If any of <code>events-worker-queue-XXX</code> parameters are defined then workers subscribe to configured event queues and listen for events.</p>
<p>  Each event queue can run multiple functions idependently but will ack/nack for all functions so to deal with replay dups it is advised to
  split between multiple consumers using the syntax: <code>queue#channel@consumer</code></p>
<p>  Multiple event queues can be defined and processed at the same time.</p>
<p>  An event processing function takes 2 arguments, an event and callback to call on finish</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>events-worker-queue-(.+)</code>, obj: &quot;worker-queue&quot;, type: &quot;list&quot;, onupdate: function() { if (ipc.role==&quot;worker&quot;&amp;&amp;core.role==&quot;worker&quot;) this.subscribeWorker() descr: &quot;Queues to subscribe for workers, same queues can be used at the same time with different functions and channels and consumers, event queue format is <code>queue#channel@consumer</code>, ex: -ipc-worker-queue-ticket ticket.processEvents, -ipc-worker-queue-ticket#inbox@staff ticket.processInboxEvents, -ipc-worker-queue-ticket@staff ticket.processStaffEvents&quot;</li>
<li><code>events-worker-options-(.+)</code>, obj: &quot;workerOptions&quot;, make: &quot;$1&quot;, type: &quot;json&quot;, logger: &quot;error&quot;, descr: &quot;Custom parameters by queue name, passed to <code>ipc.subscribeQueue</code> on worker start, useful with channels, ex: <code>-events-worker-options-ticket {\&quot;count\&quot;:3,\&quot;raw\&quot;:1}</code>&quot;</li>
<li><code>events-worker-delay</code>, type: &quot;int&quot;, descr: &quot;Delay in milliseconds for a worker before it will start accepting jobs, for cases when other dependencies may take some time to start&quot;</li>
<li><code>events-max-runtime</code>, type: &quot;int&quot;, min: 0, multiplier: 1000, descr: &quot;Max number of seconds an event processing can run before being killed&quot;</li>
<li><code>events-routing-(.+)</code>, obj: &quot;routing&quot;, type: &quot;regexp&quot;, empty: 1, descr: &quot;Queue routing by event topic&quot;</li>
<li><code>events-properties</code>, type: &quot;list&quot;, descr: &quot;List of properties to copy into an event envelope from the provided options&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>events.shutdownWorker(options, callback)</code></p>
<p>  Perform graceful worker shutdown, to be used for workers restart</p>
</li>
</ul>

<ul>
<li><p><code>events.checkTimes()</code></p>
<p>  Check how long we run a job and force kill if exceeded, check if total life time is exceeded.</p>
<p>If exit is required the <code>shundownWorker</code> methods will receive options with <code>shutdownReason</code> property
set and the name-sake property will contained the value exceeded.</p>
</li>
</ul>

<ul>
<li><p><code>events.putEvent(topic, data, options)</code></p>
<p>  Place an event into a queue by topic</p>
</li>
</ul>

<ul>
<li><p><code>events.getQueueByHandler(proc)</code></p>
<p>  Return a queue name by the event handler</p>
</li>
</ul>

<h2 id="module-httpget">Module: httpget</h2>
<p>  Downloads file using HTTP and pass it to the callback if provided</p>
<ul>
<li>uri can be full URL or an object with parts of the url, same format as in url.format</li>
<li>params can contain the following options:<ul>
<li>method - GET, POST</li>
<li>headers - object with headers to pass to HTTP request, properties must be all lower case</li>
<li>cookies - an object with cookies to send with request, if even empty rescookies will be set in the response</li>
<li>file - file name where to save response, in case of error response the error body will be saved as well, it uses sync file operations</li>
<li>stream - a writable stream where to save data</li>
<li>formdata - date to be sent with the request as x-www-form-urlencoded</li>
<li>postdata - data to be sent with the request in the body as JSON</li>
<li>postfile - file to be uploaded in the POST body, not as multipart</li>
<li>postsize - file size to be uploaded if obtained separately</li>
<li>posttype - content type for post data</li>
<li>multipart - an array of objects for multipart/form-data post, { name: &quot;..&quot;, data: &quot;..&quot; [ file: &quot;..&quot;] }, for files a Buffer can be used in data</li>
<li>noparse - do not parse known content types like json, xml</li>
<li>chunked - post files using chunked encoding</li>
<li>qsopts - an object to be passed to <code>qs.stringify</code></li>
<li>query - additional query parameters to be added to the url as an object or as encoded string</li>
<li>sign - sign request with provided email/secret properties</li>
<li>checksum - 1 if the body needs a checksum in the signature</li>
<li>mtime - a Date or timestamp to be used in conditional requests</li>
<li>conditional - add If-Modified-Since header using <code>params.mtime</code> if present or if <code>file</code> is given use file last modified timestamp, mtime</li>
<li>httpTimeout - timeout in milliseconds after which the request is aborted if no data received</li>
<li>hardTimeout - abort the request after this amount of time in ms, must be big enough to allow for all data to be received</li>
<li>maxSize - if the content being downloaded becomes greater than this size the request will be aborted</li>
<li>retryCount - how many times to retry the request on error or timeout</li>
<li>retryTimeout - timeout in milliseconds for retries, with every subsequent timeout it will be multiplied by <code>retryMultiplier</code></li>
<li>retryOnError - retry request if received non 2xx response status,
  if this is a function then it must return true in order to retry the request,
  otherwise it is treated as a boolean value, if true then retry on all non-2xx responses</li>
<li>retryPrepare - a function to be called before retrying, it can update any parameter, most related: _uri, retryTimeout, retryMultiplier</li>
<li>errorCount - how many times to retry on aborted connections, default is retryCount</li>
<li>noredirects - if true then do not follow redirect locations for 30-[1,2,3,7] statuses</li>
<li>preparse -  a function to be called before parsing the xml/json content, called in the context of the http object</li>
<li>passheaders -  a list of headers to be passed in redirects</li>
<li>user - authorization user, if also `password`` is provided then it will use Basic authorization, if only user is provided then Bearer</li>
</ul>
</li>
<li>callback will be called with the arguments:
  first argument is error object if any
  second is the params object itself with updated fields</li>
</ul>
<p>  On end, the object params will contain the following updated properties:</p>
<ul>
<li>data if file was not specified, data will contain collected response body as string</li>
<li>obj - if the content type is a known type like json or xml this property will hold a reference to the parsed document or null in case or parse error</li>
<li>status - HTTP response status code</li>
<li>date - Date object with the last modified time of the requested file</li>
<li>resheaders - response headers as an object</li>
<li>rescookies - parsed cookies from the response if request `cookies`` is not empty</li>
<li>size - size of the response body or file</li>
<li>type - response content type</li>
</ul>
<p>  Note: SIDE EFFECT: the params object is modified in place so many options will be changed/removed or added</p>

<h2 id="module-ipc">Module: ipc</h2>
<p>  IPC communications between processes and support for caching and subscriptions via queues.</p>
<p>  The module is EventEmitter and emits messages received.</p>
<p>  Some drivers may support TTL so global <code>options.ttl</code> or local <code>options.ttl</code> can be used for <code>put/incr</code> operations and it will honored if it is suported.</p>
<p>  For caches that support maps, like Redis or Hazelcast the <code>options.mapName</code> can be used with get/put/incr/del to
  work with maps and individual keys inside maps.</p>
<p>  All methods use <code>options.queueName</code> or <code>options.cacheName</code> for non-default queue or cache.
  If it is an array then a client will be picked sequentially by maintaining internal sequence number.</p>
<p>  To specify a channel within a queue use the format <code>queueName#channelName</code>, for drivers that support multiple channels like NATS/Redis
  the channel will be used for another subscription within the same connection.</p>
<p>  For drivers (NATS) that support multiple consumers the full queue syntax is <code>queueName#channelName@groupName</code> or <code>queueName@groupName</code>,
  as well as the <code>groupName</code> property in the subscribe options.</p>
<p>  A special system queue can be configured and it will be used by all processes to listen for messages on the channel <code>bkjs:role</code>, where the role
  is the process role, the same messages that are processed by the server/worker message handlers like api:restart, config:init,....
  All instances will be listening and processing these messages at once, the most usefull use case is refreshing the DB config on demand or
  restarting without configuring any other means like SSH, keys....</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>ipc-none</code>, type: &quot;bool&quot;, descr: &quot;disable all IPC subsystems&quot;</li>
<li><code>ipc-ping-interval</code>, type: &quot;int&quot;, min: 0, descr: &quot;Interval for a worker keep-alive pings, if not received within this period it will be killed&quot;</li>
<li><code>ipc-lru-max</code>, type: &quot;int&quot;, obj: &quot;lru&quot;, descr: &quot;Max number of items in the limiter LRU cache, this cache is managed by the master Web server process and available to all Web processes maintaining only one copy per machine&quot;</li>
<li><code>ipc-system-queue</code>, descr: &quot;System queue name to send broadcast control messages, this is a PUB/SUB queue to process system messages like restart, re-init config,...&quot;</li>
<li><code>ipc-(cache|queue)-?([a-z0-9]+)?$</code>, obj: &quot;configParams.$2&quot;, make: &quot;_url&quot;, nocamel: 1, onupdate: function(v,o) {this.applyOptions(v,o) descr: &quot;An URL that points to a cache/queue server in the format <code>PROTO://HOST[:PORT]?PARAMS</code>, multiple clients can be defined with unique names, all params starting with <code>bk-</code> will be copied into the options without the prefix and removed from the url, the rest of params will be left in the url, ex: -ipc-queue-redis redis://localhost?bk-count=3&amp;bk-ttl=3000&quot;</li>
<li><code>ipc-(cache|queue)(-([a-z0-9]+)?-?options)-(.+)$</code>, obj: &quot;configParams.$3&quot;, make: &quot;$4&quot;, camel: &#39;-&#39;, autotype: 1, onupdate: function(v,o) {this.applyOptions(v,o) descr: &quot;Additional parameters for clients, specific to each implementation, ex: <code>-ipc-queue-options-count 10</code>&quot;</li>
<li><code>ipc-(cache|queue)-([a-z0-9]*)-options$</code>, obj: &quot;configParams.$2&quot;, type: &quot;map&quot;, merge: 1, maptype: &quot;auto&quot;, onupdate: function(v,o) {this.applyOptions(v,o) descr: &quot;Additional parameters for clients, specific to each implementation, ex: `-ipc-queue--options count:10,interval:100&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.handleServerMessages(worker, msg)</code></p>
<p>  To be used in messages processing that came from the clients or other way</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.sendReplPort(role, worker)</code></p>
<p>  Send REPL port to a worker if needed</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.newMsg(op, msg, options)</code></p>
<p>  Returns an IPC message object, <code>msg</code> must be an object if given.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.emitMsg(op, msg, options)</code></p>
<p>  Wrapper around EventEmitter <code>emit</code> call to send unified IPC messages in the same format</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.sendMsg(op, msg, options, callback)</code></p>
<p>  Send a message to the master process via IPC messages, callback is used for commands that return value back</p>
<ul>
<li>the <code>timeout</code> property can be used to specify a timeout for how long to wait the reply, if not given the default is used</li>
<li>the rest of the properties are optional and depend on the operation.</li>
</ul>
<p>If called inside the server, it process the message directly, reply is passed in the callback if given.</p>
<p>Examples:</p>
<pre><code>   ipc.sendMsg(&quot;op1&quot;, { data: &quot;data&quot; }, { timeout: 100 })
   ipc.sendMsg(&quot;op1&quot;, { name: &quot;name&quot;, value: &quot;data&quot; }, function(data) { console.log(data); })
   ipc.sendMsg(&quot;op1&quot;, { 1: 1, 2: 2 }, { timeout: 100 })
   ipc.sendMsg(&quot;op1&quot;, { 1: 1, 2: 2 }, function(data) { console.log(data); })
   ipc.newMsg({ __op: &quot;op1&quot;, name: &quot;test&quot; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.initServer()</code></p>
<p>  This function is called by a master server process to setup IPC channels and support for cache and messaging</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.initWorker()</code></p>
<p>  This function is called by a worker process to setup IPC channels and support for cache and messaging</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.createClient(url, options)</code></p>
<p>  Return a new client for the given host or null if not supported</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.getQueue(options)</code></p>
<p>  Return a cache or queue client by name if specified in the options or use default client which always exists,
use <code>queueName</code> to specify a specific queue. If it is an array it will rotate items sequentially.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.initClients()</code></p>
<p>  Initialize a client for cache or queue purposes, previous client will be closed.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.checkClients()</code></p>
<p>  Initialize missing or new clients, existing clients stay the same</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.closeClients()</code></p>
<p>  Close all existing clients except empty local client</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.stats(options, callback)</code></p>
<p>  Returns the cache statistics, the format depends on the cache type used, for queues it returns a property &#39;queueCount&#39; with currently
visible messages in the queue, &#39;queueRunning&#39; with currently in-flight messages</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.clear(pattern, options, callback)</code></p>
<p>  Clear all or only items that match the given pattern</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.get(key, options, callback)</code></p>
<p>  Retrieve an item from the cache by key.</p>
<ul>
<li><code>options.set</code> is given and no value exists in the cache it will be set as the initial value, still
 nothing will be returned to signify that a new value assigned.</li>
<li><code>options.mapName</code> defines a map from which the key will be retrieved if the cache supports maps, to get the whole map
 the key must be set to *</li>
<li><code>options.listName</code> defines a map from which to get items, if a key is given it will return 1 if it belongs to the list,
 if no key is provided it will return an array with 2 elements:  [a random key, the length of the list], to get the whole list specify * as the key. Specifying
 <code>del</code> in the options will delete returned items from the list.</li>
<li><code>options.ttl</code> can be used with lists with <code>del</code> and empty key, in such case all popped up keys will be saved in
the cache with specified time to live, when being popped up every key is checked if it has been served already, i.e.
it exists in the cache and not expired yet, such keys are ignored and only never seen keys are returned</li>
<li><code>options.datatype</code> specifies that the returned value must be converted into the specified type using <code>lib.toValue</code></li>
</ul>
<p>If the <code>key</code> is an array then it returns an array with values for each key, for non existent keys an empty
string will be returned. For maps only if the <code>key</code> is * it will return the whole object, otherwise only value(s)
are returned.</p>
<p>Example</p>
<p>   ipc.get([&quot;my:key1&quot;, &quot;my:key2&quot;], function(err, data) { console.log(data) });
   ipc.get(&quot;my:key&quot;, function(err, data) { console.log(data) });
   ipc.get(&quot;my:counter&quot;, { set: 10 }, function(err, data) { console.log(data) });
   ipc.get(&quot;*&quot;, { mapName: &quot;my:map&quot; }, function(err, data) { console.log(data) });
   ipc.get(&quot;key1&quot;, { mapName: &quot;my:map&quot; }, function(err, data) { console.log(data) });
   ipc.get([&quot;key1&quot;, &quot;key2&quot;], { mapName: &quot;my:map&quot; }, function(err, data) { console.log(data) });
   ipc.get([&quot;key1&quot;, &quot;key2&quot;], { listName: &quot;my:list&quot; }, function(err, data) { console.log(data) });
   ipc.get(&quot;&quot;, { listName: &quot;my:list&quot;, del: 1 }, function(err, data) { console.log(data) });
   ipc.get(&quot;&quot;, { listName: &quot;my:list&quot;, del: 1, ttl: 30000 }, function(err, data) { console.log(data) });</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.del(key, options, callback)</code></p>
<p>  Delete an item by key(s),  if <code>key</code> is an array all keys will be deleted at once atomically if supported</p>
<ul>
<li><code>options.mapName</code> defines a map from which the counter will be deleted if the cache supports maps, to delete the whole map
 the key must be set to *</li>
<li><code>options.listName</code> defines a list from which an item should be removed</li>
</ul>
<p>Example:</p>
<pre><code>   ipc.del(&quot;my:key&quot;)
   ipc.del(&quot;key1&quot;, { mapName: &quot;my:map&quot; })
   ipc.del(&quot;*&quot;, { mapName: &quot;my:map&quot; })
   ipc.del(&quot;1&quot;, { listName: &quot;my:list&quot; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.put(key, val, options, callback)</code></p>
<p>  Replace or put a new item in the cache.</p>
<ul>
<li><code>options.ttl</code> can be passed in milliseconds if the driver supports it</li>
<li><code>options.mapName</code> defines a map where the counter will be stored if the cache supports maps, to store the whole map in one
 operation the <code>key</code> must be set to * and the <code>val</code> must be an object</li>
<li><code>options.setmax</code> if not empty tell the driver to set this new number only if there is no existing
value or it is less that the new number, only works for numeric values</li>
<li><code>options.listName</code> defines a list where to add items, <code>val</code> can be a value or an array of values, <code>key</code> is ignored in this case</li>
</ul>
<p>Example:</p>
<pre><code>  ipc.put(&quot;my:key&quot;, 2)
  ipc.put(&quot;my:key&quot;, 1, { setmax: 1 })
  ipc.put(&quot;key1&quot;, 1, { mapName: &quot;my:map&quot; })
  ipc.put(&quot;*&quot;, { key1: 1, key2: 2 }, { mapName: &quot;my:map&quot; })
  ipc.put(&quot;&quot;, [1,2,3], { listName: &quot;my:list&quot; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.incr(key, val, options, callback)</code></p>
<p>  Increase/decrease a counter in the cache by <code>val</code>, non existent items are treated as 0, if a callback is given an
error and the new value will be returned.</p>
<ul>
<li><code>options.ttl</code> in milliseconds can be used if the driver supports it</li>
<li><code>options.mapName</code> defines a map where the counter will be stored if the cache supports maps</li>
<li>if <code>val</code> is an object then the key is treated as a map and all numeric properties will be incremented, other properties just set,
this is the same as to set key to &#39;*&#39; and define mapName in the options</li>
</ul>
<p>Example:</p>
<pre><code>   ipc.incr(&quot;my:key&quot;, 1)
   ipc.incr(&quot;count&quot;, 1, { mapName: &quot;my:map&quot; })
   ipc.incr(&quot;my:map&quot;, { count: 1, name: &quot;aaa&quot;, mtime: Date.now().toString() })
   ipc.incr(&quot;*&quot;, { count: 1, name: &quot;bbb&quot;, mtime: Date.now().toString() }, { mapName: &quot;my:map&quot; })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.subscribe(channel, options, callback)</code></p>
<p>  Subscribe to receive messages from the given channel, the callback will be called only on new message received.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
</ul>
<p> Example:</p>
<pre><code>     ipc.subscribe(&quot;alerts&quot;, (msg) =&gt; {
         req.res.json(data);
     }, req);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.unsubscribe(channel, options, callback)</code></p>
<p>  Close a subscription for the given channel, no more messages will be delivered.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.publish(channel, msg, options, callback)</code></p>
<p>  Publish an event to the channel to be delivered to all subscribers. If the <code>msg</code> is not a string it will be stringified.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.broadcast(channel, msg, options, callback)</code></p>
<p>  Send a message to a channel, this is high level routine that uses the corresponding queue, it uses eventually ipc.publish.
If no client or queue is provided in the options it uses default <code>systemQueue</code>.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.sendBroadcast(msg, options)</code></p>
<p>  Send a broadcast to all server roles</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.subscribeQueue(options, callback)</code></p>
<p>  Listen for messages from the given queue, the callback will be called only on new message received.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
</ul>
<p>The callback accepts 2 arguments, a message and optional next callback, if it is provided it must be called at the end to confirm or reject the message processing.
Only errors with code&gt;=500 will result in rejection, not all drivers support the next callback if the underlying queue does not support message acknowledgement.</p>
<p>Depending on the implementation, this can work as fan-out, delivering messages to all subscribed to the same channel or
can implement job queue model where only one subscriber receives a message.
For some cases like Redis this is the same as <code>subscribe</code>.</p>
<p>For cases when the <code>next</code> callback is provided this means the queue implementation requires an acknowledgement of successful processing,
returning an error with <code>err.status &gt;= 500</code> will keep the message in the queue to be processed later. Special code <code>600</code> means to keep the job
in the queue and report as warning in the log.</p>
<p> Example:</p>
<pre><code>     ipc.listen({ queueName: &quot;jobs&quot; }, (msg, next) =&gt; {
         req.res.json(data);
         if (next) next();
     }, req);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.unsubscribeQueue(options, callback)</code></p>
<p>  Stop listening for message, if no callback is provided all listeners for the key will be unsubscribed, otherwise only the specified listener.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
</ul>
<p>The callback will not be called.</p>
<p>It keeps a count how many subscribe/unsubscribe calls been made and stops any internal listeners once nobody is
subscribed. This is specific to a queue which relies on polling.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.publishQueue(msg, options, callback)</code></p>
<p>  Submit a message to the queue, if the <code>msg</code> is not a string it will be stringified.</p>
<ul>
<li><code>options.queueName</code> defines the queue, if not specified then it is sent to the default queue</li>
<li><code>options.stime</code> defines when the message should be processed, it will be held in the queue until the time comes</li>
<li><code>options.etime</code> defines when the message expires, i.e. will be dropped if not executed before this time.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.monitorQueue(options)</code></p>
<p>  Queue specific monitor services that must be run in the master process, this is intended to perform
queue cleanup or dealing with stuck messages (Redis)</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.unpublishQueue(msg, options, callback)</code></p>
<p>  Queue specific message deletion from the queue in case of abnormal shutdown or job running too long in order not to re-run it after the restart, this
is for queues which require manual message deletion ofter execution(SQS). Each queue client must maintain the mapping or other means to identify messages,
the options is the message passed to the listener</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.limiter(options, callback)</code></p>
<p>  Check for rate limit using the default or specific queue, by default TokenBucket using local LRU cache is
used unless a queue client provides its own implementation.</p>
<p>The options must have the following properties:</p>
<ul>
<li>name - unique id, can be IP address, account id, etc...</li>
<li>max - the maximum burst capacity</li>
<li>rate - the rate to refill tokens</li>
<li>interval - interval for the bucket refills, default 1000 ms</li>
<li>ttl - auto expire after specified ms since last use</li>
<li>reset - if true reset the token bucket if not consumed or the total reached this value if it is a number greater than 1</li>
<li>multiplier - multiply the interval after it consumed all tokens, subsequent checks use the increased interval, fractions supported,
if the multiplier is positive then the interval will keep increasing indefinitely, if it is negative the interval will reset to the default
value on first successful consumption</li>
</ul>
<p>The callback takes 2 arguments:</p>
<ul>
<li><code>delay</code> is a number of milliseconds till the bucket can be used again if not consumed, i.e. 0 means consumed.</li>
<li><code>info</code> is an object with info about the state of the token bucket after the operation with properties: delay, count, total, elapsed</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.checkLimiter(options, callback)</code></p>
<p>  Keep checking the limiter until it is clear to proceed with the operation, if there is no available tokens in the bucket
it will wait and try again until the bucket is filled.
To support the same interface and ability to abort the loop pass <code>options.retry</code> with a number of loops to run before exiting.</p>
<p>The callback will receive the same arguments as <code>ipc.limiter``.  </code>options.retries`` will be set to how many times it tried.</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.localLimiter(msg)</code></p>
<p>  Uses msg.name as a key returns the same message with consumed set to 1 or 0</p>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.lock(name, options, callback)</code></p>
<p>  Implementation of a lock with optional ttl, only one instance can lock it, can be for some period of time and will expire after timeout.
A lock must be uniquely named and the ttl period is specified by <code>options.ttl</code> in milliseconds.</p>
<p>This is intended to be used for background job processing or something similar when
only one instance is needed to run. At the end of the processing <code>ipc.unlock</code> must be called to enable another instance immediately,
otherwise it will be available after the ttl only.</p>
<p>if <code>options.timeout</code> is given the function will keep trying to lock for the <code>timeout</code> milliseconds.</p>
<p>if <code>options.set</code> is given it will unconditionally set the lock for the specified ttl, this is for cases when
the lock must be active for longer because of the long running task</p>
<p>The callback must be passed which will take an error and a boolean value, if true is returned it means the timer has been locked by the caller,
otherwise it is already locked by other instance. In case of an error the lock is not supposed to be locked by the caller.</p>
<p>Example:</p>
<pre><code>     ipc.lock(&quot;my-lock&quot;, { ttl: 60000, timeout: 30000 }, function(err, locked) {
          if (locked) {
              ...
              ipc.unlock(&quot;my-lock&quot;);
          }
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>Ipc.prototype.unlock(name, options, callback)</code></p>
<p>  Unconditionally unlock the lock, any client can unlock any lock.</p>
</li>
</ul>

<p>  Queue client using RabbitMQ server</p>
<p>  To enable install the npm module:</p>
<pre><code>   npm i -g amqplib
</code></pre>


<ul>
<li><p><code>IpcClient.prototype.close()</code></p>
<p>  Close current connection, ports.... not valid after this call</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.applyOptions(options)</code></p>
<p>  Prepare options to be used safely, parse the reserved params from the url</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.applyReservedOptions(options)</code></p>
<p>  Handle reserved options</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.channel(options)</code></p>
<p>  Return a subscription channel from the given name or options, the same client can support multiple subscriptions, additional
subscriptions are specified by appending <code>#channel</code> to the <code>options.queueName</code>, default is to use the primary queue name.
Consumer name if present is stripped off.</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.consumer(options)</code></p>
<p>  Returns the consumer name for the given queue or empty if not specified, <code>groupName</code> will be used as the consumer name if present</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.canonical(options)</code></p>
<p>  Return canonical queue name, default channel is not appended, default consumer is not appened</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.stats(options, callback)</code></p>
<p>  CACHE MANAGEMENT
Returns the cache statistics to the callback as the forst argument, the object tructure is specific to each cache implementstion</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.clear(pattern, callback)</code></p>
<p>  Clear all or only matched keys from the cache</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.get(key, options, callback)</code></p>
<p>  Returns an item from the cache by a key, callback is required and it acceptes only the item,
on any error null or undefined will be returned</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.put(key, val, options, callback)</code></p>
<p>  Store an item in the cache, <code>options.ttl</code> can be used to specify TTL in milliseconds</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.incr(key, val, options, callback)</code></p>
<p>  Add/substract a number from the an item, returns new number in the callback if provided, in case of an error null/indefined should be returned</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.del(key, options, callback)</code></p>
<p>  Delete an item from the cache</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.subscribe(channel, options, callback)</code></p>
<p>  EVENT MANAGEMENT
Subscribe to receive notification from the given channel</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.unsubscribe(channel, options, callback)</code></p>
<p>  Stop receiving notifications on the given channel</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.publish(channel, msg, options, callback)</code></p>
<p>  Publish an event</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.subscribeQueue(options, callback)</code></p>
<p>  QUEUE MANAGEMENT
Listen for incoming messages</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.unsubscribeQueue(options, callback)</code></p>
<p>  Stop receiving messages</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.publishQueue(msg, options, callback)</code></p>
<p>  Submit a job to a queue</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.unpublishQueue(options, callback)</code></p>
<p>  Drop a job in case of abnormal shutdown or exceeded run time</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.pollQueue(options)</code></p>
<p>  This method must take care how to keep the poller running via interval or timeout as long as the <code>this._pollingQueue=1</code>.</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.schedulePollQueue(options, timeout)</code></p>
<p>  Schedule next poller iteration immediately or after timeout, check configured polling rate, make sure it polls no more than
configured number of times per second. If not ready then keep polling until the ready signal is sent.
Two events can be used for back pressure support: <code>pause</code> and <code>unpause</code> to stop/restart queue processing</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.monitorQueue()</code></p>
<p>  Queue monitor or cleanup service, when poller is involved this will be started and can be used for cleaning up stale messages or other
maintainence work the requires.</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.lock(name, options, callback)</code></p>
<p>  LOCKING MANAGEMENT
By default return an error</p>
</li>
</ul>

<ul>
<li><p><code>IpcClient.prototype.limiter(options, callback)</code></p>
<p>  RATE CONTROL
Rate limit check, by default it uses the master LRU cache meaning it works within one physical machine only.</p>
<p>The options must have the following properties:</p>
<ul>
<li>name - unique id, can be IP address, account id, etc...</li>
<li>rate, max, interval - same as for <code>metrics.TokenBucket</code> rate limiter.</li>
</ul>
<p>The callback arguments must be:</p>
<ul>
<li>1st arg is a delay to wait till the bucket is ready again,</li>
<li>2nd arg is an object with the bucket state: { delay:, count:, total:, elapsed: }</li>
</ul>
</li>
</ul>


<h3 id="module-nats">Module: nats</h3>
<p>  Queue client using NATS server</p>
<p>  To enable install the npm modules:</p>
<pre><code>   npm i -g nats
</code></pre>
<p>  Configuration:</p>
<pre><code> ipc-queue-nats=nats://localhost:4222
</code></pre>

<p>  Cache/queue client based on Redis server using <a href="https://github.com/NodeRedis/node_redis">https://github.com/NodeRedis/node_redis</a></p>
<p>  The queue client implements reliable queue using sorted sets, one for the new messages and one for the
  messages that are being processed if timeout is provided. With the timeout this queue works similar to AWS SQS.</p>
<p>  The <code>interval</code> config property defines in ms how often to check for new messages after processing a message, i.e. after a messages processed
  it can poll immediately or after this amount of time</p>
<p>  The <code>retryInterval</code> config property defines in ms how often to check for new messages after an error or no data, i.e. on empty
  pool when no messages are processed it can poll immediately or after this amount of time</p>
<p>  The <code>visibilityTimeout</code> property specifies to use a shadow queue where all messages that are being processed are stored,
  while the message is processed the timestamp will be updated so the message stays in the queue, if a worker exists or crashes without
  confirming the message finished it will be put back into the work queue after <code>visibilityTimeout</code> milliseconds. The queue name that
  keeps active messages is appended with #.</p>
<p>  The <code>threshold</code> property defines the upper limit of how many active messages can be in the queue when to show an error message, this is
  for monitoring queue performance</p>
<p>  The rate limiter implementes Tocken Bucket algorithm using Lua script inside Redis, the only requirement is that
  all workers to use NTP for time synchronization</p>
<p>  Examples:</p>
<pre><code>   ipc-client=redis://host1
   ipc-client-options-interval=1000
   ipc-client=redis://host1?bk-visibilityTimeout=30000&amp;bk-count=2
</code></pre>

<p>  Queue client using AWS SQS, full queue url can be used or just the name as sqs://queuename</p>
<p>  The <code>count</code> config property specifies how messages to process at the same time, default is 1.</p>
<p>  The <code>interval</code> config property defines in ms how often to check for new messages after processing a message, i.e. after a messages processed
  it can poll immediately or after this amount of time, default is 1000 milliseconds.</p>
<p>  The <code>retryInterval</code> config property defines in ms how often to check for new messages after an error or no data, i.e. on empty
  pool when no messages are processed it can poll immediately or after this amount of time, default is 5000 mulliseconds.</p>
<p>  The <code>visibilityTimeout</code> property specifies how long the messages being processed stay hidden, in milliseconds.</p>
<p>  The <code>timeout</code> property defines how long to wait for new messages, i.e. the long poll, in milliseconds</p>
<p>  The <code>retryCount</code> and <code>retryTimeout</code> define how many times to retry failed AWS HTTP requests, default is 5 times starting
   with the backoff starting at 500 milliseconds.</p>
<p>  For messages that have <code>startTime</code> property which is the time in the future when a message must be actually processed there
  is a parameter <code>maxTimeout</code> which defines in milliseconds the max time a messsage can stay invisible while waiting for its scheduled date,
  default is 6 hours, the AWS max is 12 hours. The scheduling is implemented using AWS <code>visibilityTimeout</code> feature, keep
  scheduled messages hidden until the actual time.</p>
<p>  Examples:</p>
<pre><code>   ipc-queue=sqs://messages?bk-interval=60000
   ipc-queue=https://sqs.us-east-1.amazonaws.com/123456/messages?bk-visibilityTimeout=300&amp;bk-count=2
</code></pre>

<h2 id="module-jobs">Module: jobs</h2>
<p>  Job queue processor</p>
<p>  When launched with <code>jobs-workers</code> parameter equal or greater than 0, the master spawns a number of workers which subscribe to
  configured job queues or the default queue and listen for messsges.
  A job message is an object that defines what method from which module to run with the options as the first argument and a callback as the second.</p>
<p>  Multiple job queues can be defined and processed at the same time.</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>jobs-workers</code>, type: &quot;number&quot;, min: -1, max: 32, descr: &quot;How many worker processes to launch to process the job queue, -1 disables jobs, 0 means launch as many as the CPUs available&quot;</li>
<li><code>jobs-worker-cpu-factor</code>, type: &quot;real&quot;, min: 0, descr: &quot;A number to multiply the number of CPUs available to make the total number of workers to launch, only used if <code>workers</code> is 0&quot;</li>
<li><code>jobs-worker-args</code>, type: &quot;list&quot;, descr: &quot;Node arguments for workers, for passing v8 jobspec, see <code>process</code>&quot;</li>
<li><code>jobs-worker-env</code>, type: &quot;json&quot;, logger: &quot;warn&quot;, descr: &quot;Environment to be passed to the worker via fork, see <code>cluster.fork</code>&quot;</li>
<li><code>jobs-worker-delay</code>, type: &quot;int&quot;, descr: &quot;Delay in milliseconds for a worker before it will start accepting jobs, for cases when other dependencies may take some time to start&quot;</li>
<li><code>jobs-max-runtime</code>, type: &quot;int&quot;, min: 0, descr: &quot;Max number of seconds a job can run before being killed&quot;</li>
<li><code>jobs-max-lifetime</code>, type: &quot;int&quot;, min: 0, descr: &quot;Max number of seconds a worker can live, after that amount of time it will exit once all the jobs are finished, 0 means indefinitely&quot;</li>
<li><code>jobs-shutdown-timeout</code>, type: &quot;int&quot;, min: 500, descr: &quot;Max number of milliseconds to wait for the graceful shutdown sequence to finish, after this timeout the process just exits&quot;</li>
<li><code>jobs-worker-queue</code>, type: &quot;list&quot;, onupdate: function() { if (ipc.role==&quot;worker&quot;&amp;&amp;core.role==&quot;worker&quot;) this.subscribeWorker() descr: &quot;Queue(s) to subscribe for workers, multiple queues can be processes at the same time, i.e. more than one job can run from different queues&quot;</li>
<li><code>jobs-worker-options-(.+)</code>, obj: &quot;workerOptions&quot;, make: &quot;$1&quot;, type: &quot;json&quot;, descr: &quot;Custom parameters by queue name, passed to <code>ipc.subscribeQueue</code> on worker start, useful with channels, ex: <code>-jobs-worker-options-nats#events {\&quot;count\&quot;:10}</code>&quot;</li>
<li><code>jobs-cron-queue</code>, type: &quot;list&quot;, min: 1, descr: &quot;Default queue to use for cron jobs&quot;</li>
<li><code>jobs-global-queue</code>, type: &quot;list&quot;, min: 1, descr: &quot;Default queue for all jobs, the queueName is ignored&quot;</li>
<li><code>jobs-global-ignore</code>, type: &quot;list&quot;, descr: &quot;Queue names which ignore the global setting, the queueName is used as usual&quot;</li>
<li><code>jobs-cron</code>, type: &quot;bool&quot;, descr: &quot;Allow cron jobs to be executed from the local etc/crontab file or via config parameter&quot;</li>
<li><code>jobs-schedule</code>, type: &quot;json&quot;, onupdate: function() { if (core.role == &quot;master&quot; &amp;&amp; this.cron) this.scheduleCronjobs(&quot;config&quot;, this.schedule)  logger: &quot;error&quot;, descr: &quot;Cron jobs to be scheduled, the JSON must be in the same format as crontab file&quot;</li>
<li><code>jobs-unique-queue</code>, descr: &quot;Default queue name to use for keeping track of unique jobs&quot;</li>
<li><code>jobs-unique-ignore</code>, type: &quot;regexp&quot;, descr: &quot;Ignore all unique parameters if a job&#39;s uniqueKey matches&quot;</li>
<li><code>jobs-unique-set-ttl-([0-9]+)</code>, type: &quot;regexp&quot;, obj: &quot;uniqueSetTtl&quot;, make: &quot;$1&quot;, descr: &quot;Override unique TTL to a new value if matches the unique key, ex: -jobs-unique-ttl-100 KEY&quot;</li>
<li><code>jobs-unique-logger</code>, descr: &quot;Log level for unique error conditions&quot;</li>
<li><code>jobs-retry-visibility-timeout</code>, type: &quot;map&quot;, maptype: &quot;int&quot;, descr: &quot;Visibility timeout by error code &gt;= 500 for queues that support it&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>jobs.configureMaster(options, callback)</code></p>
<p>  Initialize jobs processing in the master process</p>
</li>
</ul>

<ul>
<li><p><code>jobs.configureWorker(options, callback)</code></p>
<p>  Initialize a worker to be ready for jobs to execute, in instance mode setup timers to exit on no activity.</p>
</li>
</ul>

<ul>
<li><p><code>jobs.shutdownWorker(options, callback)</code></p>
<p>  Perform graceful worker shutdown, to be used for workers restart</p>
</li>
</ul>

<ul>
<li><p><code>jobs.exitWorker(options)</code></p>
<p>  Perform graceful worker shutdown and then exit the process</p>
</li>
</ul>

<ul>
<li><p><code>jobs.initServer(options, callback)</code></p>
<p>  Initialize a master that will manage jobs workers</p>
</li>
</ul>

<ul>
<li><p><code>jobs.initWorker(options, callback)</code></p>
<p>  Initialize a worker for processing jobs</p>
</li>
</ul>

<ul>
<li><p><code>jobs.isCancelled(job, tag, value)</code></p>
<p>  Returns true if a task with given name must be cancelled, this flag is set from the jobs master and
stoppable tasks must check it from time to time to terminate gracefully.
if <code>value</code> is given it will return true only if it exactly equals to the set value in the task cancel state.
The cancel state is cleared only if tag is given, if only name is matched the cancel state remains for other tasks</p>
</li>
</ul>

<ul>
<li><p><code>jobs.cancelTask(name, options)</code></p>
<p>  Send cancellation request to a worker or all workers, this has to be called from the jobs master.
<code>options.workers</code> can be a single worker id or a list of worker ids, if not given the request will be sent to all workers for the current process cluster.
<code>options.tag</code> is an opaque data that will be used to verifying which task should be cancelled, without it all tasks with given name will be cancelled.</p>
</li>
</ul>

<ul>
<li><p><code>jobs.getMaxRuntime()</code></p>
<p>  Find the max runtime allowed in seconds</p>
</li>
</ul>

<ul>
<li><p><code>jobs.checkTimes()</code></p>
<p>  Check how long we run a job and force kill if exceeded, check if total life time is exceeded.</p>
<p>If exit is required the <code>shundownWorker</code> methods will receive options with <code>shutdownReason</code> property
set and the name-sake property will contained the value exceeded.</p>
</li>
</ul>

<ul>
<li><p><code>jobs._badJob(jobspec)</code></p>
<p>  Make sure the job is valid and has all required fields, returns a normalized job object or an error, the jobspec
must be in the following formats:</p>
<pre><code>   &quot;module.method&quot;
   { job: &quot;module.method&quot; }
   { job: { &quot;module.method&quot;: {}, .... } }
   { job: [ &quot;module.method&quot;, { &quot;module.method&quot;: {} ... } ...] }
</code></pre>
<p>any task in string format &quot;module.method&quot; will be converted into { &quot;module.method: {} } automatically</p>
</li>
</ul>

<ul>
<li><p><code>jobs.checkOptions(jobspec, options)</code></p>
<p>  Apply special job properties from the options</p>
</li>
</ul>

<ul>
<li><p><code>jobs.submitJob(jobspec, options, callback)</code></p>
<p>  Submit a job for execution, it will be saved in a queue and will be picked up later and executed.
The queue and the way how it will be executed depends on the configured queue. See <code>isJob</code> for
the format of the job objects.</p>
<p><code>jobspec.uniqueTtl</code> if greater than zero it defines number of milliseconds for this job to stay in the queue or run,
it creates a global lock using the job object as the hash key, no other job can be run until the ttl expires or the job
finished, non unique jobs will be kept in the queue and repeated later according to the <code>visibilityTimeout</code> setting.</p>
<p><code>jobspec.uniqueKey</code> can define an alternative unique key for this job for cases when different jobs must be run sequentially</p>
<p><code>jobspec.uniqueKeep</code> if true then keep the unique lock after the jobs finished, otherwise it is cleared</p>
<p><code>jobspec.uniqueDrop</code> if true will make non-unique jobs to be silently dropped instead of keeping them in the queue</p>
<p><code>jobspec.logger</code> defines the logger level which will be used to log when the job is finished, default is debug</p>
<p><code>jobspec.maxRuntime</code> defines max number of seconds this job can run, if not specified then the queue default is used</p>
<p><code>jobspec.uniqueTag</code> defines additional tag to be used for job cancelling, for cases when multiple jobs are running with the same method</p>
<p><code>jobspec.uniqueOnce</code> if true than the visibility timeout is not kept alive while the job is running</p>
<p><code>jobspec.noWait</code> will run the job and delete it from the queue immediately, not at the end, for one-off jobs</p>
<p><code>jobspec.noWaitTimeout</code> number of seconds before deleting the job for one-off jobs but taking into account the uniqueKey and visibility timeout giving time
 to check for uniqueness and exit, can be used regardless of the noWait flag</p>
<p><code>jobspec.noVisibility</code> will always delete messages after processing, ignore 600 errors as well</p>
<p><code>jobspec.visibilityTimeout</code> custom timeout for how long to keep this job invisible, overrides the default timeout</p>
<p><code>jobspec.retryVisibilityTimeout</code> an object with custom timeouts for how long to keep this job invisible by error status which results in keeping tasks in the queue for retry</p>
<p><code>jobspec.stopOnError</code> will stop tasks processing on first error, otherwise all errors will be just logged. Errors with status &gt;= 600 will
 stop the job regardless of this flag</p>
<p><code>jobspec.startTime</code> and/or <code>jobspec.endTime</code> will define the time period during whihc this job is allowed to run, if
 outside the period it will be dropped</p>
<p><code>options.delay</code> is only supported by SQS currently, it delays the job execution for the specified amount of ms</p>
<p><code>options.dedup_ttl</code> - if set it defines number of ms to keep track of duplicate messages, it tries to preserver only-once behaviour. To make
 some queue to automatically use dedup mode it can be set in the queue options: <code>-ipc-queue[-NAME]-options-dedup_ttl 86400000</code>.
 Note: <code>uniqueTtl</code> settings take precedence and if present dedup is ignored.</p>
<p>Special queue name: <code>jobs.selfQueue</code> is reserved to run the job immediately inside the current process,
it will call the <code>runJob</code> directly, this is useful in cases when already inside a worker and instead of submitting a new job
just run it directly. Any queue can be configured to run in <code>selfQueue</code> by setting <code>-ipc-queue[-NAME]-options-self-queue 1</code>.</p>
</li>
</ul>

<ul>
<li><p><code>jobs.runJob(jobspec, options, callback)</code></p>
<p>  Run all tasks in the job object</p>
</li>
</ul>

<ul>
<li><p><code>jobs.cancelJob(options, callback)</code></p>
<p>  Send a cancellation request to the given <code>job</code> with optional <code>tag</code> and <code>value</code>. The value must mtach exactly.</p>
</li>
</ul>

<ul>
<li><p><code>jobs._runJob(jobspec, options, callback)</code></p>
<p>  Sequentially execute all tasks in the list, run all subtasks in parallel</p>
</li>
</ul>

<ul>
<li><p><code>jobs.runTask(name, jobspec, options, callback)</code></p>
<p>  Execute a task by name, the <code>options</code> will be passed to the function as the first argument, calls the callback on finish or error</p>
</li>
</ul>

<ul>
<li><p><code>jobs._finishTask(err, name, jobspec, options, callback)</code></p>
<p>  Complete task execution, cleanup and update the status</p>
</li>
</ul>

<ul>
<li><p><code>jobs.scheduleCronjob(jobspec)</code></p>
<p>  Create a new cron job, for remote jobs additional property args can be used in the object to define
arguments for the instance backend process, properties must start with -</p>
<p>Example:</p>
<pre><code>     { &quot;cron&quot;: &quot;0 */10 * * * *&quot;, &quot;job&quot;: &quot;server.processQueue&quot; },
     { &quot;cron&quot;: &quot;0 */30 * * * *&quot;, &quot;job&quot;: { &quot;server.processQueue&quot;: { name: &quot;queue1&quot; } } },
     { &quot;cron&quot;: &quot;0 5 * * * *&quot;, &quot;job&quot;: [ { &quot;scraper.run&quot;: { &quot;url&quot;: &quot;host1&quot; } }, { &quot;scraper.run&quot;: { &quot;url&quot;: &quot;host2&quot; } } ] }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>jobs.scheduleCronjobs(type, list)</code></p>
<p>  Schedule a list of cron jobs, types is used to cleanup previous jobs for the same type for cases when
a new list needs to replace the existing jobs. Empty list does nothing, to reset the jobs for the particular type and
empty invalid jobs must be passed, like: <code>[ {} ]</code></p>
<p>Returns number of cron jobs actually scheduled.</p>
</li>
</ul>

<ul>
<li><p><code>jobs.loadCronjobs()</code></p>
<p>  Load crontab from JSON file as list of job specs:</p>
<ul>
<li>cron - cron time interval spec: &#39;second&#39; &#39;minute&#39; &#39;hour&#39; &#39;dayOfMonth&#39; &#39;month&#39; &#39;dayOfWeek&#39;</li>
<li>job - a string as obj.method or an object with job name as property name and the value is an object with
 additional jobspec for the job passed as first argument, a job callback always takes jobspec and callback as 2 arguments</li>
<li>disabled - disable the job but keep in the cron file, it will be ignored</li>
<li>queueName - name of the queue where to submit this job, if not given it uses cron-queue</li>
<li>uniqueTtl - defines that this job must be the only one in the queue for the number of milliseconds specified, after that
 time another job with the same arguments can be submitted.</li>
</ul>
<p>Example:</p>
<pre><code>     [ { cron: &quot;0 0 * * * *&quot;, job: &quot;scraper.run&quot; }, ..]
</code></pre>
</li>
</ul>

<ul>
<li><p><code>jobs.parseCronjobs(type, data)</code></p>
<p>  Parse a JSON data with cron jobs and schedule for the given type, this can be used to handle configuration properties</p>
</li>
</ul>

<h2 id="module-lib">Module: lib</h2>
<p>  Common utilities and useful functions</p>

<ul>
<li><p><code>lib.tryCall(callback, ...args)</code></p>
<p>  Run a callback if a valid function, all arguments after the callback will be passed as is</p>
</li>
</ul>

<ul>
<li><p><code>lib.tryCatch(callback, ...args)</code></p>
<p>  Run a callback inside try..catch block, all arguments after the callback will be passed as is, in case of error
all arguments will be printed in the log</p>
</li>
</ul>

<ul>
<li><p><code>lib.log()</code></p>
<p>  Print all arguments into the console, for debugging purposes, if the first arg is an error only print the error</p>
</li>
</ul>

<ul>
<li><p><code>lib.__()</code></p>
<p>  Simple i18n translation method compatible with other popular modules, supports the following usage:</p>
<ul>
<li>__(name)</li>
<li>__(fmt, arg,...)</li>
<li>__({ phrase: &quot;&quot;, locale: &quot;&quot; }, arg...</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.getArg(name, dflt)</code></p>
<p>  Return commandline argument value by name</p>
</li>
</ul>

<ul>
<li><p><code>lib.getArgInt(name, dflt)</code></p>
<p>  Return commandline argument value as a number</p>
</li>
</ul>

<ul>
<li><p><code>lib.isArg(name)</code></p>
<p>  Returns true of given arg(s) are present in the command line, name can be a string or an array of strings.</p>
</li>
</ul>

<ul>
<li><p><code>lib.deferCallback(parent, msg, callback, timeout)</code></p>
<p>  Register the callback to be run later for the given message, the message may have the <code>__id</code> property which will be used for keeping track of the responses or it will be generated.
The <code>parent</code> can be any object and is used to register the timer and keep reference to it.</p>
<p>A timeout is created for this message, if <code>runCallback</code> for this message will not be called in time the timeout handler will call the callback
anyway with the original message.</p>
<p>The callback passed will be called with only one argument which is the message, what is inside the message this function does not care. If
any errors must be passed, use the message object for it, no other arguments are expected.</p>
</li>
</ul>

<ul>
<li><p><code>lib.onDeferCallback(msg)</code></p>
<p>  To be called on timeout or when explicitely called by the <code>runCallback</code>, it is called in the context of the message.</p>
</li>
</ul>

<ul>
<li><p><code>lib.runCallback(parent, msg)</code></p>
<p>  Run delayed callback for the message previously registered with the <code>deferCallback</code> method.
The message must have <code>id</code> property which is used to find the corresponding callback, if the msg is a JSON string it will be converted into the object.</p>
<p>Same parent object must be used for <code>deferCallback</code> and this method.</p>
</li>
</ul>

<ul>
<li><p><code>lib.deferInterval(parent, interval, name, callback)</code></p>
<p>  Assign or clear an interval timer, keep the reference in the given parent object</p>
</li>
</ul>

<ul>
<li><p><code>lib.sortByVersion(list, name)</code></p>
<p>  Sort a list be version in descending order, an item can be a string or an object with
a property to sort by, in such case <code>name</code> must be specified which property to use for sorting.
The name format is assumed to be: <code>XXXXX-N.N.N</code></p>
</li>
</ul>

<ul>
<li><p><code>lib.newError(msg, status, code)</code></p>
<p>  Return a new Error object, msg can be a string or an object with message, code, status properties.
The default error status is 400 if not specified.</p>
</li>
</ul>

<ul>
<li><p><code>lib.traceError(err)</code></p>
<p>  Returns the error stack or the error itself, to be used in error messages</p>
</li>
</ul>

<ul>
<li><p><code>lib.loadLocale(file, callback)</code></p>
<p>  Load a file with locale translations into memory</p>
</li>
</ul>

<ul>
<li><p><code>lib.shuffle(list)</code></p>
<p>  Randomize the list items in place</p>
</li>
</ul>

<ul>
<li><p><code>lib.toVersion(str)</code></p>
<p>  Returns a floating number from the version string, it assumes common semver format as major.minor.patch, all non-digits will
be removed, underscores will be treated as dots. Returns a floating number which can be used in comparing versions.</p>
<p>Example
 &gt; lib.toVersion(&quot;1.0.3&quot;)
 1.000003
 &gt; lib.toVersion(&quot;1.0.3.4&quot;)
 1.000003004
 &gt; lib.toVersion(&quot;1.0.3.4&quot;) &gt; lib.toVersion(&quot;1.0.3&quot;)
 true
 &gt; lib.toVersion(&quot;1.0.3.4&quot;) &gt; lib.toVersion(&quot;1.0.0&quot;)
 true
 &gt; lib.toVersion(&quot;1.0.3.4&quot;) &gt; lib.toVersion(&quot;1.1.0&quot;)
 false</p>
</li>
</ul>

<ul>
<li><p><code>lib.toTitle(name)</code></p>
<p>  Convert text into capitalized words</p>
</li>
</ul>

<ul>
<li><p><code>lib.toCamel(name, chars)</code></p>
<p>  Convert into camelized form, optional chars can define the separators, default is -, _ and .</p>
</li>
</ul>

<ul>
<li><p><code>lib.toUncamel(str, sep)</code></p>
<p>  Convert Camel names into names separated by the given separator or dash if not.</p>
</li>
</ul>

<ul>
<li><p><code>lib.toNumber(val, options, float)</code></p>
<p>  Safe version, uses 0 instead of NaN, handle booleans, if float specified, returns as float.</p>
<p>Options:</p>
<ul>
<li>dflt - default value</li>
<li>float - treat as floating number</li>
<li>min - minimal value, clip</li>
<li>max - maximum value, clip</li>
<li>incr - a number to add before checking for other conditions</li>
<li>mult - a number to multiply before checking for other conditions</li>
<li>novalue - replace this number with default</li>
<li>zero - replace with this number if result is 0</li>
</ul>
<p>Example:</p>
<pre><code>          lib.toNumber(&quot;123&quot;)
          lib.toNumber(&quot;1.23&quot;, { float: 1, dflt: 0, min: 0, max: 2 })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.toDigits(str)</code></p>
<p>  Strip all non-digit characters from a string</p>
</li>
</ul>

<ul>
<li><p><code>lib.toClamp(num, min, max)</code></p>
<p>  Return a number clamped between the range</p>
</li>
</ul>

<ul>
<li><p><code>lib.toBool(val, dflt)</code></p>
<p>  Return true if value represents true condition, i.e. non empty value</p>
</li>
</ul>

<ul>
<li><p><code>lib.toDate(val, dflt, invalid)</code></p>
<p>  Return Date object for given text or numeric date representation, for invalid date returns 1969 unless <code>invalid</code> parameter is given,
in this case invalid date returned as null. If <code>dflt</code> is NaN, null or 0 returns null as well.</p>
</li>
</ul>

<ul>
<li><p><code>lib.toMtime(val, dflt)</code></p>
<p>  Return milliseconds from the date or date string, only number as dflt is supported, for invalid dates returns 0</p>
</li>
</ul>

<ul>
<li><p><code>lib.toBase62(num, alphabet)</code></p>
<p>  Return base62 representation for a number</p>
</li>
</ul>

<ul>
<li><p><code>lib.toUrl(val, options)</code></p>
<p>  Return a well formatted and validated url or empty string</p>
</li>
</ul>

<ul>
<li><p><code>lib.toPrice(num, options)</code></p>
<p>  Return a test representation of a number according to the money formatting rules, default is en-US, options may include:
currency(USD), display(symbol), sign(standard), min(2), max(3)</p>
</li>
</ul>

<ul>
<li><p><code>lib.toEmail(val, options)</code></p>
<p>  Return an email address if valid, <code>options.parse</code> makes it extract the email from <code>name &lt;email&gt;</code> format</p>
</li>
</ul>

<ul>
<li><p><code>lib.toValue(val, type, options)</code></p>
<p>  Convert a value to the proper type, default is to return a string or convert the value to a string if no type is specified,
special case if the type is &quot;&quot; or null return the value as is without any conversion</p>
</li>
</ul>

<ul>
<li><p><code>lib.toString(str, options)</code></p>
<p>  Return the value as a string</p>
</li>
</ul>

<ul>
<li><p><code>RegExp.prototype.toJSON()</code></p>
<p>  Serialize regexp with a custom format, `lib.toRegxp`` will be able to use it</p>
</li>
</ul>

<ul>
<li><p><code>lib.toRegexp(str, options)</code></p>
<p>  Safely create a regexp object, if invalid returns undefined, the options can be a string with srandard RegExp
flags or an object with the following properties:</p>
<ul>
<li>ingoreCase - similar to i</li>
<li>globalMatch - similar to m</li>
<li>multiLine - similar to m</li>
<li>unicode - similar to u</li>
<li>sticky - similar to y</li>
<li>escape - escape all special symbols or symbol e</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.toRegexpMap(obj, val, options)</code></p>
<p>  Add a regexp to the list of regexp objects, this is used in the config type <code>regexpmap</code>.</p>
</li>
</ul>

<ul>
<li><p><code>lib.toRegexpObj(obj, val, options)</code></p>
<p>  Add a regexp to the object that consist of list of patterns and compiled regexp, this is used in the config type <code>regexpobj</code></p>
</li>
</ul>

<ul>
<li><p><code>lib.toDuration(mtime, options)</code></p>
<p>  Return duration in human format, mtime is msecs</p>
</li>
</ul>

<ul>
<li><p><code>lib.toAge(mtime, options)</code></p>
<p>  Given time in msecs, return how long ago it happened</p>
</li>
</ul>

<ul>
<li><p><code>lib.toSize(size, decimals)</code></p>
<p>  Return size human readable format</p>
</li>
</ul>

<ul>
<li><p><code>lib.toParams(query, schema, options)</code></p>
<p>  Process incoming query and convert parameters according to the type definition, the schema contains the definition of the paramaters against which to
validate incoming data. It is an object with property names and definitoons that at least must specify the type, all other options are type specific.</p>
<p>Returns a string message on error or an object</p>
<p>The options can define the following global properties:</p>
<ul>
<li>null - always return null on any error</li>
<li>setnull - if the value is equal this or any value if an array then set property to null, useful to reset lists, maps...</li>
<li>existing - skip properties if not present in the query</li>
<li>prefix - prefix to be used when searching for the parameters in the query, only properties with this prefix will be processed. The resulting
 object will not have this prefix in the properties.</li>
<li>dprefix - prefix to use when checking for defaults, defaults are checks in this order: dprefix+name, name, *.type, *</li>
<li>defaults - to pass realtime or other custom options for the validation or convertion utilities as the first argument if not defined in the definition,
 this is the place to customize/add/override global parameter conditions without changing it. Exact parameter name is used or a wildcard in the format
 <code>*.type</code> where type id any valid type supported or just <code>*</code> for all parameters.</li>
</ul>
<p>Schema parameter properties:</p>
<ul>
<li>type - convert the input to the type format</li>
<li>name - to save a value with different name than in the original query</li>
<li>dflt - use this value if property does not exists or undefined</li>
<li>dfltempty - also use the dflt value for empty properties</li>
<li>required - if true the target value must not be empty, the check is performed after type conversion,
   if an object it checks the target object using <code>lib.isMatched</code> at the end</li>
<li>errmsg - return this error on error or invalid format or required condition</li>
<li>min - minimum length for the target data, returns an error if smaller, for list type will skip item from the list</li>
<li>max -  maximum length alowed, returns an error if longer</li>
<li>trunc - if true and longer than max just truncate the value instead of returning an error or skipping</li>
<li>separator - for list type default separator is <code>,|</code>, for map type default is <code>:;</code></li>
<li>delimiter - map type contains elements separated by , by default, use another if commas are expected</li>
<li>regexp - validate input against this regexp and return an error if not matched, for list type skip items not matched</li>
<li>noregexp - validate the input against this regexp and return an error if matched, for list type skip items matched</li>
<li>datatype - convert each value or item into this type, used by string/list types</li>
<li>maptype - for maps convert each value to this type</li>
<li>novalue - if the target value equals this ignore the parameter, can be a list of values to be ignored</li>
<li>ignore - if true skip this parameter</li>
<li>optional - for date types, if true do not assign the current time for empty values</li>
<li>value - assign this value unconditionally</li>
<li>values - a list of allowed values, if not present the parameter is ignored</li>
<li>values_map - an objexct map for values, replace matching values with a new one</li>
<li>params - an object with schema to validate for json/obj/array types</li>
<li>empty - if true and the target value is empty return as empty, by default empty values are ignored</li>
<li>keepempty - for list type keep empty items in the list, default is skip empty items</li>
<li>minlist - min allowed length of the target array for list/map types, returns error if less</li>
<li>maxlist - max allowed length of the target array for list/map types, returns error if longer</li>
<li>strip - a regexp with characters to strip from the final value</li>
<li>upper/lower - transform case</li>
<li>cap - capitalize the value</li>
<li>trim - trim the final value if a string</li>
<li>replace - an object map with characters to be replaced with other values</li>
</ul>
<p>Supported types:</p>
<ul>
<li>string types: string, text,</li>
<li>boolean types: bool, boolean,</li>
<li>numeric types: int, bigint, long, number, float, real, double, counter, clock, now, random</li>
<li>object types: list, map, obj, object, array, json,</li>
<li>date/time types: mtime, date, time, timestamp, datetime</li>
<li>special types: set, email, symbol, url, phone, e164, regexp</li>
</ul>
<p>Example:</p>
<pre><code>   var query = lib.toParams(req.query, {
           id: { type: &quot;int&quot; },
           count: { type: &quot;int&quot;, min: 1, max: 10, dflt: 5 },
           name: { type: &quot;string&quot;, max: 32, trunc: 1 },
           pair: { type: &quot;map&quot;, maptype: &quot;int&quot; },
           code: { type: &quot;string&quot;, regexp: /^[a-z]-[0-9]+$/, errmsg: &quot;Valid code is required&quot; },
           start: { type: &quot;token&quot;, required: 1 },
           email: { type: &quot;list&quot;, datatype: &quot;email&quot;, novalue: [&quot;a@a&quot;] },
           email1: { type: &quot;email&quot;, required: { email: null } },
           data: { type: &quot;json&quot;, datatype: &quot;obj&quot; },
           mtime: { type: &quot;mtime&quot;, name: &quot;timestamp&quot; },
           flag: { type: &quot;bool&quot;, novalue: false },
           descr: { novalue: { name: &quot;name&quot;, value: &quot;test&quot; }, replace: { &quot;&lt;&quot;: &quot;!&quot; } },
           internal: { ignore: 1 },
           tm: { type: &quot;timestamp&quot;, optional: 1 },
           ready: { value: &quot;ready&quot; },
           state: { values: [ &quot;ok&quot;,&quot;bad&quot;,&quot;good&quot; ] },
           status: { value: [ &quot;ok&quot;,&quot;done&quot; ] },
           obj: { type: &quot;obj&quot;, params: { id: { type: &quot;int&quot; }, name: {} } },
           arr: { type: &quot;array&quot;, params: { id: { type: &quot;int&quot; }, name: {} } },
           ssn: { type: &quot;string&quot;, regexp: /^[0-9]{3}-[0-9]{3}-[0-9]{4}$/, errmsg: &quot;Valid SSN is required&quot; },
           phone: { type: &quot;list&quot;, datatype: &quot;number&quot; },
   }, {
           defaults: {
               start: { secret: req.account.secret },
               name: { dflt: &quot;test&quot; },
               count: { max: 100 },
               email: { ignore: req.account.type != &quot;admin&quot; },
               &quot;*.string&quot;: { max: 255 },
               &#39;*&#39;: { maxlist: 255 },
   })
   if (typeof query == &quot;string) return api.sendReply(res, 400, query);
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.toFormat(format, data, options)</code></p>
<p>  Convert a list of records into the specified format, supported formats are: <code>xml, csv, json, jsontext</code>.</p>
<ul>
<li>For <code>csv</code> the default separator is comma but can be specified with <code>options.separator</code>. To produce columns header specify <code>options.header</code>.</li>
<li>For <code>json</code> format puts each record as a separate JSON object on each line, so to read it back
it will require to read every line and parse it and add to the list.</li>
<li>For <code>xml</code> format the name of the row tag is <code>&lt;row&gt;</code> but can be
specified with <code>options.tag</code>.</li>
</ul>
<p>All formats support the property <code>options.allow</code> which is a list of property names that are allowed only in the output for each record, non-existent
properties will be replaced by empty strings.</p>
<p>The <code>mapping</code> object property can redefine different tag/header names to be put into the file instead of the exact column names from the records.</p>
</li>
</ul>

<ul>
<li><p><code>lib.toTemplate(text, obj, options)</code></p>
<p>  Given a template with @..@ placeholders, replace each placeholder with the value from the obj.
The <code>obj</code> can be an object or an array of objects in which case all objects will be checked for the value until non empty.</p>
<p>To use @ in the template specify it as @@</p>
<p>The options if given may provide the following:</p>
<ul>
<li>allow - placeholders with a name present in this list will be replaced, all other will be replaced with empty string</li>
<li>skip - placeholders with a name present in this list will be ignored, the placeholer will be kept</li>
<li>only - placeholders with a name present in this list will be replaced only, all other will be ignored and kept as placeholders</li>
<li>encoding - can be url or base64, the replaced values will be encoded accordingly</li>
<li>separator1 - left side of the placehoder, default is @</li>
<li>separator2 - right side of the placeholder, default is @</li>
</ul>
<p>Default placeholders:</p>
<ul>
<li>@exit@ - stop processing and return the template ignoring the rest</li>
<li>@RAND@ - produce a random number using Math.random</li>
<li>@n@ - produce a line break, newline</li>
<li>@p@ - produce 2 newlines</li>
</ul>
<p>Example:</p>
<pre><code>   lib.toTemplate(&quot;http://www.site.com/@code@/@id@&quot;, { id: 123, code: &quot;YYY&quot; }, { encoding: &quot;url&quot; })
   lib.toTemplate(&quot;Hello @name|friend@!&quot;, {})
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.toFlags(cmd, list, name)</code></p>
<p>  Flags command utility, the commands are:</p>
<ul>
<li>add - adds the <code>name</code> flags to the list if does not exists, returns the same array</li>
<li>update - adds new flags and removes flags that starts with - , returns the same array</li>
<li>concat - same as add but always returns a new list</li>
<li>del - removes the flags <code>name</code>, returns the same array</li>
<li>present - returns only flags that present in the list <code>name</code></li>
<li>absent - returns only flags that are not present in the list <code>name</code></li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.toRFC3339 (date)</code></p>
<p>  Return RFC3339 formatted timestamp for a date or current time</p>
</li>
</ul>

<ul>
<li><p><code>lib.jsonToBase64(data, secret, options)</code></p>
<p>  Stringify JSON into base64 string, if secret is given, sign the data with it</p>
</li>
</ul>

<ul>
<li><p><code>lib.base64ToJson(data, secret, options)</code></p>
<p>  Parse base64 JSON into JavaScript object, in some cases this can be just a number then it is passed as it is, if secret is given verify
that data is not chnaged and was signed with the same secret</p>
</li>
</ul>


<ul>
<li><p><code>lib.jsonFormat(obj, options)</code></p>
<p>  Nicely format an object with indentations, optional <code>indentlevel</code> can be used to control until which level deep
to use newlines for objects.</p>
</li>
</ul>

<ul>
<li><p><code>lib.stringify(obj, replacer, space)</code></p>
<p>  JSON stringify without exceptions, on error just returns an empty string and logs the error</p>
</li>
</ul>

<ul>
<li><p><code>lib.encodeURIComponent(str)</code></p>
<p>  Encode with additional symbols, convert these into percent encoded:</p>
<pre><code>     ! -&gt; %21, * -&gt; %2A, &#39; -&gt; %27, ( -&gt; %28, ) -&gt; %29
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.decodeURIComponent(str)</code></p>
<p>  No-exception version of the global function, on error returen empty string</p>
</li>
</ul>

<ul>
<li><p><code>lib.escapeUnicode(text)</code></p>
<p>  Convert all Unicode binary symbols into Javascript text representation</p>
</li>
</ul>

<ul>
<li><p><code>lib.unicode2Ascii(str)</code></p>
<p>  Replace Unicode symbols with ASCII equivalents</p>
</li>
</ul>

<ul>
<li><p><code>lib.unescape(str)</code></p>
<p>  Convert escaped characters into native symbols</p>
</li>
</ul>

<ul>
<li><p><code>lib.textToXml(str)</code></p>
<p>  Convert all special symbols into xml entities</p>
</li>
</ul>

<ul>
<li><p><code>lib.textToEntity(str)</code></p>
<p>  Convert all special symbols into html entities</p>
</li>
</ul>

<ul>
<li><p><code>lib.entityToText(str)</code></p>
<p>  Convert html entities into their original symbols</p>
</li>
</ul>

<ul>
<li><p><code>lib.toBase32(buf, options)</code></p>
<p>  Convert a Buffer into base32 string</p>
</li>
</ul>

<ul>
<li><p><code>lib.fromBase32(str, options)</code></p>
<p>  Convert a string in base32 into a Buffer</p>
</li>
</ul>

<ul>
<li><p><code>lib.encrypt(key, data, options)</code></p>
<p>  Encrypt data with the given key code</p>
</li>
</ul>

<ul>
<li><p><code>lib.decrypt(key, data, options)</code></p>
<p>  Decrypt data with the given key code</p>
</li>
</ul>

<ul>
<li><p><code>lib.sign (key, data, algorithm, encode)</code></p>
<p>  HMAC signing and base64 encoded, default algorithm is sha1</p>
</li>
</ul>

<ul>
<li><p><code>lib.hash (data, algorithm, encode)</code></p>
<p>  Hash and base64 encoded, default algorithm is sha1</p>
</li>
</ul>

<ul>
<li><p><code>lib.random(size)</code></p>
<p>  Generate random key, size if specified defines how many random bits to generate</p>
</li>
</ul>

<ul>
<li><p><code>lib.randomUShort()</code></p>
<p>  Return random number between 0 and USHORT_MAX</p>
</li>
</ul>

<ul>
<li><p><code>lib.randomShort()</code></p>
<p>  Return random number between 0 and SHORT_MAX</p>
</li>
</ul>

<ul>
<li><p><code>lib.randomUInt()</code></p>
<p>  Return random number between 0 and ULONG_MAX</p>
</li>
</ul>

<ul>
<li><p><code>lib.randomFloat()</code></p>
<p>  Returns random number between 0 and 1, 32 bits</p>
</li>
</ul>

<ul>
<li><p><code>lib.randomInt(min, max)</code></p>
<p>  Return random integer between min and max inclusive using crypto generator, based on
<a href="https://github.com/joepie91/node-random-number-csprng">https://github.com/joepie91/node-random-number-csprng</a></p>
</li>
</ul>

<ul>
<li><p><code>lib.randomNum(min, max, decs)</code></p>
<p>  Generates a random number between given min and max (required)
Optional third parameter indicates the number of decimal points to return:</p>
<ul>
<li>If it is not given or is NaN, random number is unmodified</li>
<li>If &gt;0, then that many decimal points are returned (e.g., &quot;2&quot; -&gt; 12.52</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.timingSafeEqual(a, b)</code></p>
<p>  Timing safe string compare using double HMAC, from suryagh/tsscmp</p>
</li>
</ul>

<ul>
<li><p><code>lib.totp(key, options)</code></p>
<p>Create a Timed One-Time Password, RFC6328</p>
</li>
</ul>


<ul>
<li><p><code>lib.toSkip32(op, key, n)</code></p>
<p>  Encrypt/decrypt a number using a 10 byte <code>key</code> array, <code>op</code> == <code>d</code> for decrypt, other is encrypt</p>
</li>
</ul>

<ul>
<li><p><code>lib.forEachLine(file, options, lineCallback, endCallback)</code></p>
<p>  Call callback for each line in the file
options may specify the following parameters:</p>
<ul>
<li>sync - read file synchronously and call callback for every line</li>
<li>abort - signal to stop processing</li>
<li>limit - number of lines to process and exit</li>
<li>length - amount of data in bytes to process and exit</li>
<li>count - return this number of lines in an array if greater than 0</li>
<li>skip - number of lines to skip from the start</li>
<li>progress - if &gt; 0 report how many lines processed so far every specified lines</li>
<li>until - skip lines until this regexp matches</li>
<li>ignore - skip lines that match this regexp</li>
<li>header - if true then skip first line because it is the a header, if <code>options.header</code> it is a function
it will be called with the first line as an argument and must return true if this line needs to be skipped</li>
<li>json - each line represents an JSON object, convert and pass it to the line callback if not null</li>
<li>split - split every line before calling the callback, it uses phraseSplit</li>
<li>keepempty - by default is enabled if split is set to keep empty fields in the line array</li>
<li>separator - a string with characters to be used for splitting, default is <code>,</code></li>
<li>rxLine - a Regexp for line splitting, default is <code>lib.rxLine</code></li>
<li>quotes - a string with characters to be used for phrase splitting, default is <code>&quot;&#39;</code></li>
<li>quiet - do not report about open file errors</li>
<li>direct - to pass to lib.forEachLimit for true async processing</li>
<li>concurrency - how many lines to process at the samer time</li>
</ul>
<p>Properties updated and returned in the options:</p>
<ul>
<li>nlines - number of lines read from the file</li>
<li>ncalls - number of lines passed to the line callback</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.readLines(ctx, options, lineCallback, endCallback)</code></p>
<p>  Process lines asynchronously, both callbacks must be provided</p>
</li>
</ul>

<ul>
<li><p><code>lib.forEachLineSync(file, options, lineCallback)</code></p>
<p>  Sync version of the <code>forEachLine</code>, read every line and call callback which may not do any async operations
because they will not be executed right away but only after all lines processed</p>
</li>
</ul>

<ul>
<li><p><code>lib.writeLines(file, lines, options, callback)</code></p>
<p>  Write given lines into a file, lines can be a string or list of strings or numbers</p>
<ul>
<li>size - rotate if the file is larger, keep 2 files</li>
<li>ext - file ext to append on rotation, without dot, <code>old</code> is default, it can be in the <code>strftime</code> format to use date, like %w, %d, %m</li>
<li>mode - open file mode, usually a or w</li>
<li>newline - if true newlines are added for each line</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.moveFile(src, dst, overwrite, callback)</code></p>
<p>  Copy file and then remove the source, do not overwrite existing file</p>
</li>
</ul>

<ul>
<li><p><code>lib.copyFile(src, dst, overwrite, callback)</code></p>
<p>  Copy file, overwrite is optional flag, by default do not overwrite</p>
</li>
</ul>

<ul>
<li><p><code>lib.statSync(file)</code></p>
<p>  Non-exception version, returns empty object,
mtime is 0 in case file does not exist or number of seconds of last modified time
mdate is a Date object with last modified time</p>
</li>
</ul>

<ul>
<li><p><code>lib.readFileSync(file, options)</code></p>
<p>  Return contents of a file, empty if not exist or on error.</p>
<p>Options can specify the format:</p>
<ul>
<li>cfg - parse file in config format, name=value per line, return a list of args</li>
<li>json - parse file as JSON, return an object, in case of error an empty object</li>
<li>xml - parse the file as XML, return an object</li>
<li>list - split contents with the given separator</li>
<li>encoding - file encoding when converting to string</li>
<li>logger - log level for error messages</li>
<li>missingok - if set ENOENT will not be logged</li>
<li>offset - read from the position in the file, if negative the offset is from the end of file</li>
<li>length - read only this much of the data, otherwise read till the end of file</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.readFile(file, options, callback)</code></p>
<p>  Same as <code>lib.readFileSync</code> but asynchronous</p>
</li>
</ul>

<ul>
<li><p><code>lib.findFilter(file, stat, options)</code></p>
<p>  Filter function to be used in findFile methods</p>
</li>
</ul>

<ul>
<li><p><code>lib.findFileSync(file, options)</code></p>
<p>  Return list of files than match filter recursively starting with given path, file is the starting path.</p>
<p>The options may contain the following:</p>
<ul>
<li>include - a regexp with file pattern to include</li>
<li>exclude - a regexp with file pattern to exclude</li>
<li>filter - a function(file, stat) that return 1 if the given file matches, stat is a object returned by fs.statSync</li>
<li>depth - if a number it specifies max depth to go into the subfolders, starts with 1</li>
<li>types - a string with types of files to include: d - a dir, f - a file, l - a symlink, c - char dev, b - block dev, s - socket, p - a FIFO</li>
<li>base - if set only keep base file name in the result, not full path</li>
<li>details - return the whole stat structure instead of just names</li>
</ul>
<p> Example:</p>
<pre><code>   lib.findFileSync(&quot;modules/&quot;, { depth: 1, types: &quot;f&quot;, include: /\.js$/ }).sort()
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.findFile(dir, options, callback)</code></p>
<p>  Async version of find file, same options as in the sync version</p>
</li>
</ul>

<ul>
<li><p><code>lib.watchFiles(options, fileCallback, endCallback)</code></p>
<p>  Watch files in a dir for changes and call the callback, the parameters:</p>
<ul>
<li>root - a string with root path</li>
<li>files - a regexp to watch files individually, if omitted watch the whole dir</li>
<li>match - a regexp to watch files when using the whole dir, only for matched files the callback will be called</li>
<li>ignore - a regexp to ignore files</li>
<li>recursive - watch files in root subfolders</li>
<li>depth - how deep to look for files in case of individual files</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.makePathSync(dir)</code></p>
<p>  Recursively create all directories, return 1 if created or 0 on error or if exists, no exceptions are raised, error is logged only</p>
</li>
</ul>

<ul>
<li><p><code>lib.makePath(dir, callback)</code></p>
<p>  Async version of makePath, stops on first error</p>
</li>
</ul>

<ul>
<li><p><code>lib.unlink(name, callback)</code></p>
<p>  Unlink a file, no error on non-existent file, callback is optional</p>
</li>
</ul>

<ul>
<li><p><code>lib.unlinkPath(dir, callback)</code></p>
<p>  Recursively remove all files and folders in the given path, returns an error to the callback if any</p>
</li>
</ul>

<ul>
<li><p><code>lib.unlinkPathSync(dir)</code></p>
<p>  Recursively remove all files and folders in the given path, stops on first error</p>
</li>
</ul>

<ul>
<li><p><code>lib.chownSync(uid, gid)</code></p>
<p>  Change file owner, multiples files can be specified, do not report errors about non existent files, the uid/gid must be set to non-root user
for this function to work and it is called by the root only, all the rest of the arguments are used as files names</p>
<p>Example:</p>
<pre><code>      lib.chownSync(1, 1, &quot;/path/file1&quot;, &quot;/path/file2&quot;)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.mkdirSync()</code></p>
<p>  Create a directories if do not exist, multiple dirs can be specified, all preceeding directories are not created</p>
<p>Example:</p>
<pre><code>        lib.mkdirSync(&quot;dir1&quot;, &quot;dir2&quot;)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.findProcess(options, callback)</code></p>
<p>  Return a list of matching processes, Linux only</p>
</li>
</ul>

<ul>
<li><p><code>lib.execProcess(cmd, callback)</code></p>
<p>  Run the process and return all output to the callback, this a simply wrapper around child_processes.exec so the lib.runProcess
can be used without importing the child_processes module. All fatal errors are logged.</p>
</li>
</ul>

<ul>
<li><p><code>lib.spawnProcess(cmd, args, options, callback)</code></p>
<p>  Run specified command with the optional arguments, this is similar to child_process.spawn with callback being called after the process exited</p>
<p> Example</p>
<pre><code>     lib.spawProcess(&quot;ls&quot;, &quot;-ls&quot;, { cwd: &quot;/tmp&quot; }, lib.log)
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.checkRespawn(callback)</code></p>
<p>  If respawning too fast, delay otherwise call the callback after a short timeout</p>
</li>
</ul>

<ul>
<li><p><code>lib.spawnSeries(cmds, options, callback)</code></p>
<p>  Run a series of commands, <code>cmds</code> is an object where a property name is a command to execute and the value is an array of arguments or null.
if <code>options.error</code> is 1, then stop on first error or if non-zero status on a process exit.</p>
<p> Example:</p>
<pre><code>     lib.spawnSeries({&quot;ls&quot;: &quot;-la&quot;,
                       &quot;ps&quot;: &quot;augx&quot;,
                       &quot;du&quot;: { argv: &quot;-sh&quot;, stdio: &quot;inherit&quot;, cwd: &quot;/tmp&quot; },
                       &quot;uname&quot;: [&quot;-a&quot;] },
                      lib.log)
</code></pre>
</li>
</ul>


<ul>
<li><p><code>lib.forEach(list, iterator, callback, direct)</code></p>
<p>  Apply an iterator function to each item in an array in parallel. Execute a callback when all items
have been completed or immediately if there is an error provided.</p>
<p>The <code>direct</code> argument controls how the final callback is called, if true it is called directly otherwisde via setImmediate</p>
<pre><code>     lib.forEach([ 1, 2, 3 ], function (i, next) {
         console.log(i);
         next();
     }, function (err) {
         console.log(&#39;done&#39;);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.forEvery(list, iterator, callback, direct)</code></p>
<p>  Same as <code>forEach</code> except that the iterator will be called for every item in the list, all errors will be ignored</p>
</li>
</ul>

<ul>
<li><p><code>lib.forEachSeries(list, iterator, callback, direct)</code></p>
<p>  Apply an iterator function to each item in an array serially. Execute a callback when all items
have been completed or immediately if there is is an error provided.</p>
<pre><code>     lib.forEachSeries([ 1, 2, 3 ], function (i, next, data) {
         console.log(i, data);
         next(null, data);
     }, function (err, data) {
         console.log(&#39;done&#39;, data);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.forEverySeries(list, iterator, callback, direct)</code></p>
<p>  Same as <code>forEachSeries</code> except that the iterator will be called for every item in the list, all errors will be passed to the next
item with optional additional data argument.</p>
<pre><code>     lib.forEverySeries([ 1, 2, 3 ], function (i, next, err, data) {
         console.log(i, err, data);
         next(err, i, data);
     }, function (err, data) {
         console.log(&#39;done&#39;, err, data);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.forEachLimit(list, limit, iterator, callback, direct)</code></p>
<p>  Apply an iterator function to each item in an array in parallel as many as specified in <code>limit</code> at a time. Execute a callback when all items
have been completed or immediately if there is is an error provided.</p>
</li>
</ul>

<ul>
<li><p><code>lib.forEveryLimit(list, limit, iterator, callback, direct)</code></p>
<p>  Same as <code>forEachLimit</code> but does not stop on error, all items will be processed and errors will be collected in an array and
passed to the final callback</p>
</li>
</ul>

<ul>
<li><p><code>lib.forEachItem(options, next, iterator, callback, direct)</code></p>
<p>  Apply an iterator function to each item returned by the <code>next(item, cb)</code> function until it returns <code>null</code> or the iterator returns an error in the callback,
the final callback will be called after all iterators are finished.</p>
<p>If no item is available the <code>next()</code> should return empty value, it will be called again in <code>options.interval</code> ms if specified or
immediately in the next tick cycle.</p>
<p>The max number of iterators to run at the same time is controlled by <code>options.max</code>, default is 1.</p>
<p>The maximum time waiting for items can be specified by <code>options.timeout</code>, it is not an error condition, just another way to stop
processing if it takes too long because the <code>next()</code> function is a black box just returning items to process. Timeout will send null
to the queue and it will stop after all iterators are finished.</p>
<pre><code>   var list = [1, 2, &quot;&quot;, &quot;&quot;, 3, &quot;&quot;, 4, &quot;&quot;, &quot;&quot;, &quot;&quot;, null];
   lib.forEachItem({ max: 2, interval: 1000, timeout: 30000 },
       function(next) {
           next(list.shift());
       },
       function(item, next) {
           console.log(&quot;item:&quot;, item);
           next();
       },
       (err) =&gt; {
           console.log(&quot;done&quot;, err);
       });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.parallel(tasks, callback, direct)</code></p>
<p>  Execute a list of functions in parallel and execute a callback upon completion or occurance of an error. Each function will be passed
a callback to signal completion. The callback accepts an error for the first argument. The iterator and callback will be
called via setImmediate function to allow the main loop to process I/O unless the <code>direct</code> argument is true</p>
</li>
</ul>

<ul>
<li><p><code>lib.everyParallel(tasks, callback, direct)</code></p>
<p>  Same as <code>lib.parallel</code> but all functions will be called and any error will be ignored</p>
</li>
</ul>

<ul>
<li><p><code>lib.series(tasks, callback, direct)</code></p>
<p>  Execute a list of functions serially and execute a callback upon completion or occurance of an error. Each function will be passed
a callback to signal completion. The callback accepts either an error for the first argument in which case the flow will be aborted
and the final callback will be called immediately or some optional data to be passed to thr next iterator function as a second argument.</p>
<p>The iterator and callback will be called via setImmediate function to allow the main loop to process I/O unless the <code>direct</code> argument is true</p>
<pre><code>     lib.series([
        function(next) {
           next(null, &quot;data&quot;);
        },
        function(next, data) {
           setTimeout(function () { next(null, data); }, 100);
        },
     ], function(err, data) {
           console.log(err, data);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.everySeries(tasks, callback, direct)</code></p>
<p>  Same as <code>lib.series</code> but all functions will be called with errors passed to the next task, only the last passed error will be returned</p>
<pre><code>     lib.everySeries([
        function(next) {
           next(&quot;error1&quot;, &quot;data1&quot;);
        },
        function(next, err, data) {
           setTimeout(function () { next(err, &quot;data2&quot;); }, 100);
        },
     ], function(err, data) {
           console.log(err, data);
     });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.whilst(test, iterator, callback, direct, _)</code></p>
<p>  While the test function returns true keep running the iterator, call the callback at the end if specified.
All functions are called via setImmediate unless the <code>direct</code> argument is true</p>
<pre><code>     var count = 0;
     lib.whilst(
         function(data) {
             return count &lt; 5;
         },
         function (next, data) {
             count++;
             setTimeout(next, 1000);
         },
         function (err, data) {
             console.log(err, data, count);
         });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.doWhilst(iterator, test, callback, direct, _)</code></p>
<p>  Keep running iterator while the test function returns true, call the callback at the end if specified.
All functions are called via setImmediate unless the <code>direct</code> argument is true</p>
<pre><code>     var count = 0;
     lib.doWhilst(
         (next, data) =&gt; {
             count++;
             setTimeout(next, 1000);
         },
         (data) =&gt; (count &lt; 5),
         (err, data) =&gt; {
             console.log(err, data, count);
         });
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.typeName(v)</code></p>
<p>  Return object type, try to detect any distinguished type</p>
</li>
</ul>

<ul>
<li><p><code>lib.isObject(v)</code></p>
<p>  Returns true of the argument is a generic object, not a null, Buffer, Date, RegExp or Array</p>
</li>
</ul>

<ul>
<li><p><code>lib.isNumber(val)</code></p>
<p>  Return true if the value is a number</p>
</li>
</ul>

<ul>
<li><p><code>lib.isPrefix(val, prefix)</code></p>
<p>  Return true if the value is prefixed</p>
</li>
</ul>

<ul>
<li><p><code>lib.isUuid(val, prefix)</code></p>
<p>  Returns true if the value represents an UUID</p>
</li>
</ul>

<ul>
<li><p><code>lib.isTuuid(str)</code></p>
<p>  Returns true if the value represent tuuid</p>
</li>
</ul>

<ul>
<li><p><code>lib.isUnicode(str)</code></p>
<p>  Returns true of a string contains Unicode characters</p>
</li>
</ul>

<ul>
<li><p><code>lib.isPositive(val)</code></p>
<p>  Returns true if a number is positive, i.e. greater than zero</p>
</li>
</ul>

<ul>
<li><p><code>lib.isArray(val, dflt)</code></p>
<p>  Returns the array if the value is non empty array or dflt value if given or undefined</p>
</li>
</ul>

<ul>
<li><p><code>lib.isEmpty(val)</code></p>
<p>  Return true of the given value considered empty</p>
</li>
</ul>

<ul>
<li><p><code>lib.isNumeric(val)</code></p>
<p>  Returns true if the value is a number or string representing a number</p>
</li>
</ul>

<ul>
<li><p><code>lib.isNumericType(type)</code></p>
<p>  Returns true if the given type belongs to the numeric family of data types</p>
</li>
</ul>

<ul>
<li><p><code>lib.isDate(d)</code></p>
<p>  Returns true if the given date is valid</p>
</li>
</ul>

<ul>
<li><p><code>lib.isFlag(list, name)</code></p>
<p>  Returns true if <code>name</code> exists in the array <code>list</code>, search is case sensitive. if <code>name</code> is an array it will return true if
any element in the array exists in the <code>list</code>.</p>
</li>
</ul>

<ul>
<li><p><code>lib.isWord(text, start, end, delimiters)</code></p>
<p>  Returns true if it is a word at the position <code>start</code> and <code>end</code> in the <code>text</code> string,</p>
<ul>
<li><code>delimiters</code> define a character set to be used for words boundaries, if not given or empty string the default will be used</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.validNum(...args)</code></p>
<p>  Returns first valid number from the list of arguments or 0</p>
</li>
</ul>

<ul>
<li><p><code>lib.validPositive(...args)</code></p>
<p>  Returns first valid positive number from the list of arguments or 0</p>
</li>
</ul>

<ul>
<li><p><code>lib.validBool(...args)</code></p>
<p>  Returns first valid boolean from the list of arguments or false</p>
</li>
</ul>

<ul>
<li><p><code>lib.validVersion(version, condition)</code></p>
<p>  Return true if the version is within given condition(s), always true if either argument is empty.
Conditions can be: &gt;=M.N, &gt;M.N, =M.N, &lt;=M.N, &lt;M.N, M.N-M.N</p>
</li>
</ul>

<ul>
<li><p><code>lib.LRUCache(max)</code></p>
<p>  Simple LRU cache in memory, supports get,put,del operations only, TTL can be specified in milliseconds as future time</p>
</li>
</ul>

<ul>
<li><p><code>lib.exists(obj, name)</code></p>
<p>  Return true if a variable or property in the object exists,</p>
<ul>
<li>if obj is null or undefined return false</li>
<li>if obj is an object, return true if the property is not undefined</li>
<li>if obj is an array then search for the value with indexOf, only simple values supported,</li>
<li>if obj is a string then perform indexOf if the name is also a string or a number</li>
<li>if both are arrays return true if at least one item is in both arrays</li>
</ul>
<p>Example:</p>
<pre><code>    lib.exists({ 1: 1 }, &quot;1&quot;)
    lib.exists([ 1, 2, 3 ], 1)
    lib.exists([ 1, 2, 3 ], [ 1, 5 ])
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.isMatched(obj, condition, options)</code></p>
<p>  All properties in the object <code>obj</code> must match all properties in the object <code>condition</code>, for comparison <code>lib.isTrue</code> is used for each property
in the condition object.</p>
<ul>
<li>if a condition value is null it means an empty or non-existed value,</li>
<li>if a condition property is a string/number or regexp then it must match or be equal</li>
<li>if a condition property is a list then the object value must be present in the list</li>
<li>if an object property is a list and the condition property is a string/number/list then it must be present in the list</li>
<li>a condition can be a RegExp to test patterns</li>
</ul>
<p>Example:</p>
<pre><code>   lib.isMatched({ id: 1, name: &quot;test&quot;, type: [&quot;user&quot;, &quot;admin&quot;] }, { name: /^j/ })
   true
   lib.isMatched({ id: 1, name: &quot;test&quot;, type: [&quot;user&quot;, &quot;admin&quot;] }, { type: &quot;admin&quot; }, { ops: { type: &quot;not_in&quot; } })
   false
   lib.isMatched({ id: 1, name: &quot;test&quot;, type: [&quot;user&quot;, &quot;admin&quot;] }, { type: [staff&quot;] })
   false
   lib.isMatched({ id: 1, name: &quot;test&quot;, type: [&quot;user&quot;, &quot;admin&quot;] }, { id: 1 }, { ops: { id: &quot;ge&quot; } })
   true
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.isTrue(val, cond, op, type)</code></p>
<p>  Evaluate an expr, compare 2 values with optional type and operation, compae a data value <code>val`` against a condtion </code>cond`.</p>
</li>
</ul>

<ul>
<li><p><code>lib.arrayLength(list)</code></p>
<p>  Return the length of an array or 0 if it is not an array</p>
</li>
</ul>

<ul>
<li><p><code>lib.arrayRemove(list, item)</code></p>
<p>  Remove the given item from the list in place, returns the same list</p>
</li>
</ul>

<ul>
<li><p><code>lib.arrayUnique(list, key)</code></p>
<p>  Returns only unique items in the array, optional <code>key</code> specified the name of the column to use when determining uniqueness if items are objects.</p>
</li>
</ul>

<ul>
<li><p><code>lib.arrayEqual(list1, list2)</code></p>
<p>  Returns true if both arrays contain same items, only primitive types are supported</p>
</li>
</ul>

<ul>
<li><p><code>lib.arrayFlatten(list)</code></p>
<p>  Flatten array of arrays into a single array</p>
</li>
</ul>

<ul>
<li><p><code>lib.objClone()</code></p>
<p>  A copy of an object, this is a shallow copy, only arrays and objects are created but all other types are just referenced in the new object</p>
<ul>
<li>first argument is the object to clone, can be null</li>
<li>all additional arguments are treated as name value pairs and added to the cloned object as additional properties
Example:
   lib.objClone({ 1: 2 }, &quot;3&quot;, 3, &quot;4&quot;, 4)</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.objNew()</code></p>
<p>  Return new object using arguments as name value pairs for new object properties</p>
</li>
</ul>

<ul>
<li><p><code>lib.objFlatten(obj, options)</code></p>
<p>  Flatten a javascript object into a single-depth object, all nested values will have property names appended separated by comma</p>
<p>The options properties:</p>
<ul>
<li>separator - use something else instead of .</li>
<li>index - initial index for arrays, 0 is default</li>
</ul>
<p>Example</p>
<pre><code>     &gt; lib.objFlatten({ a: { c: 1 }, b: { d: 1 } } )
     { &#39;a.c&#39;: 1, &#39;b.d&#39;: 1 }
    &gt; lib.objFlatten({ a: { c: 1 }, b: { d: [1,2,3] } }, { index: 1 })
     { &#39;a.c&#39;: 1, &#39;b.d.1&#39;: 1, &#39;b.d.2&#39;: 2, &#39;b.d.3&#39;: 3 }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objClean(obj, options)</code></p>
<p>  Cleanup object properties, delete all undefined values in place by default.
Additional options:</p>
<ul>
<li>If <code>null</code> is true then delete all null properties.</li>
<li>If <code>empty</code> is true then delete all empty properties, i.e. null/undefined/&quot;&quot;/[]</li>
<li>If <code>type</code> is a RegExp then all properties that match it by type will be deleted.</li>
<li>If <code>name</code> is a RegExp then all properties that match it by name will be deleted.</li>
<li>If <code>value</code> is a RegExp then all string|number|boolean properties that match it by value will be deleted.</li>
<li>If <code>array</code> is true then process all array items recursivelly</li>
</ul>
<p>Example</p>
<pre><code>&gt; lib.cleanObj({ a: 1, b: true, c: undefined, d: 2, e: null, l: [&quot;a&quot;, &quot;b&quot;, null, undefined, { a: 1, b: undefined } ] },{ null:1, array:1, type: /boolean/})
{ a: 1, d: 2, l: [ &#39;a&#39;, &#39;b&#39;, { a: 1 } ] }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objExtend(obj, val, options)</code></p>
<p>  Add properties to an existing object where the first arg is an object, the second arg is an object to add properties from,
the third argument can be an options object that can control how the properties are merged.</p>
<p>Options properties:</p>
<ul>
<li><p>allow - a regexp which properties are allowed to be merged</p>
</li>
<li><p>ignore - a regexp which properties should be ignored</p>
</li>
<li><p>del - a regexp which properties should be removed</p>
</li>
<li><p>strip - a regexp to apply to each property name before merging, the matching parts will be removed from the name</p>
</li>
<li><p>deep - extend all objects not just the top level</p>
</li>
<li><p>noempty - skip undefined, default is to keep</p>
<p>   lib.objExtend({ a:1, c:5 }, { c: { b: 2 }, d: [{ d: 3 }], _e: 4, f: 5, x: 2 }, { allow: /^(c|d|<em>e)/, strip: /^</em>/, del: /^f/ })
   { a: 1, c: { b: 2 }, d: [ { d: 3 } ], e: 4 }</p>
<p>   lib.objExtend({ a:1, c:5 }, { c: { b: 2 }, d: [{ d: 3 }], _e: 4, f: 5, x: 2 }, { allow: /^(c|d|<em>e)/, strip: /^</em>/, del: /^f/, deep: 1 })
   { a: 1, c: {}, d: [ { d: 3 } ], e: 4 }</p>
</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.objMerge(obj, val, options)</code></p>
<p>  Merge two objects, all properties from the <code>val</code> override existing properties in the <code>obj</code>, returns a new object</p>
<p>Options properties:</p>
<ul>
<li>allow - a regexp which properties are allowed to be merged</li>
<li>ignore - a regexp which properties should be ignored</li>
<li>del - a regexp which properties should be removed</li>
<li>remove - a regexp to apply to each property name before merging, the matching parts will be removed from the name</li>
<li>deep - make a deep copy using objExtend</li>
</ul>
<p> Example</p>
<pre><code>  var o = lib.objMerge({ a:1, b:2, c:3 }, { c:5, d:1, _e: 4, f: 5, x: 2 }, { allow: /^(c|d)/, remove: /^_/, del: /^f/ })
  o = { a:1, b:2, c:5, d:1 }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objDel()</code></p>
<p>  Delete properties from the object, first arg is an object, the rest are properties to be deleted</p>
</li>
</ul>

<ul>
<li><p><code>lib.objSearch(obj, options)</code></p>
<p>  Return list of objects that matched the given criteria in the given object. Performs the deep search.</p>
<p>The options can define the following properties:</p>
<ul>
<li>exists - search by property name, return all objects that contain given property</li>
<li>hasValue - return only objects that have a property with given value</li>
<li>matchValue - return only objects that match the given RegExp by property value</li>
<li>matchName - return only objects that match the given RegExp by property name</li>
<li>sort - sort the result by the given property</li>
<li>value - return an object with this property only, not the whole matched object</li>
<li>count - return just number of found properties</li>
</ul>
<p>Example:</p>
<pre><code>     var obj = { id: { index: 1 }, name: { index: 3 }, descr: { type: &quot;string&quot;, pub: 1 }, items: [ { name: &quot;test&quot; } ] };

     lib.objSearch(obj, { matchValue: /string/ });
     [ { name: &#39;descr&#39;, value: { type: &quot;string&quot;, pub: 1 } } ]

     lib.objSearch(obj, { matchName: /name/, matchValue: /^t/ });
     [{ name: &#39;0&#39;: value: { name: &quot;test&quot; }]

     lib.objSearch(obj, { exists: &#39;index&#39;, sort: 1, value: &quot;index&quot; });
     { id: 1, name: 3 }

     lib.objSearch(obj, { hasValue: &#39;test&#39;, count: 1 });
     1
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objGet(obj, name, options)</code></p>
<p>  Return a property from the object, name specifies the path to the property, if the required property belong to another object inside the top one
the name uses . to separate objects. This is a convenient method to extract properties from nested objects easily.
Options may contains the following properties:</p>
<ul>
<li>list - return the value as a list even if there is only one value found</li>
<li>obj - return the value as an object, if the result is a simple type, wrap into an object like { name: name, value: result }</li>
<li>str - return the value as a string, convert any other type into string</li>
<li>num - return the value as a number, convert any other type by using toNumber</li>
<li>func - return the value as a function, if the object is not a function returns null</li>
<li>owner - return the owner object, not the value, i.e. return the object who owns the value specified in the name</li>
</ul>
<p>Example:</p>
<pre><code>     &gt; lib.objGet({ response: { item : { id: 123, name: &quot;Test&quot; } } }, &quot;response.item.name&quot;)
     &quot;Test&quot;
     &gt; lib.objGet({ response: { item : { id: 123, name: &quot;Test&quot; } } }, &quot;response.item.name&quot;, { list: 1 })
     [ &quot;Test&quot; ]
     &gt; lib.objGet({ response: { item : { id: 123, name: &quot;Test&quot; } } }, &quot;response.item.name&quot;, { owner: 1 })
     { item : { id: 123, name: &quot;Test&quot; } }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objSet(obj, name, value, options)</code></p>
<p>  Set a property of the object, name can be an array or a string with property path inside the object, all non existent intermediate
objects will be create automatically. The options can have the folowing properties:</p>
<ul>
<li>incr - increment a numeric property with the given number or 1, 0 is noop, non-existing propertties will be initilaized with 0</li>
<li>mult - multiply a numeric property with the given number, non-existing properties will be initialized with 0</li>
<li>push - add to the array, if it is not an array a new empty aray is created</li>
<li>append - append to a string</li>
<li>unique - only push if not in the list</li>
<li>separator - separator for object names, default is <code>.</code></li>
<li>result - &quot;new&quot; - new value, &quot;old&quot; - old value, &quot;obj&quot; - final object, otherwise the original object itself</li>
</ul>
<p>Example</p>
<pre><code>     var a = lib.objSet({}, &quot;response.item.count&quot;, 1)
     lib.objSet(a, &quot;response.item.count&quot;, 1, { incr: 1 })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>lib.objIncr(obj, name, count, result)</code></p>
<p>  Increment a property by the specified number, if the property does not exist it will be created,
returns new incremented value or the value specified by the <code>result</code> argument.
It uses <code>lib.objSet</code> so the property name can be a nested path.</p>
</li>
</ul>

<ul>
<li><p><code>lib.objMult(obj, name, count, result)</code></p>
<p>  Similar to <code>objIncr</code> but does multiplication</p>
</li>
</ul>

<ul>
<li><p><code>lib.objKeys(obj)</code></p>
<p>  Return all property names for an object</p>
</li>
</ul>

<ul>
<li><p><code>lib.objDescr(obj, options)</code></p>
<p>  Return an object structure as a string object by showing primitive properties only,
for arrays it shows the length and <code>options.count</code> or 25 first items,
for objects it will show up to the <code>options.keys</code> or 25 first properties,
strings are limited by <code>options.length</code> or 256 bytes, if truncated the full string length is shown.
the object depth is limited by <code>options.depth</code> or 5 levels deep, the number of properties are limited by options.count or 15,
all properties that match <code>options.ignore</code> will be skipped from the output, if <code>options.allow</code> is a regexp, only properties that
match it will be output. Use <code>options.replace</code> for replacing anything in the final string.</p>
</li>
</ul>

<ul>
<li><p><code>lib.objSize(obj, options, priv)</code></p>
<p>  Returns the size of the whole object, this is not exact JSON size, for speed it
summarizes approximate size of each property recursively</p>
<ul>
<li><code>depth</code> - limits how deep it goes, on limit returns MAX_SAFE_INTEGER+ number</li>
<li><code>nan</code> - if true return NaN on reaching the limits</li>
<li><code>pad</code> - extra padding added for each property, default is 5 to simulate JSON encoding, &quot;..&quot;: &quot;..&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.objReset(obj, options)</code></p>
<p>  Reset properties of the <code>obj</code> matching the regexp, simple types are removed but objects/arrays/maps are set to empty objects
Options properties:</p>
<ul>
<li>name - a regexp with property names to be matched</li>
<li>type - a regexp of types to be matched</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.configParse(data, options)</code></p>
<p>  Parse data as config format name=value per line,
return an array of arguments in command line format [&quot;-name&quot;, value,....]</p>
<p>Supports sections:</p>
<ul>
<li>The format is: <code>[name=value,...]</code> or <code>[name!=value,...]</code>
where name is a property name with optional value(s).</li>
<li>if the value is empty then it just checks if the property is empty.</li>
<li><code>!=</code> denotes negative condition, i.e. not matching or NOT empty</li>
<li>section names may refer deep into objects like <code>aws.region</code> or <code>instance.tag</code>,
all modules will be checked inside <code>options.modules</code> object only,
all other names are checked in the top level options.</li>
</ul>
<p>Sections work like a filter, only if a property matches it is used otherwise skipped completely, it uses <code>lib.isTrue</code> for matching
so checking an item in an array will work as well.
The [global] section can appear anytime to return to global mode</p>
</li>
</ul>

<ul>
<li><p><code>lib.jsonParse(obj, options)</code></p>
<p>  Silent JSON parse, returns null on error, no exceptions raised.</p>
<p>options can specify the following properties:</p>
<ul>
<li>datatype - make sure the result is returned as type: obj, list, str</li>
<li>dflt - return this in case of error</li>
<li>empty - if true silent about empty input, no logging</li>
<li>logger - report in the log with the specified level, log, debug, ...</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.xmlParse(obj, options)</code></p>
<p>  Same arguments as for <code>jsonParse</code></p>
</li>
</ul>

<p>  Combined parser with type validation</p>

<ul>
<li><p><code>lib.matchRegexp(str, rx, index)</code></p>
<p>  Perform match on a regexp for a string and returns matched value, if no index is specified returns item 1,
using index 0 returns the whole matched string, -1 means to return the whole matched array
If the `rx`` object has the &#39;g&#39; flag the result will be all matches in an array.</p>
</li>
</ul>

<ul>
<li><p><code>lib.matchAllRegexp(str, rx, index)</code></p>
<p>  Perform match on a regexp and return all matches in an array, if no index is specified returns item 1</p>
</li>
</ul>

<ul>
<li><p><code>lib.testRegexp(str, rx)</code></p>
<p>  Perform test on a regexp for a string and returns true only if matched.</p>
</li>
</ul>

<ul>
<li><p><code>lib.testRegexpObj(str, rx)</code></p>
<p>  Run test on a regexpObj</p>
</li>
</ul>

<ul>
<li><p><code>lib.replaceRegexp(str, rx, val)</code></p>
<p>  Safe version of replace for strings, always returns a string, if <code>val</code> is not provided performs
removal of the matched patterns</p>
</li>
</ul>

<ul>
<li><p><code>lib.strTrim(str, chars)</code></p>
<p>  Remove all whitespace from the begining and end of the given string, if an array with characters is not given then it trims all whitespace</p>
</li>
</ul>

<ul>
<li><p><code>lib.strSplit(str, sep, options)</code></p>
<p>  Split string into array, ignore empty items,</p>
<ul>
<li><code>sep</code> is an RegExp to use as a separator instead of default  pattern <code>[,\|]</code>,</li>
<li><code>options</code> is an object with the same properties as for the <code>toParams</code>,<ul>
<li><code>datatype&#39; will be used with </code>lib.toValue` to convert the value for each item</li>
<li><code>keepempty</code> - will preserve empty items, by default empty strings are ignored</li>
<li><code>notrim</code> - will skip trimming strings, trim is the default</li>
<li><code>max</code> - will skip strings over the specificed size if no <code>trunc</code></li>
<li><code>trunc</code> - will truncate strings longer than <code>max</code></li>
<li><code>regexp</code> - will skip string if not matching</li>
<li><code>noregexp</code> - will skip string if matching</li>
<li><code>replace</code> - an object map which characters to replace with new values</li>
</ul>
</li>
</ul>
<p>If <code>str</code> is an array and type is not specified then all non-string items will be returned as is.</p>
</li>
</ul>

<ul>
<li><p><code>lib.strSplitUnique(str, sep, options)</code></p>
<p>  Split as above but keep only unique items, case-insensitive</p>
</li>
</ul>

<ul>
<li><p><code>lib.phraseSplit(str, options)</code></p>
<p>  Split a string into phrases separated by <code>options.separator</code> character(s) and surrounded by characters in <code>options.quotes</code>.
The default separator is space and default quotes are both double and single quote.
If <code>options.keepempty</code> is given all empty parts will be kept in the list.</p>
</li>
</ul>

<ul>
<li><p><code>lib.zeropad(n, width)</code></p>
<p>  Return a string with leading zeros</p>
</li>
</ul>

<ul>
<li><p><code>lib.sprintf(fmt, args)</code></p>
<p>  C-sprintf alike
based on <a href="http://stackoverflow.com/a/13439711">http://stackoverflow.com/a/13439711</a>
Usage:</p>
<ul>
<li>sprintf(fmt, arg, ...)</li>
<li>sprintf(fmt, [arg, ...]);</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.strCompress(data, encoding)</code></p>
<p>  From <a href="https://github.com/pieroxy/lz-string/">https://github.com/pieroxy/lz-string/</a></p>
</li>
</ul>

<ul>
<li><p><code>lib.strSimilarity(s1, s2, options)</code></p>
<p>  Returns a score between 0 and 1 for two strings, 0 means no similarity, 1 means exactly similar.
The default algorithm is JaroWrinkler, options.type can be used to specify a different algorithm:</p>
<ul>
<li>sd - Sorensent Dice</li>
<li>cs - Cosine Similarity</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.AhoCorasick(keywords)</code></p>
<p>  Text search using Aho-Corasick algorithm, based on <a href="https://github.com/BrunoRB/ahocorasick">https://github.com/BrunoRB/ahocorasick</a></p>
</li>
</ul>

<ul>
<li><p><code>lib.AhoCorasick.prototype.search(text, options)</code></p>
<p>  Search given text for keywords, returns a list of matches in the format [ index, [ keywords] ]
where the index points to the last character of the found keywords. When <code>options.list</code> is true it returns
the matched keywords only.</p>
<p>Example:
 var ac = new lib.AhoCorasick([&#39;keyword1&#39;, &#39;keyword2&#39;, &#39;etc&#39;]);
 ac.search(&#39;should find keyword1 at position 19 and keyword2 at position 47.&#39;);
 [ [ 19, [ &#39;keyword1&#39; ] ], [ 47, [ &#39;keyword2&#39; ] ] ]

 ac.search(&#39;should find keyword1 at position 19 and keyword2 at position 47.&#39;, { list: 1 });
 [ &#39;keyword1&#39;, &#39;keyword2&#39; ]
If <code>options.delimiters</code> is a string then return words only if surrounded by characters in the delimiters, this is
to return true words and not substrings, empty string means use the default delimiters which are all punctuation characters</p>
</li>
</ul>

<ul>
<li><p><code>lib.findWords(words, text, delimiters)</code></p>
<p>  Return an array of <code>words`` found in the given </code>text`` separated by delimiters, this a brute force search for every keyword and
using <code>lib.isWord</code> to detect boundaries.
This is an alternative to AhoCorasick if number of words is less than 50-70.</p>
</li>
</ul>

<ul>
<li><p><code>lib.networkInterfaces(options)</code></p>
<p>  Return a list of local interfaces, default is all active IPv4 unless `IPv6`` property is set</p>
</li>
</ul>

<ul>
<li><p><code>lib.dropPrivileges(uid, gid)</code></p>
<p>  Drop root privileges and switch to a regular user</p>
</li>
</ul>

<ul>
<li><p><code>lib.ip2int(ip)</code></p>
<p>  Convert an IP address into integer</p>
</li>
</ul>

<ul>
<li><p><code>lib.int2ip(int)</code></p>
<p>  Convert an integer into IP address</p>
</li>
</ul>

<ul>
<li><p><code>lib.inCidr(ip, cidr)</code></p>
<p>  Return true if the given IP address is within the given CIDR block</p>
</li>
</ul>

<ul>
<li><p><code>lib.cidrRange(cidr)</code></p>
<p>  Return first and last IP addresses for the CIDR block</p>
</li>
</ul>

<ul>
<li><p><code>lib.domainName(host, toplevel)</code></p>
<p>  Extract domain from the host name, takes all host parts except the first one, if toplevel is true return 2 levels only</p>
</li>
</ul>

<ul>
<li><p><code>lib.localEpoch(type)</code></p>
<p>  Returns current time in seconds (s), microseconds (m), time struct (tm) or milliseconds since the local <code>lib._epoch</code> (2023-07-31 UTC)</p>
</li>
</ul>

<ul>
<li><p><code>lib.clock()</code></p>
<p>  Returns current time in microseconds since January 1, 1970, UTC</p>
</li>
</ul>

<ul>
<li><p><code>lib.getTimeOfDay()</code></p>
<p>  Return current time in an array as [ tv_sec, tv_usec ]</p>
</li>
</ul>

<ul>
<li><p><code>lib.now()</code></p>
<p>  Return number of seconds for current time</p>
</li>
</ul>

<ul>
<li><p><code>lib.daysInMonth(year, month)</code></p>
<p>  Return the number of days in the given month of the specified year.</p>
</li>
</ul>

<ul>
<li><p><code>lib.weekOfYear(date, utc)</code></p>
<p>  Return an ISO week number for given date, from <a href="https://www.epochconverter.com/weeknumbers">https://www.epochconverter.com/weeknumbers</a></p>
</li>
</ul>

<ul>
<li><p><code>lib.isDST(date)</code></p>
<p>  Returns true if the given date is in DST timezone</p>
</li>
</ul>

<ul>
<li><p><code>lib.tzName(tz)</code></p>
<p>  Return a timezone human name if matched (EST, PDT...), tz must be in GMT-NNNN format</p>
</li>
</ul>

<ul>
<li><p><code>lib.parseTime(time)</code></p>
<p>  Parses a string with time and return an array [hour, min], accepts 12 and 24hrs formats,
a single hour is accepted as well, returns undefined if cannot parse</p>
</li>
</ul>

<ul>
<li><p><code>lib.isTimeRange(time1, time2, options)</code></p>
<p>  Returns 0 if the current time is not within specified valid time range or it is invalid. Only continious time rang eis support, it
does not handle over the midninght ranges, i.e. time1 is always must be greater than time2.</p>
<p><code>options.tz</code> to specify timezone, no timezone means current timezone.
<code>options.date</code> if given must be a list of dates in the format: YYY-MM-DD,...</p>
</li>
</ul>


<ul>
<li><p><code>lib.strftime(date, fmt, options)</code></p>
<p>  Format date object</p>
</li>
</ul>

<ul>
<li><p><code>lib.getHashid(options)</code></p>
<p>  Return cached Hashids object for the given configuration
Properties:</p>
<ul>
<li>salt - hashid salt, default is lib.salt</li>
<li>min - minimum size of a hashid</li>
<li>alphabet - chars allowed in hashids, default is lib.base32</li>
<li>separators - hashid separator characters</li>
<li>counter - max counter value to wrap back to 1, default is 65535</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.uuid(prefix, options)</code></p>
<p>  Return unique Id without any special characters and in lower case</p>
</li>
</ul>

<ul>
<li><p><code>lib.slug(options)</code></p>
<p>  Generate a 22 chars slug from an UUID, alphabet can be provided, default is <code>lib.uriSafe</code></p>
</li>
</ul>

<ul>
<li><p><code>lib.suuid(prefix, options)</code></p>
<p>  Returns a short unique id within a microsecond</p>
</li>
</ul>

<ul>
<li><p><code>lib.murmurHash3(key, seed = 0)</code></p>
<p>  32-bit MurmurHash3 implemented by bryc (github.com/bryc)</p>
</li>
</ul>

<ul>
<li><p><code>lib.sfuuid(options)</code></p>
<p>  Generate a SnowFlake unique id as 64-bit number
Format: time - 41 bit, node - 10 bit, counter - 12 bit
Properties can be provided:</p>
<ul>
<li>now - time, if not given local epoch clock is used in microseconds</li>
<li>epoch - local epoch type, default is milliseconds, <code>m</code> for microseconds, <code>s</code> for seconds</li>
<li>node - node id, limited to max 1024</li>
<li>radix - default is 10, use any value between 2 - 36 for other numeric encoding</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>lib.sfuuidParse(id)</code></p>
<p>  Parse an id into original components: now, node, counter</p>
</li>
</ul>

<ul>
<li><p><code>lib.tuuid(prefix, encode)</code></p>
<p>  Returns time sortable unique id, inspired by <a href="https://github.com/paixaop/node-time-uuid">https://github.com/paixaop/node-time-uuid</a></p>
</li>
</ul>

<ul>
<li><p><code>lib.tuuidTime(str)</code></p>
<p>  Return time in milliseconds from the time uuid</p>
</li>
</ul>

<h2 id="module-logger">Module: logger</h2>
<p>  Simple logger utility for debugging</p>

<ul>
<li><p><code>logger.registerLevel(level, callback, options)</code></p>
<p>  Register a custom level handler, must be invoked via <code>logger.logger</code> only, if no handler registered for given level
the whole message will be logger as an error. The custom hadnler is called in the context of the module which means
the options are available inside the handler.</p>
<p>The following properties are supported automatically:</p>
<ul>
<li>format - if 1 then all arguments will be formatted into one line as for the regular levels and passed
 the handler as one argument, this is to support different transport and preserve the same standard logging format</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>logger.setSyslog(facility, tag)</code></p>
<p>  Set or close syslog mode</p>
</li>
</ul>

<ul>
<li><p><code>logger.setFile(file, options)</code></p>
<p>  Redirect logging into file</p>
</li>
</ul>

<ul>
<li><p><code>logger.setLevel(level)</code></p>
<p>  Set the output level, it can be a number or one of the supported level names</p>
</li>
</ul>

<ul>
<li><p><code>logger.setDebugFilter(str, func)</code></p>
<p>  Enable debugging level for this label, if used with the same debugging level it will be printed regardless of the global level,
a label is first argument to the <code>logger.debug</code> methods, it is used as is, usually the fist argument is
the current function name with comma, like <code>logger.debug(&quot;select:&quot;, name, args)</code>
The <code>func</code> can be a function to be instead of regular logging, this is for rerouting some output to a custom console or for
dumping the actual Javascript data without preformatting, most useful to use <code>console.log</code></p>
</li>
</ul>

<ul>
<li><p><code>logger.errorWithOptions(err, options)</code></p>
<p>  Prints the given error and the rest of the arguments, the logger level to be used is determined for the given error by code,
uses <code>options</code> or <code>options.logger_error</code> as the level if a string,</p>
<ul>
<li>if <code>options.logger_error</code> is an object, extract the level by <code>err.code</code> or use <code>*</code> as the default level for not matched codes,
the default is to use the <code>error</code> level.</li>
<li>In case the level is notice or info the error will only show status/code/message properties in order not to print stack trace</li>
<li>Merge <code>options.logger_inspect</code> if present with the current inspect options to log the rest of arguments.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>logger.setInspectOptions(options)</code></p>
<p>  Merge with existing inspect options temporarily, calling without options will reset to previous values</p>
</li>
</ul>

<ul>
<li><p><code>logger.trace()</code></p>
<p>  Print stack backtrace as error</p>
</li>
</ul>

<ul>
<li><p><code>logger.logger(level, ...args)</code></p>
<p>  A generic logger method, safe, first arg is supposed to be a logging level, if not valid the error level is used</p>
</li>
</ul>

<ul>
<li><p><code>logger.write(str)</code></p>
<p>  Stream emulation</p>
</li>
</ul>

<h3 id="module-syslog">Module: syslog</h3>

<h2 id="module-metrics">Module: metrics</h2>

<ul>
<li><p><code>TokenBucket.prototype.configure(rate, max, interval, total)</code></p>
<p>  Initialize existing token with numbers for rate calculations</p>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.toJSON()</code></p>
<p>  Return a JSON object to be serialized/saved</p>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.toString()</code></p>
<p>  Return a string to be serialized/saved</p>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.toArray()</code></p>
<p>  Return an array object to be serialized/saved</p>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.equal(rate, max, interval)</code></p>
<p>  Return true if this bucket uses the same rates in arguments</p>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.consume(tokens)</code></p>
<p>  Consume N tokens from the bucket, if no capacity, the tokens are not pulled from the bucket.</p>
<p>Refill the bucket by tracking elapsed time from the last time we touched it.</p>
<pre><code> min(totalTokens, current + (fillRate * elapsedTime))
</code></pre>
</li>
</ul>

<ul>
<li><p><code>TokenBucket.prototype.delay(tokens)</code></p>
<p>  Returns number of milliseconds to wait till number of tokens can be available again</p>
</li>
</ul>

<h2 id="module-msg">Module: msg</h2>
<p>  Messaging and push notifications for mobile and other clients, supports Apple, Google and AWS/SNS push notifications.</p>
<p>  Emits a signal <code>uninstall(client, device_id, account_id)</code> on device invalidation or if a device token is invalid as reported by the server, account_id
  may not be available.</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>msg-([^-]+)-key(@.+)?</code>, obj: &quot;config&quot;, make: &quot;$1$2|_key&quot;, nocamel: 1, trim: 1, descr: &quot;API private key for FCM/Webpush or similar services, if the suffix is specified in the config parameter will be used as the app name, without the suffix it is global&quot;</li>
<li><code>msg-([^-]+)-pubkey(@.+)?</code>, obj: &quot;config&quot;, make: &quot;$1$2|_pubkey&quot;, nocamel: 1, trim: 1, descr: &quot;API public key for Webpush or similar services, if the suffix is specified in the config parameter will be used as the app name, without the suffix it is global&quot;</li>
<li><code>msg-([^-]+)-authkey-([^-]+)-(.+)</code>, obj: &quot;config&quot;, make: &quot;$1@$2-$3|_authkey&quot;, nocamel: 1, descr: &quot;A auth key for APN in p8 format, can be a file name with .p8 extension or a string with the key contents encoded with base64, the format is: -msg-apn-authkey-TEAMID-KEYID KEYDATA&quot;</li>
<li><code>msg-([^-]+)-sandbox(@.+)?</code>, obj: &quot;config&quot;, make: &quot;$1$2|_sandbox&quot;, nocamel: 1, type: &quot;bool&quot;, descr: &quot;Enable sandbox for a service, default is production mode&quot;</li>
<li><code>msg-([^-]+)-options-([^@]+)(@.+)?</code>, obj: &quot;config&quot;, make: &quot;$1$3|$2&quot;, autotype: 1, nocamel: 1, descr: &quot;A config property to the specified agent, driver specific&quot;</li>
<li><code>msg-shutdown-timeout</code>, type: &quot;int&quot;, min: 0, descr: &quot;How long to wait for messages draining out in ms on shutdown before exiting&quot;</li>
<li><code>msg-app-default</code>, descr: &quot;Default app id(app bundle id) to be used when no app_id is specified&quot;</li>
<li><code>msg-app-dependency@(.+)</code>, obj: &quot;dependency&quot;, make: &quot;$1&quot;, type: &quot;list&quot;, nocamel: 1, descr: &quot;List of other apps that are considered in the same app family, sending to the primary app will also send to all dependent apps&quot;</li>
<li><code>msg-app-team-(.+)</code>, obj: &quot;teams&quot;, make: &quot;$1&quot;, type: &quot;regexp&quot;, nocamel: 1, descr: &quot;Regexp that identifies all app bundles for a team&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.init(options, callback)</code></p>
<p>  Initialize supported notification services, it supports jobs arguments convention so can be used in the jobs that
need to send push notifications in the worker process.</p>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.shutdown(options, callback)</code></p>
<p>  Shutdown notification services, wait till all pending messages are sent before calling the callback</p>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.send(device, options, callback)</code></p>
<p>  Deliver a notification for the given device token(s).</p>
<p>The <code>device</code> is where to send the message to, can be multiple ids separated by , or |.</p>
<p>Options with the following properties:</p>
<ul>
<li>service_id - list of services to use for delivery only: default, sns, apn, gcm</li>
<li>account_id - an account id associated with this token, for debugging and invalid token management</li>
<li>app_id - send to the devices for the given app only, if none matched send to the default device tokens only</li>
<li>msg - text message to send</li>
<li>badge - badge number to show if supported by the service</li>
<li>sound - set to 1 if a sound should be produced on message receive</li>
<li>type - set type of the message, service specific</li>
<li>category - action category for APN</li>
<li>id - send id with the notification, this is application specific data, sent as is</li>
<li>name - notification group name, can be used for grouping multiple messages under this name</li>
<li>url - a launch url for the app, it show associated screen on launch if supported</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.parseDevice(device)</code></p>
<p>  Parse device URN and returns an object with all parts into separate properties. A device URN can be in the following format:
   [service://]device_token[@app]</p>
<ul>
<li>service is optional, supported types: <code>apn</code>, <code>gcm</code>, <code>sns</code>, the <code>default</code> service uses APN delivery</li>
<li>app is optional and can define an application id which is used by APN for routing to the devices with corresponding APS certificate.</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.getClient(dev)</code></p>
<p>  Return a client module that supports the given device</p>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.getConfig(name)</code></p>
<p>  Return a list of all config cert/key parameters for the given name.
Each item in the list is an object with the following properties: key, secret, app</p>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.getAgent(mod, dev)</code></p>
<p>  Return an agent for the given module for the given device</p>
</li>
</ul>

<ul>
<li><p><code>Msg.prototype.getTeam(app)</code></p>
<p>  Return a team for the given app</p>
</li>
</ul>


<ul>
<li><p><code>client.check(dev)</code></p>
<p>  Returns true if given device is supported by APN</p>
</li>
</ul>

<ul>
<li><p><code>client.init(options)</code></p>
<p>  Initialize Apple Push Notification service in the current process, Apple supports multiple connections to the APN gateway but
not too many so this should be called on the dedicated backend hosts, on multi-core servers every spawn web process will initialize a
connection to APN gateway.</p>
</li>
</ul>

<ul>
<li><p><code>client.close(callback)</code></p>
<p>  Close APN agent, try to send all pending messages before closing the gateway connection</p>
</li>
</ul>

<ul>
<li><p><code>client.send(dev, options, callback)</code></p>
<p>  Send push notification to an Apple device, returns true if the message has been queued.</p>
<p>The options may contain the following properties:</p>
<ul>
<li>msg - message text</li>
<li>title - alert title</li>
<li>badge - badge number</li>
<li>sound - 1, true or a sound file to play</li>
<li>category - a user notification category</li>
<li>alertAction - action to exec per Apple doc, action</li>
<li>launchImage - image to show per Apple doc, launch-image</li>
<li>contentAvailable - content indication per Apple doc, content-available</li>
<li>mutableContent - mark the notification to go via extention for possible modifications</li>
<li>locKey - localization key per Apple doc, loc-key</li>
<li>locArgs - localization key per Apple doc, loc-args</li>
<li>titleLocKey - localization key per Apple doc, title-loc-key</li>
<li>titleLocArgs - localization key per Apple doc, title-loc-args</li>
<li>threadId - grouping id, all msgs with the same id will be grouped together</li>
<li>id - send id in the user properties</li>
<li>type - set type of the event</li>
<li>url - launch url</li>
<li>payload - an object with additional fileds to send in the message payload</li>
</ul>
</li>
</ul>


<ul>
<li><p><code>client.init(options)</code></p>
<p>  Initialize Google Cloud Messaging service to send push notifications to mobile devices</p>
</li>
</ul>

<ul>
<li><p><code>client.close(callback)</code></p>
<p>  Close GCM connection, flush the queue</p>
</li>
</ul>

<ul>
<li><p><code>client.send(dev, options, callback)</code></p>
<p>  Send push notification to an Android device, return true if queued.</p>
</li>
</ul>

<ul>
<li><p><code>client.retryOnError()</code></p>
<p>  Retry on server error, honor Retry-After header if present, use it only on the first error</p>
</li>
</ul>


<ul>
<li><p><code>client.send(dev, options, callback)</code></p>
<p>  Send a Web push notification using the <code>web-push</code> npm module, referer to it for details how to generate VAPID credentials to
configure this module with 3 required parameters:</p>
<ul>
<li><code>msg-webpush-key</code> - VAPID private key</li>
<li><code>msg-webpush-pubkey</code> - VAPID public key</li>
<li><code>msg-webpush-options-email</code> - an admin email for the VAPID subject</li>
</ul>
<p>The device token must be generated in the browser after successful subscription:</p>
<pre><code>     navigator.serviceWorker.register(&quot;/js/webpush.js&quot;, { scope: &quot;/&quot; }).then(function(registration) {
         registration.pushManager.subscribe({ userVisibleOnly: true, applicationServerKey: vapidKeyPublic }).then(function(subscription) {
             bkjs.send({ url: &#39;/uc/account/update&#39;, data: { device_id: &quot;wp://&quot; + window.btoa(JSON.stringify(subscription)) }, type: &quot;POST&quot; });
         }).catch((err) =&gt; {})
     });
</code></pre>
</li>
</ul>

<h2 id="module-pool">Module: pool</h2>
<p>  Create a resource pool, <code>create</code> and <code>close</code> callbacks must be given which perform allocation and deallocation of the resources like db connections.</p>
<p>  Options defines the following properties:</p>
<ul>
<li>create - method to be called to return a new resource item, takes 1 argument, a callback as <code>function(err, item)</code></li>
<li>destroy - method to be called to destroy a resource item</li>
<li>reset - method to bec alled just before releasing an item back to the resource pool, this is a chance to reset the item to the initial state</li>
<li>validate - method to verify active resource item, return false if it needs to be destroyed</li>
<li>init - method to cal on pool.init, it may be called multiple times</li>
<li>shutdown - method to call on pool shutdown to clear other resources</li>
<li>min - min number of active resource items</li>
<li>max - max number of active resource items</li>
<li>max_queue - how big the waiting queue can be, above this all requests will be rejected immediately</li>
<li>timeout - number of milliseconds to wait for the next available resource item, cannot be 0</li>
<li>idle - number of milliseconds before starting to destroy all active resources above the minimum, 0 to disable.</li>
</ul>
<p>  If no create implementation callback is given then all operations are basically noop but still cals the callbacks.</p>
<p>  Example:
         var pool = new Pool({ min: 1, max: 5,
                                   create: function(cb) {
                                      someDb.connect(function(err) { cb(err, this) }
                                   },
                                   destroy: function(client) {
                                      client.close() }
                                   })</p>
<pre><code>     pool.aquire(function(err, client) {
        ...
        client.findItem....
        ...
        pool.release(client);

     });
</code></pre>

<ul>
<li><p><code>Pool.prototype.init(options)</code></p>
<p>  Initialize pool properties, this can be run anytime even on the active pool to override some properties</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.acquire(callback)</code></p>
<p>  Return next available resource item, if not available immediately wait for defined amount of time before calling the
callback with an error. The callback second argument is active resource item.</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.destroy(item, callback)</code></p>
<p>  Destroy the resource item calling the provided close callback</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.release(item)</code></p>
<p>  Return the resource item back to the list of available resources.</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.destroyAll()</code></p>
<p>  Close all active items</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.stats()</code></p>
<p>  Return an object with stats</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype.shutdown(callback, maxtime)</code></p>
<p>  Close all connections and shutdown the pool, no more items will be open and the pool cannot be used without re-initialization,
if callback is provided then wait until all items are released and call it, optional maxtime can be used to retsrict how long to wait for
all items to be released, when expired the callback will be called</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype._call(name, callback)</code></p>
<p>  Call registered method and catch exceptions, pass it to the callback if given</p>
</li>
</ul>

<ul>
<li><p><code>Pool.prototype._timer()</code></p>
<p>  Timer to ensure pool integrity</p>
</li>
</ul>

<h2 id="module-run">Module: run</h2>
<h2 id="module-server">Module: server</h2>
<p>  The main server class that starts various processes</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>server-max-processes</code>, type: &quot;callback&quot;, callback: setWorkers</li>
<li><code>server-workers</code>, type: &quot;callback&quot;, callback: setWorkers, descr: &quot;Max number of processes to launch for Web servers, 0 means <code>NumberOfCPUs-1</code>, &lt; 0 means <code>NumberOfCPUs*abs(N)</code>&quot;</li>
<li><code>server-crash-delay</code>, type: &quot;number&quot;, max: 30000, obj: &quot;crash&quot;, descr: &quot;Delay between respawing the crashed process&quot;</li>
<li><code>server-restart-delay</code>, type: &quot;number&quot;, max: 30000, descr: &quot;Delay between respawning the server after changes&quot;</li>
<li><code>server-no-restart</code>, type: &quot;bool&quot;, descr: &quot;Do not restart any processes terminated, for debugging crashes only&quot;</li>
<li><code>server-log-errors</code> , type: &quot;bool&quot;, descr: &quot;If true, log crash errors from child processes by the logger, otherwise write to the daemon err-file. The reason for this is that the logger puts everything into one line thus breaking formatting for stack traces.&quot;</li>
<li><code>server-process-name</code>, descr: &quot;Path to the command to spawn by the monitor instead of node, for external processes guarded by this monitor&quot;</li>
<li><code>server-process-args</code>, type: &quot;list&quot;, re_map: [&quot;%20&quot;, &quot; &quot;], descr: &quot;Arguments for spawned processes, for passing v8 options or other flags in case of external processes&quot;</li>
<li><code>server-worker-args</code>, type: &quot;list&quot;, re_map: [&quot;%20&quot;, &quot; &quot;], descr: &quot;Node arguments for workers, job and web processes, for passing v8 options&quot;</li>
<li><code>server-api-restart-hours</code>, type: &quot;list&quot;, datatype: &quot;int&quot;, descr: &quot;List of hours when to restart api workers, only done once for each hour&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>server.start()</code></p>
<p>  Start the server process, call the callback to perform some initialization before launchng any server, just after core.init</p>
</li>
</ul>

<ul>
<li><p><code>server.startMonitor(options)</code></p>
<p>  Start process monitor, running as root</p>
</li>
</ul>

<ul>
<li><p><code>server.startMaster(options)</code></p>
<p>  Setup worker environment</p>
</li>
</ul>

<ul>
<li><p><code>server.startWebServer(options)</code></p>
<p>  Create Express server, setup worker environment, call supplied callback to set initial environment</p>
</li>
</ul>

<ul>
<li><p><code>server.startWebMaster()</code></p>
<p>  Spawn web server from the master as a separate master with web workers, it is used when web and master processes are running on the same server</p>
</li>
</ul>

<ul>
<li><p><code>server.handleChildProcess(child, type, method)</code></p>
<p>  Setup exit listener on the child process and restart it</p>
</li>
</ul>

<ul>
<li><p><code>server.startProcess()</code></p>
<p>  Restart the main process with the same arguments and setup as a monitor for the spawn child</p>
</li>
</ul>

<ul>
<li><p><code>server.startDaemon()</code></p>
<p>  Create daemon from the current process, restart node with -daemon removed in the background</p>
</li>
</ul>

<ul>
<li><p><code>server.onProcessExit()</code></p>
<p>  Kill all child processes on exit</p>
</li>
</ul>

<ul>
<li><p><code>server.onProcessTerminate()</code></p>
<p>  Terminates the server process, it is called on SIGTERM signal but can be called manually for graceful shitdown,
it runs <code>shutdown[Role]</code> methods before exiting</p>
</li>
</ul>

<ul>
<li><p><code>server.shutdown(options, callback)</code></p>
<p>  Shutdown the system immediately, mostly to be used in the remote jobs as the last task</p>
</li>
</ul>

<ul>
<li><p><code>server.shutdownServer(options, callback)</code></p>
<p>  Graceful shutdown if the api server needs restart</p>
</li>
</ul>

<ul>
<li><p><code>server.spawnProcess(args, skip, opts)</code></p>
<p>  Start new process reusing global process arguments, args will be added and args in the skip list will be removed</p>
</li>
</ul>

<ul>
<li><p><code>server.writePidfile()</code></p>
<p>  Create a pid file for the current process</p>
</li>
</ul>

<ul>
<li><p><code>server.restartWebWorkers()</code></p>
<p>  Performs graceful web worker restart</p>
</li>
</ul>

<h2 id="module-shell">Module: shell</h2>
<p>  Shell command interface for <code>bksh</code></p>
<p>  This module is supposed to be extended with commands, the format is `shell.cmdNAME``</p>
<p>  where <code>NAME</code> is he commnd name in camel case</p>
<p>  For example:</p>
<pre><code class="language-javascript"> const bkjs = require(&quot;backendjs&quot;);
 const shell = bkjs.shell;
 
 shell.cmdMyCommand = function(options) { console.log(&quot;hello&quot;); return &quot;continue&quot; }
</code></pre>
<p>  Now if i call <code>bksh -my-command</code> it will print hello and launch the repl,
  instead of retuning continue if the command must exit jut call <code>process.exit()</code></p>
<p>  Run <code>bksh -shell-help</code> to see all registered shell commands</p>

<ul>
<li><p><code>shell.start(options)</code></p>
<p>  Start REPL shell or execute any subcommand if specified in the command line.
A subcommand may return special string to indicate how to treat the flow:</p>
<ul>
<li>stop - stop processing commands and create REPL</li>
<li>continue - do not exit and continue processing other commands or end with REPL</li>
<li>all other values will result in returning from the run assuming the command will decide what to do, exit or continue running, no REPL is created</li>
<li>if `-noexit`` is passed in the command line keep the shell running after executing the command</li>
<li><code>-exit-timeout MS</code> will be set to ms to wait before exit</li>
<li><code>-shell-delay MS</code> will wait before running the command</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>shell.awsCheckTags(obj, name)</code></p>
<p>  Check all names in the tag set for given name pattern(s), all arguments after 0 are checked</p>
</li>
</ul>

<ul>
<li><p><code>shell.awsFilterSubnets(subnets, zone, name)</code></p>
<p>  Return matched subnet ids by availability zone and/or name pattern</p>
</li>
</ul>

<ul>
<li><p><code>shell.awsGetSelfImages(name, callback)</code></p>
<p>  Retrieve my AMIs for the given name pattern</p>
</li>
</ul>

<ul>
<li><p><code>shell.awsSearchImage(filter, appName, callback)</code></p>
<p>  Return an image that matches given app name latest version</p>
</li>
</ul>

<ul>
<li><p><code>shell.awsGetAmazonImages(options, callback)</code></p>
<p>  Return Amazon AMIs for the current region, HVM type only</p>
</li>
</ul>

<ul>
<li><p><code>shell.awsLaunchInstances(options, callback)</code></p>
<p>  Launch instances by run mode and/or other criteria</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsLaunchInstances(options)</code></p>
<p>  Delete an AMI with the snapshot</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsDeleteImage(options)</code></p>
<p>  Delete an AMI with the snapshot</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsCreateImage(options)</code></p>
<p>  Create an AMI from the current instance of the instance by id</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsRebootInstances(options)</code></p>
<p>  Reboot instances by run mode and/or other criteria</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsTerminateInstances(options)</code></p>
<p>  Terminate instances by run mode and/or other criteria</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsShowInstances(options)</code></p>
<p>  Show running instances by run mode and/or other criteria</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsSetupSsh(options)</code></p>
<p>  Open/close SSH access to the specified group for the current external IP address</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsSetupInstance(options)</code></p>
<p>  Launch an instance and setup it with provisioning script</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsS3Get(options)</code></p>
<p>  Get file</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsS3Put(options)</code></p>
<p>  Put file</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsS3List(options)</code></p>
<p>  List folder</p>
</li>
</ul>


<ul>
<li><p><code>shell.cmdAwsSetRoute53(options)</code></p>
<p>  Update a Route53 record with IP/names of all instances specified by the filter or with manually provided values</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAwsCreateRoute53(options)</code></p>
<p>  Create a new domain if does not exist, assign an ELB alias to a hosted zone</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbGetConfig(options)</code></p>
<p>  Show all config parameters</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbTables(options)</code></p>
<p>  Show all tables</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbSelect(options)</code></p>
<p>  Show record that match the search criteria, return up to <code>-count N</code> records</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbScan(options)</code></p>
<p>  Show all records that match search criteria</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbBackup(options)</code></p>
<p>  Save all tables to the specified directory or the server home</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbRestore(options)</code></p>
<p>  Restore tables</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbPut(options)</code></p>
<p>  Put a record</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbUpdate(options)</code></p>
<p>  Update a record</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbDel(options)</code></p>
<p>  Delete a record</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbDelAll(options)</code></p>
<p>  Delete all records</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdDbDrop(options)</code></p>
<p>  Drop a table</p>
</li>
</ul>

<ul>
<li><p><code>shell.exit(err, msg)</code></p>
<p>  Exit and write to the console a message or error message if non empty</p>
</li>
</ul>

<ul>
<li><p><code>shell.die(...args)</code></p>
<p>  Exit with error code and dump all arguments to the stderr, backtrace as well</p>
</li>
</ul>

<ul>
<li><p><code>shell.getUser(obj, callback)</code></p>
<p>  Resolves a user from <code>obj.id</code> or <code>obj.login</code> params and return the record in the callback</p>
</li>
</ul>

<ul>
<li><p><code>shell.getQuery(options)</code></p>
<p>  Returns an object with all command line params that do not start with dash(-), treat 2 subsequent parms without dashes as name value pair</p>
</li>
</ul>

<ul>
<li><p><code>shell.getQueryList()</code></p>
<p>  Returns a list with all command line params that do not start with dash(-), only the trailing arguments will be collected</p>
</li>
</ul>

<ul>
<li><p><code>shell.getArgs(options)</code></p>
<p>  Returns an object with all command line params starting with dash set with the value if the next param does not start with dash or 1.
By sefault all args are stored as is with dashes, if <code>options.camel`` is true then all args will be stored in camel form, if </code>options.underscore is true then all args will be stored with dashes converted into underscores.
<code>options.index</code> can be used to get the args from any position, by default it only returns args after the current
commands processed from <code>shell.cmdIndex</code></p>
</li>
</ul>

<ul>
<li><p><code>shell.getOption(name, options)</code></p>
<p>  Return an argument by name from the options, options may contain parameters in camel form or with underscores, both formats will be checked</p>
</li>
</ul>

<ul>
<li><p><code>shell.getArg(name, options, dflt)</code></p>
<p>  Return first available value for the given name, options first, then command arg and then default,</p>
</li>
</ul>

<ul>
<li><p><code>shell.getArgList(name, options)</code></p>
<p>  Returns a list of all values for the given argument name, it handles duplicate arguments with the same name</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdShowInfo(options)</code></p>
<p>  App version</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunFile(options)</code></p>
<p>  Load a module and optionally execute it</p>
<p>Example:</p>
<pre><code>   var bkjs = require(&quot;backendjs&quot;)
   bkjs.app.test = 123;
   exports.run = function() {
       console.log(&quot;run&quot;);
   }
   exports.newMethod = function() {
       console.log(bkjs.core.version, &quot;version&quot;);
   }
</code></pre>
<p> Save into a file a.js and run</p>
<pre><code>   bksh -run-file a.js
</code></pre>
<p> In the shell now it new methods can be executed</p>
<pre><code>   &gt; shell.newMethod()
</code></pre>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunConfig(options)</code></p>
<p>  Load a config file</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunIpc(options)</code></p>
<p>  Initialize more IPC clients</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunApi(options)</code></p>
<p>  Run API server inside the shell</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunJobs(options)</code></p>
<p>  Run jobs workers inside the shell</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdRunWorker(options)</code></p>
<p>  Run jobs workers inside the shell</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAuthGet(options)</code></p>
<p>  Show account records by id or login</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAuthAdd(options)</code></p>
<p>  Add a user login</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAuthUpdate(options)</code></p>
<p>  Update a user login</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdAuthDel(options)</code></p>
<p>  Delete a user login</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdLogWatch(options)</code></p>
<p>  Run logwatcher and exit</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdSendRequest(options)</code></p>
<p>  Send API request</p>
</li>
</ul>

<ul>
<li><p><code>shell.cmdSubmitJob(options)</code></p>
<p>  Send API request</p>
</li>
</ul>


<ul>
<li><p><code>tests.expect(ok, ...args)</code></p>
<p>  To be used in the tests, these global functions takes the following arguments:</p>
<p>expect(ok, ....)</p>
<ul>
<li>ok - it must be true or non empty value in order to continue</li>
<li>all other arguments will be printed to stderr before exiting including the backtrace</li>
</ul>
<p>assert(failed, ....)</p>
<ul>
<li>failed - it must be false or empty value in order to continue</li>
<li>all arguments will be printed to stderr before exiting including the backtrace</li>
</ul>
<p>Example</p>
<pre><code>     tests.test_GetUser = function(next)
     {
         describe(&quot;Test user record existence by id&quot;);
         db.get(&quot;bk_user&quot;, { login: &quot;123&quot; }, (err, row) =&gt; {
              assert(err, &quot;no error expected&quot;, row);
              expect(row?.id == &quot;123&quot;, `id must be 123`, row);
              next();
         });
     }
</code></pre>
</li>
</ul>

<ul>
<li><p><code>tests.describe(...args)</code></p>
<p>  Set the title and description of the next test, the title will be printed at the beginning of the global test object,
this is a convenience utility to better document tests</p>
</li>
</ul>

<ul>
<li><p><code>tests.checkAccess(options, callback)</code></p>
<p>  Generic access checker to be used in tests, accepts an array in .config with urls to check
The following properties can be used:</p>
<ul>
<li>url - URL to be checked with POST</li>
<li>get - URL to be check with GET</li>
<li>method - explicit method for url</li>
<li>data - query data for GET or postdata for POST</li>
<li>form - formdata for requests that need urlformencoded data</li>
<li>headers/cookies - extra headers and cookies to send</li>
<li>user - a user record with login and secret, a signature is send</li>
<li>status - status to expect, 200 is default</li>
<li>match - an object to checked against the response, uses lib.isMatched</li>
<li>nocsrf/nosig - do not use CSRF or signature in request</li>
<li>preprocess - function(conf, cb) to be called before making request</li>
<li>postprocess - function(conf, rc, cb) to be called after the request, rc is the response object from the request</li>
<li>delay - wait before making next request</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>shell.cmdTestRun(options)</code></p>
<p>  Run the test function which is defined in the global tests module, all arguments will be taken from the options or the command line. Options
use the same names as command line arguments without preceeding <code>test-</code> prefix.</p>
<p>The main commands:</p>
<ul>
<li>-test-list - show all available test functions and exit</li>
<li>-test-config - list of file(s) to load and parse as configs, all test- params will be added to the test object</li>
<li>-test-file - a javascript file to be loaded with tests or functions, it must reside inside tests/ folder, only the name is expected</li>
<li>-test-run - name of the functions to run, can be a list, must be the last command</li>
</ul>
<p>Optional parameters for the test-run:</p>
<ul>
<li>-test-verbose - on error print the context and backtrace</li>
<li>-test-delay - number of milliseconds before starting the test and exiting the process, default 500ms</li>
<li>-test-cluster - use a cluster worker to run each test in a separate process</li>
<li>-test-interval - number of milliseconds between iterations</li>
<li>-test-concurrency - how many tests to run at the same time, default is 1</li>
</ul>
<p>All other common command line arguments are used normally, like -db-pool to specify which db to use.</p>
<p>After finish or in case of error the process exits if no callback is given.</p>
<p>Example, store it in tests/index.js:</p>
<pre><code>     tests.test_mytest = async function(next) {
        describe(&quot;Check user record existence&quot;)
        var row = await db.aget(&quot;bk_user&quot;, { login: &quot;123&quot; });
        expect(row, &quot;record must exists&quot;);
        expect(row.id != &quot;123&quot;, &quot;Record id must not be 123&quot;, row)
        next();
     }

     # bksh -test-run mytest
</code></pre>
<p>Custom tests:</p>
<ul>
<li><p>to run al test in tests/</p>
<pre><code>bkjs test-all
</code></pre>
</li>
<li><p>to start all test commands in the shell using local ./tests/db.js</p>
<pre><code>bksh -test-file db -test-run

or

bkjs test-db
</code></pre>
</li>
<li><p>to start a specific test</p>
<pre><code>bksh -test-file db -test-run dynamodb
</code></pre>
</li>
</ul>
</li>
</ul>

<h2 id="module-watch">Module: watch</h2>
<p>  Watch the sources for changes and restart the server</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>watch-dir</code>, type: &quot;list&quot;, array: 1, descr: &quot;Watch sources directories for file changes to restart the server, for development only, the backend module files will be added to the watch list automatically, so only app specific directores should be added. In the production -monitor must be used.&quot;</li>
<li><code>watch-ignore</code>, type: &quot;regexp&quot;, descr: &quot;Files to be ignored by the watcher&quot;</li>
<li><code>watch-match</code>, type: &quot;regexp&quot;, descr: &quot;Files to be watched, .js and .css is the default&quot;</li>
<li><code>watch-web</code>, type: &quot;list&quot;, array: 1, descr: &quot;List of directories to be watched for file modifications and execute a <code>buildWeb</code> command to produce bundles, apps, etc... Relative paths will be applied to all packages, example: web/js,web/css&quot;</li>
<li><code>watch-build</code>, descr: &quot;Command to run on web files modifications, to be used with tools like minify/uglify&quot;</li>
<li><code>watch-mode</code>, descr: &quot;How to serialize web build launches for multiple files chnaged at the same time, if empty run one build per file, <code>dir</code> to run every launch per config directory, <code>dir1</code> to run by next top dir, <code>dir3</code> to run by thid directory from the file....&quot;</li>
<li><code>watch-delay</code>, type: &quot;int&quot;, descr: &quot;Delay in ms before triggering the build web command to allow multiple files saved&quot;</li>
</ul>
</li>
</ul>

<h2 id="module-bk_data">Module: bk_data</h2>
<p>  Account management</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>bk_data-perms</code>, type: &quot;map&quot;, maptype: &quot;list&quot;, descr: &quot;Tables and allowed operations, ex: -bk_data-perms bk_config:select;put&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>bk_data.configureWeb(options, callback)</code></p>
<p>  Create API endpoints and routes</p>
</li>
</ul>

<ul>
<li><p><code>bk_data.configureDataAPI()</code></p>
<p>  API for full access to all tables</p>
</li>
</ul>

<h2 id="module-bk_system">Module: bk_system</h2>
<p>  System management</p>

<ul>
<li><p><code>Config parameters</code></p>
<ul>
<li><code>bk_system-perms</code>, type: &quot;map&quot;, maptype: &quot;list&quot;, descr: &quot;Allowed operations, ex: -bk_system-perms restart:api,init:queue;config;db&quot;</li>
</ul>
</li>
</ul>

<ul>
<li><p><code>bk_system.configureWeb(options, callback)</code></p>
<p>  Create API endpoints and routes</p>
</li>
</ul>

<ul>
<li><p><code>bk_system.configureSystemAPI()</code></p>
<p>  API for internal provisioning and configuration</p>
</li>
</ul>

<h2 id="module-bk_user">Module: bk_user</h2>
<p>  Account management</p>

<ul>
<li><p><code>bk_user.configureWeb(options, callback)</code></p>
<p>  Create API endpoints and routes</p>
</li>
</ul>

<ul>
<li><p><code>bk_user.configureAccountsAPI()</code></p>
<p>  Account management</p>
</li>
</ul>

<ul>
<li><p><code>bk_user.getAccount(req, options, callback)</code></p>
<p>  Returns current account, used in /account/get API call, req.account will be filled with the properties from the db</p>
</li>
</ul>

<ul>
<li><p><code>bk_user.notifyAccount(options, callback)</code></p>
<p>  Send Push notification to the account. The delivery is not guaranteed, if the message was queued for delivery, no errors will be returned.</p>
<p>The options may contain the following:</p>
<ul>
<li>account - the whole account record where to send the notification</li>
<li>account_id - the id of the account where to send, the record will be retrieved</li>
<li>account_login - the login of the account where to send, the record will be retrieved</li>
<li>device_id - the device to send the message directly</li>
<li>msg - message text to send</li>
</ul>
<p>In addition the device_id can be saved in the format service://id where the service is one of the supported delivery services, this way the notification
system will pick the right delivery service depending on the device id, the default service is apple.</p>
<p> Example:</p>
<pre><code>  bk_user.notifyAccount({ account_id: &quot;123&quot;, msg: &quot;test&quot;, badge: 1, sound: 1 } })
</code></pre>
</li>
</ul>

<ul>
<li><p><code>bk_user.addAccount(req, options, callback)</code></p>
<p>  Register new account, may be used an API call, but the req does not have to be an Express request, it just
need to have query and options objects.</p>
</li>
</ul>

<ul>
<li><p><code>bk_user.updateAccount(req, options, callback)</code></p>
<p>  Update existing account, used in /account/update API call</p>
</li>
</ul>

<ul>
<li><p><code>bk_user.deleteAccount(req, callback)</code></p>
<p>  Delete account specified by the obj.
The options may contain <code>keep</code> array with tables to be kept, for example
delete an account but keep all messages and location: keep:[&quot;bk_user&quot;,&quot;bk_location&quot;]</p>
<p>This methods is suitable for background jobs</p>
</li>
</ul>


</div></body>
